\chapter{Computer code}
\label{sec:computercode}

Extensive use of computer software such as \MM \cite{M2} and SAGE \cite{sagemath} has been invaluable during my work. Especially the \MM package \texttt{VersalDeformations} \cite{ilten_versaldeformations} has been useful for experiments (lifting deformations to higher order, looking at base spaces, etc.).

In this Appendix I collect computer code for reproducing some of my calculations. Not everything is reproduced here. For all my code, consult my GitHub account at \url{https://github.com/FredrikMeyer/m2files}.

\section{Computing the singular locus}

In some cases, equations simplify significantly in affine charts. Therefore, using the naive command \texttt{singularLocus} in \MM often takes unnecessarily long time (and sometimes the computations never finish), as it computes the minors of a very large Jacobian matrix. Restricting to each affine chart, we can use the command \texttt{minimalPresentation} to eliminate variables to produce a new ring isomorphic to the first one, but with fewer equations.

The following code produces a list of the components of the singular locus of the projective scheme with homogeneous ideal $I$.

\begin{lstlisting}[language=Macaulay2]
fastSingularities = I -> (
    R := ring I;
    n := numgens R;
    gensR := gens R;
    singlist := {};
    for i from 0 to (n-1) do {
        affineChart := I + ideal(gensR_i - 1);
        singloc     := singularLocus minimalPresentation affineChart;
        sing        := radical ideal mingens ideal singloc;
        inv         := affineChart.cache.minimalPresentationMap;
        singlist = singlist | {(homogenize(preimage(inv,sing),gensR_i))};
        };
    saturate intersect(singlist)
    )
\end{lstlisting}

The method works by computing the singular locus in each affine chart, taking the radical, and then pulling back to the homogeneous coordinate ring. Finally, we get a list of singular loci in each affine chart. We return the (saturation of) the intersection of the singular loci of each affine chart.

The script is especially fast when computing the singular locus of toric varieties with a low-dimensional singular locus.

The following code finds the singular locus of the projectice cone $C(\P^2 \times \P^2) \subset \P^9$.

\begin{lstlisting}[language=Macaulay2]
R = QQ[x_0..x_8,x_9]
M = genericMatrix(R,3,3)
I = minors(2,M)
time fastSingularities I
time radical ideal singularLocus I
\end{lstlisting}

Our function performs significantly faster, than the native function \texttt{singularLocus}. On a modern MacBook Pro, the times are 1.14 seconds versus 4.31 seconds, respectively.

Here is a more involved example. Let $Y'$ be the four-dimensional singular toric variety from Chapter 4. It is defined by the $2 \times 2$-minors of two matrices with variables. In \MM we can define it as follows:
\begin{lstlisting}[language=Macaulay2]
S = QQ[x_1..x_6,z_1..z_6,y]
M1 = matrix{{y,x_1,x_2},{x_4,y,x_3},{x_5,x_6,y}}
M2 = matrix{{y,z_1,z_2},{z_4,y,z_3},{z_5,z_6,y}}
J = minors(2,M1) + minors(2,M2)
\end{lstlisting}

Here the difference in performance is even more striking. Our function computes the singular locus in 7.29 seconds, but the built-in function \texttt{singularLocus} used more than 22 minutes (at which point I interrupted the computation).

\section{Torus action}

The following lines checks if a projective scheme with ideal sheaf \texttt{IX} admits an action of a subtorus of $G=(\C^\ast)^n \subset \P^n$. To check this, we check if the equations are still valid after a torus action. Since $G$ is abelian, it act on functions by $\lambda \cdot f(x_0,\ldots,x_n)=f(\lambda_0 x_1, \ldots, \lambda_n x_n)$. 


\begin{lemma}
Suppose $\{ f_1,\ldots, f_r \}$ is a homogeneous generating set for $I_X=\text{\texttt{IX}}$. Then the subgroup of $G$ acting on $X \subset \P^n$ is generated by those $\lambda \in G$ such that $\lambda \cdot f_i  = c f_i$ for some $c \in \C^\ast$.
\end{lemma}
\begin{proof}
Let $H$ be the subgroup of $G$ fixing the ideal $I_X$. Let $H'$ be the subgroup of $g \in G$ acting on the $f_i$ by scalar multiplication: $g \cdot f_i =c f_i$. Clearly $H' \subseteq H$.  Now suppose $g \in H$. Then
$$
g \cdot f_1 = \sum_j a_j f_j
$$
for some constants $a_j$. We have that $g \cdot f_1 = f_1(\lambda_1 x _1 ,\ldots, \lambda_n x_n)$. Suppose the leading term of $f_1$ is $x_1^{b_1}\cdots x_n^{b_n}$. Then comparing leading terms in the left hand side and the right hand side, we see that $a_1 = \lambda_1^{b_1}\cdots \lambda_n^{b_n} := \lambda^m$. Hence the right hand side is $\lambda^m f_1 + \text{other terms}$. But there are the same number of terms on each side of the equation, meaning that the ``other terms''-part must be zero.

Hence $H=H'$. 
\end{proof}

It follows that to find the subgroup of $G$ acting on $X$, we have to find the $\lambda \in G$ such that the $f_i$ are simultaneous eigenvectors for them.

\begin{example}
\label{example:torus}
Let  $X$ be defined by $f = x_0x_1x_2x_3x_4+\sum_{i=0}^5 x_i^5$ in $\P^4$. Then for $\C^4$ to act on it, we must have $\lambda_0\lambda_1\lambda_2\lambda_3\lambda_4=\lambda_0^5=\ldots=\lambda_4^5$. By setting $\lambda_0=1$, we see that all the $\lambda_i$ are fifth roots of unity. Hence the subgroup acting on $H$ is the subgroup of $(\Z/5)^5/\Z_5$ given by $\{ (a_0,\ldots,a_5) \mid \sum a_i = 0 \}$.
\end{example}

The following code find the subtori of $G$ acting on $X$ in this way, by equating terms in the polynomials defining $X$.

\begin{lstlisting}[language=Macaulay2]
loadPackage "Binomials"
torus = ideal apply(flatten apply(
                  apply(
                      apply(flatten entries gens IX, monomials),
                          v ->  flatten entries v), 
                              j -> subsets(j,2)),
                                  s -> s_0-s_1)
toruskomps = BPD torus
toruskomps = select(toruskomps, I -> dim I == 1)
\end{lstlisting}

\begin{proof}[Explanation]
In order to have $g \cdot f = \lambda f$, all terms of the polynomial must be eigenvectors of $g$. Then as in \cref{example:torus},  this translates into equating all monomials in the generators. The code first makes a list of all pairs of monomials in generators of \texttt{IX}. Then we make the ideal of differences between each pair. Putting all the differences equal to zero, we find the subset of the torus acting on $X$.

The ideal \texttt{torus} is the ideal generated by the differences of terms in the polynomials defining $X$.

The \MM package \texttt{Binomials} \cite{kahle_binomials} can decompose binomials over cyclic extensions of $\Q$ with the command \texttt{BPD}. In the last line we select the components corresponding to finite subgroups of the torus.

Then we check manually if these actually correspond to non-trivial actions. There will be one component for each generator of the cyclic group acting on $X$.
\end{proof}

%%%%%%
%%%%%%
\section{Computing fixed points}

Computing fixed points of a torus action is often just as easy to do by hand, but to save time and potential for error, we mostly did this in \MM.

To check if a point $P \in \P^n$ is a fixed point of a group action, we lift $P$ to $\overline{P} \in \C^{n+1}$. Then $P$ is a fix point if and only if $g \cdot \overline P = \lambda \overline P$ for some $\lambda \in \C^\ast$.

To compute all fix points, we consider the ideal generated by $x_i - \lambda (g \cdot x_i)$ for each generator $x_i$. The fixed locus correspond to a primary decomposition of this ideal.

Below is the code to compute the fixed points of the $\Z/2$-action on the invariant subfamily of $X_2$. We create the ideal, then saturate by the maximal ideal $(x_1,\ldots,x_n)$ (since not all coordinates are allowed to be zero). Then we use the \texttt{decompose} command in \MM to get a primary decomposition.

\begin{lstlisting}[language=Macaulay2]
S  = R[lambda]
M1 =  matrix{{x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_10,x_11,x_12}}
nnnnnM2 =  matrix{{x_1*lambda,x_2*lambda,-x_3*lambda,x_4*lambda,-x_5*lambda,-x_6*lambda,-lambda*x_7,-x_8*lambda,lambda*x_9,-lambda*x_10,lambda*x_11,lambda*x_12}}

Ifiks = saturate(ideal (M1-M2), sub(ideal gens R,S))
decompose(Ifiks + IX)
\end{lstlisting}

The result is a list of $12$ ideals, corresponding to the $12$ fixed points.


%%%%%
%%%%%%
\section{Computing the Gaifullin triangulation}
\label{sec:compute_gaifullin}

Below is a short SAGE script computing the $15$ vertex triangulation of $\C \P^2$ as described in \cite{cp2_15_chess}. The last line returns a \texttt{SimplicialComplex} object in SAGE.

\begin{lstlisting}[language=Python]
#Defines the Klein 4 group.
V4 = PermutationGroup([Permutation("(1,2)(3,4)"),Permutation("(1,3)(2,4)")])

def isValidFace(F):
    '''
    Assumes the first vertex is a permutation.
    Then checks if F satisfies the condition in the
    definition of T.
    '''
    g = F[0]
    for v in (1,2,3,4):
        if (F[g(v)][1] == F[v][1]):
            return False
    return True


# Makes a list of all possible maximal faces of the correct form
candidates = [(g,(1,a1),(2,a2),(3,a3),(4,a4)) for g in V4.list()[1:] for a1 in (1,2,3) for a2 in (1,2,3) for a3 in (1,2,3) for a4 in (1,2,3)]

# Filters out the faces not fullfilling the condition
maximalFacets = filter(lambda F: isValidFace(F), candidates)

# Renames the vertices
S = SimplicialComplex(maximalFacets)
vertexSet = S.vertices()
D = dict([(F,i) for i,F in enumerate(vertexSet)])
renamedMaximalFacets = [[D[v] for v in F] for F in maximalFacets]
SS = SimplicialComplex(renamedMaximalFacets)
\end{lstlisting}

To get the Stanley--Reisner ideal, one can write:
\begin{verbatim}
list(SS.stanley_reisner_ring().defining_ideal().gens())
\end{verbatim}
The returned value is a list of the monomials generating the Stanley--Reisner ideal of $\mathcal T$. This can then be copied into \MM for further analysis.

%%%%%%%%
\section{Construction of the $X_i$}

In this section we describe an efficient way to present the Calabi--Yau varieties $X_i$ from \cref{sec:constructions} in \MM.

\subsection{Construction of $X_1$}

Recall the construction of $X_1$: it is the intersection of a toric variety $M \subset \P^{17}$ with a generic $\P^{11}$. The variety $X_1$ parametrized pairs of rank $1+1$ tensors in this $\P^{11}$.

We can think of elements of $E \otimes E \oplus E \otimes E$ as pairs of $3 \times 3$ matrices, which we denote by $(A,B)$. To span the $\P^{11}$, we choose block matrices $\left(A,B\right)_i$ ($i=1,\ldots,12$). Then we form the sum

\[
A \stackrel \Delta = \sum_{i=1}^{12} (A,B)_i x_i,
\]
with variables $x_i$. This matrix has rank $1+1$ if all the $2 \times 2$-minors of $A$ and $B$ vanish, and neither $A$ nor $B$ is zero (which for generic $(A,B)$ won't happen). 

Below is a short \MM script implementing this construction.

\begin{lstlisting}[caption = Code for $X_1$, language=Macaulay2]
kk = ZZ/3001
R = kk[x_1..x_12]

generateX2 = () -> (
    K = random(R^18,R^12);
    a = transpose gens gb K; -- same image
    b = entries a;
    b = apply(0..11, i-> apply(b#i, z -> z*x_(i+1)));
    bb = sum toList b;
    bb1 = bb_{0..8};
    bb2 = bb_{9..17};
    M1 = matrix toList apply(0..2,
            i-> toList apply(0..2, j-> bb1#(3*i+j)));
    M2 = matrix toList apply(0..2,
            i-> toList apply(0..2, j-> bb2#(3*i+j)));
    I1 = minors(2, M1);
    I2 = minors(2, M2);
    I1+I2
    )
\end{lstlisting}

We explain each step. First we create a random $18 \times 12$-matrix with coefficients from the field \texttt{kk}. Then we replace the random matrix with a its Gaussian reduced form, which have the same image in $k^{18}$, but is much simpler.

Next, we use the matrix to create $18$ random linear forms in the variables $x_i$. These are then inserted into two $3 \times 3$ matrices $M_1$ and $M_2$. Finally, we return the ideal which is the sum of the ideal of the minors of the two matrices $M_1$ and $M_2$. This is the ideal of $X_1$.



\begin{remark}
Replacing the matrix $K$ with its Gaussian reduced form is the same as letting $\GL(k^{12})$ act on the left. This \emph{significantly} reduces the size of the resulting Gröbner basis. Without this simplification, the resulting Gröbner basis have $49$ elements, but with it, it has $19$ elements.

As an example, computing the degree zero part of $T^1(S_{X_1}/k,S_{X_1})$ takes about a week on a modern computer before simplification. With the smaller Gröbner basis, the same computation takes just a couple of hours.
\end{remark}

\subsection{Construction of $X_2$}

The construction of $X_2$ is very similar. Again, we create $12$ random elements of $\left(F \otimes F \otimes \right)^{\oplus 2}$ spanning a $\P^{11}$. This correspond to the $12$ columns of the random matrix $K$.

As with $X_1$, we replace $K$ with its Gaussian reduced form. This matrix spans the same $\P^{11}$, but has a lot more zeroes.

Then we form the sum
\[
\sum_{i=1}^{12} (T_1,T_2)_i x_i,
\]
where $T_1$ and $T_2$ are $2 \times 2 \times 2$-tensors. We return the ideal generated by the ``minors'' of this sum.

\begin{lstlisting}[caption=Code for $X_2$, language=Macaulay2]
minors222tensor = (L) -> ( -- L is a list of lists of lists
    eqs = {L#0#0#0*L#1#0#1 - L#0#0#1*L#1#0#0,
      L#1#0#0*L#1#1#1 - L#1#1#0*L#1#0#1,
      L#1#1#0*L#0#1#1 - L#1#1#1*L#0#1#0,
      L#0#1#0*L#0#0#1 - L#0#1#1*L#0#0#0,
      L#1#0#1*L#0#1#1 - L#1#1#1*L#0#0#1,
      L#1#0#0*L#0#1#0 - L#1#1#0*L#0#0#0};
    eqs = eqs | {L#0#0#0 * L#1#1#1 - L#0#0#1*L#1#1#0,
      L#1#0#0*L#0#1#1 - L#1#0#1*L#0#1#0,
      L#0#0#1*L#1#1#0 - L#1#0#1*L#0#1#0};
    ideal eqs
    )

generateX2 = () -> (
    K = random(R^16,R^12);
    a = transpose gens gb K;
    b = entries transpose K;
    b = entries a;
    b = apply(0..11, i-> apply(b#i, z -> z*x_(i+1)));
    bb = sum toList b;
    bb1 = bb_{0..7};
    bb2 = bb_{8..15};
    I1 = minors222tensor {{{bb1#0,bb1#1},{bb1#2,bb1#3}},
                         {{bb1#4,bb1#5},{bb1#6,bb1#7}}};
    I2 = minors222tensor {{{bb2#0,bb2#1},{bb2#2,bb2#3}}
                         {{bb2#4,bb2#5},{bb2#6,bb2#7}}};
    I1+I2
    )
\end{lstlisting}

Constructing $X_3$ in \MM is entirely similar to the above two constructions, so we omit the code.

\begin{remark}
Using a finite field when computing $T^1$ is essential. Without a limit on the size of the coefficients, the amount of necesserary computer RAM is way beyond current technology.
\end{remark}

\section{Constructing the invariant subfamilies}

Below is \MM code for constructing the invariant Calabi--Yau families described in Chapter 4.

\subsection{Code for $X_{H_t}$}

\begin{lstlisting}[caption=Code for $X_{H_t}$, language=Macaulay2]
Z = QQ[x_1..x_12]

pars = {2,3,5}
fija = (i,j,a) -> (
    Eij  := (id_(Z^3))_{i} * transpose (id_(Z^3))_{j};
    Eij' :=  (id_(Z^3))_{(-i-j) % 3} * transpose (id_(Z^3))_{(-i-j) % 3};
    if (a == 0) then (
      Eij | pars#((i-j)%3) * Eij'
      )
    else (
      pars#((i-j)%3) * Eij' | Eij
      )
    )

MG = x_1*fija(0,1,0) + x_2*fija(0,2,0) + x_3*fija(1,0,0) + 
     x_4*fija(1,2,0) + x_5*fija(2,0,0) + x_6*fija(2,1,0) +
     x_7*fija(0,1,1) + x_8*fija(0,2,1) + x_9*fija(1,0,1) +
     x_10*fija(1,2,1)+ x_11*fija(2,0,1)+ x_12*fija(2,1,1)

IX = minors(2,MG_{0..2}) + minors(2,MG_{3..5})
\end{lstlisting}

The function \texttt{fija} takes as inputs the indices in the definition of $f_{ij}^\alpha$ in \cref{eq:fija}. The list \texttt{pars} are parameters. Only if the parameters are all equal to $1$ do the variety obtain more singularities.

\subsection{Code for $X_{K_t}$}
{}
For the invariant subfamily of the $X_2$-family, the code is shorter (but uglier). We manually entered the equations of the invariant $2 \times 2 \times 2$-tensors $g_{ijk}^\alpha$ from \cref{eq:gijk}, and then computed the $2 \times 2 \times 2$-minors.

\begin{lstlisting}[caption=Code for $X_{K_t}$, language=Macaulay2]
pars = {2,3,5}
L1 = {{{pars#0 * x_7 + pars#1 * x_8 + pars#2 * x_10,x_1},
      {x_2,x_3}},{{x_4,x_5},
      {x_6,pars#2 *x_9 + pars#1 * x_11 + pars#0 * x_12}}}
L2 = {{{pars#0 * x_1 + pars#1 * x_2 + pars#2 * x_4,x_7},
      {x_8,x_9}},{{x_10,x_11},
      {x_12,pars#2 *x_3 + pars#1 * x_5 + pars#0 * x_6}}}

IX = (minors222tensor L1) + (minors222tensor L2)
\end{lstlisting}