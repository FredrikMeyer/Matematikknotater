\chapter{Computer code}
\label{sec:computercode}

Extensive use of computer software such as \MM \cite{M2} and SAGE \cite{sagemath} has been invaluable during my work. In this Appendix I collect some computer code for reproducing some of my calculations.

\section{Computing the singular locus}

In some cases, equations simplify significantly in affine charts. Therefore, using the naive command \texttt{singularLocus} in \MM often takes unnecessarily long time (and sometimes the computations never finish), as it computes the minors of a very large Jacobian matrix. Restricting to each affine chart, we can use the command \texttt{minimalPresentation} to eliminate variables to produce a new ring isomorphic to the first one, but with fewer equations.

The following code produces a list of the components of the singular locus of the projective scheme with ideal $I$.

\begin{lstlisting}[language=Macaulay2]
fastSingularities = I -> (
    R := ring I;
    n := numgens R;
    gensR := gens R;
    singlist := {};
    for i from 0 to (n-1) do {
        affineChart := I + ideal(gensR_i - 1);
        singloc     := singularLocus minimalPresentation affineChart;
        sing        := radical ideal mingens ideal singloc;
        inv         := affineChart.cache.minimalPresentationMap;
        singlist = singlist | {(homogenize(preimage(inv,sing),gensR_i))};
        };
    saturate intersect(singlist)
    )
\end{lstlisting}

The method works by computing the singular locus in each affine chart, taking the radical, and then pulling back to the homogeneous coordinate ring. Finally, we get a list of singular loci in each affine chart. We return the (saturation of) the intersection of the singular loci of the affine charts.

It is especially fast when computing the singular locus of toric varieties with a low-dimensional singular locus.

The following code finds the singular locus of the projectice cone $C(\P^2 \times \P^2) \subset \P^9$.

\begin{lstlisting}[language=Macaulay2]
R = QQ[x_0..x_8,x_9]
M = genericMatrix(R,3,3)
I = minors(2,M)
time fastSingularities I
time radical ideal singularLocus I
\end{lstlisting}

Our function performs significantly faster. On a modern Mac, the times are 1.14 seconds versus 4.31 seconds, respectively.

Here is a more involved example. Let $Y'$ be four-dimensional toric variety from Chapter 4. It is defined by the $2 \times 2$-minors two matrices. In \MM we can define it as follows:
\begin{lstlisting}[language=Macaulay2]
S = QQ[x_1..x_6,z_1..z_6,y]
M1 = matrix{{y,x_1,x_2},{x_4,y,x_3},{x_5,x_6,y}}
M2 = matrix{{y,z_1,z_2},{z_4,y,z_3},{z_5,z_6,y}}
J = minors(2,M1) + minors(2,M2)
\end{lstlisting}

Here the performance difference is even more impressive. Our function computes the singular locus in 7.29 seconds, but the built-in function \texttt{singularLocus} used more than 22 minutes (at which point I interrupted the computation).

\section{Torus action}

The following lines checks if a projective scheme with ideal sheaf \texttt{IX} admits an action of a subtorus of $G=(\C^\ast)^n \subset \P^n$. To check this, we check if the equations are still valid after a torus action. Since $G$ is abelian, it act on functions by $\lambda \cdot f(x_1,\ldots,x_n)=f(\lambda_1 x_1, \ldots, \lambda_n x_n)$. 


\begin{lemma}
Suppose $\{ f_1,\ldots, f_r \}$ is a homogeneous generating set for $I_X=\text{\texttt{IX}}$. Then subgroup of $G$ acting on $X \subset \P^n$ is generated by those $\lambda \in G$ such that $\lambda \cdot f_i  = c f_i$ for some $c \in \C^\ast$.
\end{lemma}
\begin{proof}
Let $H$ be the subgroup of $G$ fixing the ideal $I_X$. Let $H'$ be the subgroup of $g \in G$ acting on the $f_i$ by scalar multiplication: $g \cdot f_i =c f_i$. Clearly $H' \subseteq H$.  Now suppose $g \in H$. Then
$$
g \cdot f_1 = \sum_j a_j f_j
$$
for some constants $a_j$. Now $g \cdot f_1 = f_1(\lambda_1 x _1 ,\ldots, \lambda_n x_n)$. Suppose the leading term of $f_1$ is $x_1^{a_1}\cdots x_n^{a_n}$. Then comparing leading terms in the left hand side and the right hand side, we see that $a_1 = \lambda_1^{a_1}\cdots \lambda_n^{a_n} := \lambda^m$. Hence the right hand side is $\lambda^m f_1 + \text{other terms}$. But now there are the same number of terms on each side of the equation, so there are no other terms. Hence $H=H'$. 
\end{proof}

It follows that to find the subgroup of $G$ acting on $X$, we have to find the $\lambda \in G$ such that the $f_i$ are simultaneous eigenvectors for them.

\begin{example}
\label{example:torus}
Let  $X$ be defined by $f = x_0x_1x_2x_3x_4+\sum_{i=0}^5 x_i^5$ in $\P^4$. Then for $\C^4$ to act on it, we must have $\lambda_0\lambda_1\lambda_2\lambda_3\lambda_4=\lambda_0^5=\ldots=\lambda_4^5$. By setting $\lambda_0=1$, we see that all the $\lambda_i$ are fifth roots of unity. Hence the subgroup acting on $H$ is the subgroup of $(\Z/5)^5/\Z_5$ given by $\{ (a_0,\ldots,a_5) \mid \sum a_i = 0 \}$.
\end{example}

The following code find the subtori of $G$ acting on $X$ in this way, by equating terms in the polynomials defining $X$.

\begin{lstlisting}[language=Macaulay2]
loadPackage "Binomials"
torus = ideal apply(flatten apply(apply(apply(flatten entries gens IX, monomials), v ->  flatten entries v), j -> subsets(j,2)),    s -> s_0-s_1)
toruskomps = BPD torus
toruskomps = select(toruskomps, I -> dim I == 1)
\end{lstlisting}

\begin{proof}[Explanation]
In order to have $g \cdot f = \lambda f$, all terms of the polynomial must be eigenvectors of $g$. Then as in \cref{example:torus},  this translates into equating all monomials in the generators.

The ideal \texttt{torus} is the ideal generated by the differences of terms in the polynomials defining $X$.

The \MM package \texttt{Binomials} \cite{kahle_binomials} can decompose binomials over cyclic extensions of $\Q$ with the command \texttt{BPD}. In the last line we select the components corresponding to finite subgroups of the torus.

Then we check manually if these actually correspond to non-trivial actions. There will be one component for each generator of the cyclic group acting on $X$.
\end{proof}

%%%%%%
\section{Computing fixed points}

Computing fixed points of torus action is often just as easy to do by hand, but to save time and potential for error, we mostly did this in \MM.

To check if a point $P \in \P^n$ is a fixed point of a group action, we lift it to $\overline{P} \in \C^{n+1}$. Then $P$ is a fix point if and only if $g \cdot \overline P = \lambda \overline P$ for some $\lambda \in \C^\ast$.

To compute all fix points, we consider the ideal generated by $x_i - \lambda (g \cdot x_i)$ for each generator $x_i$. The fixed points correspond to a primary decomposition of this ideal.

Below is the code to compute the fixed points of the $\Z/2$-action on the invariant subfamily of $X_2$. We create the ideal, then saturate by the maximal ideal $(x_1,\ldots,x_n)$ (since not all coordinates are allowed to be zero). Then we use the \texttt{decompose} command in \MM to get a primary decomposition.

\begin{lstlisting}[language=Macaulay2]
S  = R[lambda]
M1 =  matrix{{x_1,x_2,x_3,x_4,x_5,x_6,x_7,x_8,x_9,x_10,x_11,x_12}}
M2 =  matrix{{x_1*lambda,x_2*lambda,-x_3*lambda,x_4*lambda,-x_5*lambda,-x_6*lambda,-lambda*x_7,-x_8*lambda,lambda*x_9,-lambda*x_10,lambda*x_11,lambda*x_12}}

Ifiks = saturate(ideal (M1-M2), sub(ideal gens R,S))
decompose(Ifiks + IX)
\end{lstlisting}

The result is a list of $12$ ideals, corresponding to the $12$ fixed points.


%%%%%
\section{Computing the Gaifullin triangulation}
\label{sec:compute_gaifullin}

Below is a short SAGE script computing the $15$ vertex triangulation of $\C \P^2$ as described in \cite{cp2_15_chess}. The last line returns a \texttt{SimplicialComplex} object in SAGE.

\begin{lstlisting}[language=Python]
#Defines the Klein 4 group.
V4 = PermutationGroup([Permutation("(1,2)(3,4)"),Permutation("(1,3)(2,4)")])

def isValidFace(F):
    '''
    Assumes the first vertex is a permutation.
    Then checks if F satisfies the condition in the
    definition of T.
    '''
    g = F[0]
    for v in (1,2,3,4):
        if (F[g(v)][1] == F[v][1]):
            return False
    return True


# Makes a list of all possible maximal faces of the correct form
candidates = [(g,(1,a1),(2,a2),(3,a3),(4,a4)) for g in V4.list()[1:] for a1 in (1,2,3) for a2 in (1,2,3) for a3 in (1,2,3) for a4 in (1,2,3)]

# Filters out the faces not fullfilling the condition
maximalFacets = filter(lambda F: isValidFace(F), candidates)

# Renames the vertices
S = SimplicialComplex(maximalFacets)
vertexSet = S.vertices()
D = dict([(F,i) for i,F in enumerate(vertexSet)])
renamedMaximalFacets = [[D[v] for v in F] for F in maximalFacets]
SS = SimplicialComplex(renamedMaximalFacets)
\end{lstlisting}

To get the Stanley--Reisner ideal, one can write:
\begin{verbatim}
list(SS.stanley_reisner_ring().defining_ideal().gens())
\end{verbatim}
The returned value is a list of the monomials generating the Stanley--Reisner ideal of $\mathcal T$. This can then be copied into \MM for further computation.

%%%%%%%%
\section{Construction of the $X_i$}

In this section we describe an efficient way to present the Calabi--Yau varieties $X_i$ from \cref{sec:constructions} in \MM.

\subsection{Construction of $X_1$}

Recall the construction of $X_1$: it is the intersection of a toric variety $M \subset \P^{17}$ with a generic $\P^{11}$. The variety $X_1$ parametrized pairs of rank $1+1$ tensors in this $\P^{11}$.

We can think of elements of $E \otimes E \oplus E \otimes E$ as pairs of $3 \times 3$ matrices, which we denote by $(A,B)$. To span the $\P^{11}$, we choose block matrices $\left(A,B\right)_i$ ($i=1,\ldots,12$). Then we form the sum

\[
A \stackrel \Delta = \sum_{i=1}^{12} (A,B)_i x_i,
\]
with variables $x_i$. This matrix has rank $1+1$ if all the $2 \times 2$-minors of $A$ and $B$ vanish. 

Below is a short \MM script implementing this construction.

\begin{lstlisting}[caption = Code for $X_1$, language=Macaulay2]
kk = ZZ/3001
R = kk[x_1..x_12]

generateX2 = () -> (
    K = random(R^18,R^12);
    a = transpose gens gb K; -- same image
    b = entries a;
    b = apply(0..11, i-> apply(b#i, z -> z*x_(i+1)));
    bb = sum toList b;
    bb1 = bb_{0..8};
    bb2 = bb_{9..17};
    M1 = matrix toList apply(0..2,
            i-> toList apply(0..2, j-> bb1#(3*i+j)));
    M2 = matrix toList apply(0..2,
            i-> toList apply(0..2, j-> bb2#(3*i+j)));
    I1 = minors(2, M1);
    I2 = minors(2, M2);
    I1+I2
    )
\end{lstlisting}

We explain each step. First we create a random $18 \times 12$-matrix with coefficients from the field \texttt{kk}. Then we replace the random matrix with a its Gaussian reduced form, which have the same image in $k^{18}$, but is much simpler.

Next, we use the matrix to create $18$ random linear forms in the variables $x_i$. These are then inserted into two $3 \times 3$ matrices $M_1$ and $M_2$. Finally, we return the ideal which is the sum of the ideal of the minors of the two matrices $M_1$ and $M_2$. This is the ideal of $X_1$.



\begin{remark}
Replacing the matrix $K$ with its Gaussian reduced form is the same as letting $\GL(k^{12})$ act on the left. This \emph{significantly} reduces the size of the resulting Gröbner basis. Without this simplification, the resulting Gröbner basis have $49$ elements, but with it, it has $19$ elements.

As an example, computing the degree zero part of $T^1(S_{X_1}/k,S_{X_1})$ takes about a week on a modern computer before simplification. With the smaller Gröbner basis, the same computation takes just a couple of hours.
\end{remark}

\subsection{Construction of $X_2$}

The construction of $X_2$ is very similar. Again, we create $12$ random elements of $\left(F \otimes F \otimes \right)^{\oplus 2}$ spanning a $\P^{11}$. This correspond to the $12$ columns of the random matrix $K$.

As with $X_1$, we replace $K$ with its Gaussian reduced form. This matrix spans the same $\P^{11}$, but has a lot more zeroes.

Then we form the sum
\[
\sum_{i=1}^{12} (T_1,T_2)_i x_i,
\]
where $T_1$ and $T_2$ are $2 \times 2 \times 2$-tensors. We return the ideal generated by the ``minors'' of this sum.

\begin{lstlisting}[caption=Code for $X_2$, language=Macaulay2]
minors222tensor = (L) -> ( -- L is a list of lists of lists
    eqs = {L#0#0#0*L#1#0#1 - L#0#0#1*L#1#0#0,
      L#1#0#0*L#1#1#1 - L#1#1#0*L#1#0#1,
      L#1#1#0*L#0#1#1 - L#1#1#1*L#0#1#0,
      L#0#1#0*L#0#0#1 - L#0#1#1*L#0#0#0,
      L#1#0#1*L#0#1#1 - L#1#1#1*L#0#0#1,
      L#1#0#0*L#0#1#0 - L#1#1#0*L#0#0#0};
    eqs = eqs | {L#0#0#0 * L#1#1#1 - L#0#0#1*L#1#1#0,
      L#1#0#0*L#0#1#1 - L#1#0#1*L#0#1#0,
      L#0#0#1*L#1#1#0 - L#1#0#1*L#0#1#0};
    ideal eqs
    )

generateX2 = () -> (
    K = random(R^16,R^12);
    a = transpose gens gb K;
    b = entries transpose K;
    b = entries a;
    b = apply(0..11, i-> apply(b#i, z -> z*x_(i+1)));
    bb = sum toList b;
    bb1 = bb_{0..7};
    bb2 = bb_{8..15};
    I1 = minors222tensor {{{bb1#0,bb1#1},{bb1#2,bb1#3}},
                         {{bb1#4,bb1#5},{bb1#6,bb1#7}}};
    I2 = minors222tensor {{{bb2#0,bb2#1},{bb2#2,bb2#3}}
                         {{bb2#4,bb2#5},{bb2#6,bb2#7}}};
    I1+I2
    )
\end{lstlisting}

Constructing $X_3$ in \MM is entirely similar to the above two constructions, so we omit the code.

\begin{remark}
Using a finite field is essential. Without a limit on the size of the coefficients, the amount of necesserary computer RAM is way beyond current technology.
\end{remark}