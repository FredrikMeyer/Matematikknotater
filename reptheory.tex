\documentclass[11pt, english]{article}
%\documentclass[12pt]{article}  
%\usepackage[papersize={108mm,144mm},margin=2mm]{geometry}  
\sloppy 
%\pagestyle{empty} 
%\usepackage[scaled]{helvet}
%\renewcommand{\familydefault}{\sfdefault}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}   % S P R A A K

\usepackage{amssymb, amsmath, amsthm, amssymb} % symboler, osv
\usepackage{mathrsfs,calligra}
\usepackage{url}
\usepackage{thmtools}
\usepackage{enumerate}  % lister $
\usepackage{float}
\usepackage{tikz}
\usepackage[all]{xy}   % for comm.diagram
\usepackage{wrapfig} % for float right
\usepackage[colorlinks=true]{hyperref}
\usepackage{mystyle} % stilfilen      


\title{Representation theory}
\author{Fredrik Meyer} 
\date{}
\begin{document}
\maketitle

\abstract{These are notes from the course MAT4270 on representation theory, autumn 2015. The lectures were held by Sergey Neshyevey. The notes are mine. The first half is about representations of finite groups, the second  half about representations of compact Lie groups.}
\section{Lecture 1}

From now on $G$ is always a \emph{finite group} and $V$ a finite-dimensional vector space over the complex number. Most results will hold over any algebraically closed field of characteristic zero.

\subsection{Motivating example}

In 1896 Dedekind made the following observation. Let $\C[x_g \mid g \in G]$ be the free $\C$-algebra with basis the elements of $G$. Then one can form the following polynomial:
\[
P_G(x_{\rho_1},\ldots,x_{\rho_n}) = \det \left( (x_{\rho_i g_j})_{i,j=1}^n \right).
\]

Note that the matrix is just the multiplication table for the group $G$. The problem is to decompose $P_G$ into irreducible polynomials. 

\begin{example}
Let $G=S_3$. Then $G$ is generated by two elements $r$ and $s$ with the relation $srs=r^2$. If we write the elements of $G$ as $\{e,r,r^2,s,sr,sr^2\}$, then the multiplication table looks like
 $$ \bgroup\begin{pmatrix}
e&     r&     r^2&     s&     sr&     sr^2\\
     r&    r^2&     e&    sr^2&     s&     sr\\ 
    r^2&     e&     r&     sr&     sr^2&     s\\ 
    s&     sr&    sr^2&     e&     r&    r^2\\ 
    sr&     sr^2&     s&    r^2&    e&     r\\
  sr^2&     s&   sr&     r&    r^2&     e\\
     \end{pmatrix}\egroup.$$
The determinant is quite long, so I won't write it out. Suffice it to say it is a degree $6$ polynomial with 146 terms. Using a computer algebra system such as \verb|Macaulay2|, one can decompose it. It decomposes into three factors: one quadratic and two linear. They are the following (we change notation to avoid confusion about exponents):
\[
x_e+x_r+x_{r^2}+x_s+x_{sr}+x_{sr^2}
\]
and 
\[
x_e+x_r+x_{r^2}-x_s-x_{sr}-x_{sr^2}
\]
and 
\[
x_e^2-x_ex_r+x_{r^2}-x_e x_{r^2}-x_r x_{r^2} + x_{r^2}^2-x_s^2+x_s x_{sr} - x_{sr^2}^2 + x_s x_{sr^2}-x_{sr^2}^2-x_{sr^2}^2.
\]
We will see later that the first factor corresponds to the trivial representation, the second to the alternating representation, and the third is the so-called standard represenation of $G$.
\end{example}
Frobenius proved the following theorem:
\begin{thm}
  Let $P_G= \prod_{i=1}^r P_i^{m_i}$ be the decomposition of $P_G$ into irreducibles. Then
  \begin{enumerate}
  \item $m_i=\deg P_i$ for every $i$.
\item $r$ is the number of conjugacy classes in $G$. 
  \end{enumerate}
In particular, since $r=\lvert G \rvert $ if and only if $G$ is abelian, $P_G$ decomposes into linear factors if and only if $G$ is abelian.
\end{thm}

In trying to prove the above theorem, Frobenius had to develop representation theory.

\subsection{Representations}

A \textbf{representation of $G$ on $V$} is a homomorphism $\pi:G \to \GL(V)$. We will denote a representation interchangably by $\pi, (\pi,V), V_\pi$ or $V$, depending upon the situation.

This means that a representation is a \emph{linear} action of $G$ on $V$.

\begin{example}
  The trivial representation $\epsilon$ of any group is given by letting $V= \C$ and $\epsilon(g)=e$ for all $g \in G$.
\end{example}

\begin{example}[Left regular representation]
Let $\C[G]$ be the space of functions on $G$. It is a finite-dimensional vector space under pointwise addition. Define $\lambda:G \to \GL(\C[G])$ by
\[
g \mapsto \left(f \mapsto (h \mapsto f(g^{-1}h)) \right)
\]
This vector space have a basis consisting of the characteristic functions $e_g$ for $g \in G$. On these elements on sees that the action is given by $g \cdot e_h = e_{gh}$. 

\end{example}
\begin{example}
 Similarly, one has the \textbf{permutation representation}. Let $X$ be a $G$-set, i.e. a set on which $G$ acts. Then one forms the space $\C[X]$ of $X$-valued functions. It has a basis $e_x$ of characteristic functions, and the action of $G$ on $\C[X]$ is given by $g e_x = e_{gx}$. 
\end{example}

The notion of isomorphism is not surprising. An \textbf{equivalence} of representations $(\pi,V)$ and $(\theta,W)$ is given by a vector space isomorphism $T:V \to W$ such that $T(g \cdot v) = g \cdot T(v)$ for all $g \in G$.

In case $T:V \to W$ is not an isomorphism, we say that $T$ is an \textbf{intertwiner} of $V$ and $W$. The set of intertwiners is denoted by $\Mor(\pi,\theta)$ or $\Hom_G(V,W)$.

A subspace $W \subset V$ is \textbf{invariant} if $g \cdot W \subset W$ for all $g \in G$. Letting $\theta(g) = \restr{\pi(g)}{W}$, we get another representation of $G$, called a \textbf{subrepresentation} of $G$. We write $\restr{\pi}{W}$ for $\theta$. 

If we have two representation $(\pi,V)$ and $(\pi',V')$, we can form the \textbf{direct sum representation} by letting $g \in G$ act on $V \oplus V'$ componentwise. Note that $\pi$ is a subrepresentation of $V \oplus V'$.

\begin{prop}[Mascke's theorem]
\label{propmaschke}
Let $(\pi,V)$ be a representation of $G$ and $W \subset V$ an invariant subspace. Then there exists a complementary invariant subspace $W^\perp$. That is, $W$ is also invariant and such that $V = W \oplus W^\perp$.
\end{prop}

\begin{proof}
  We prove this by ``averaging''. Let $P:V \to W$ be \emph{any} projection from $V$ to $W$. Then define 
\[
\Pi(v) = \frac 1{\lvert G \rvert} \sum_{g \in G} g P(g^{-1}v).
\]
This is a $G$-linear morphism, because
\begin{eqnarray*}
\Pi(h\cdot v) &= \frac 1{\lvert G \rvert} \sum_{g \in G} g P(g^{-1} h \cdot v) \\  
&=  \frac 1{\lvert G \rvert} \sum_{g \in G} g P((h^{-1}g) \cdot v) \\
&=  \frac h{\lvert G \rvert} \sum_{g \in G} h^{-1}g P((h^{-1}g) \cdot v).
\end{eqnarray*}
It is also surjective, since if $v \in W$, then clearly $\Pi(v)=v$. Hence $\Pi$ is a $G$-linear surjection onto $W$. Then it is clear that $\ker \Pi$ is a $G$-invariant subspace of $V$ complementary to $W$.
\end{proof}

We say that a representation is \textbf{irreducible} if it has no proper invariant subspaces. A representation is \textbf{completely reducible} if it decomposes into a direct sum of irreducible representations.

\begin{example}
  Let $G = (\R,+)$ act on $\R^2$ by the matrices
\[
\begin{pmatrix}
1 & a \\ 
0 & 1
\end{pmatrix}.
\]
This leaves the $x$-axis fixed, so the representation is not irreducible. But it does not split into irreducible representations, since there is no complementary subspaces.
\end{example}

However, if $G$ is finite (or \textbf{compact}, as we shall see later), things are nicer:

\begin{thm}
 Any finitely-dimensional representation of a finite group $G$ is completely reducible.
\end{thm}
The proof follows directly from Maschke's theorem \eqref{propmaschke}.  

We next prove Schur's lemma, which although has a very simple proof, has great consequences.

\begin{prop}[Schur's lemma]
Let $(V,\pi)$ and $(W,\theta)$ be irreducible representations. Then
\begin{enumerate}
\item If $\pi \not \sim \theta$, then $\Hom_G(V,W)=0$.
\item If $\pi \sim \theta$, then $\Hom_G(V,W)$ is $1$-dimensional. 
\end{enumerate}
\end{prop}
\begin{proof}
Both the kernel and the image of a morphism of representations is a representation. But since $V,W$ are irreducible, it follows that $\ker \varphi = 0$ or $\ker \varphi  = V$ for any $\varphi:V \to W$. This proves i). 

Now suppose $\Pi:V \to W$ is an equivalence of representations. Let $\varphi \in \Hom_G(V,W)$. Then $\varphi$ must be an equivalence as well, since the neither the kernel nor image can be non-zero. Consider $T=\varphi^{-1} \circ \Pi: V \to V$. This is a linear map, and since we work over $\C$, it has an eigenvalue $\lambda$. Now consider $T-\lambda \id_V$. This has non-zero invariant kernel, hence $T-\lambda \id_V=0$. 
\end{proof}

\begin{prop}
 If $G$ is abelian, then any irreducible representation of $G$ is 1-dimensional.
\end{prop}
\begin{proof}
Each $g \in G$ gives a map $\pi(g):V \to V \in \End(V)$. This is even an intertwining map, because $\pi(g)\pi(h)=\pi(gh)=\pi(hg)=\pi(h)\pi(g)$.

If $\pi$ is not trivial, by Schur's lemma, this map is just multiplication by some constant. But any 1-dimensional subspace of $V$ is invariant under this action, so $V$ must be 1-dimensional in order to be irreducible.
\end{proof}

Thus, up to equivalence, every irreducible representation of a finite abelian group is just a homomorphism $\chi:G \to \C$. But since $G$ is finite, this actually maps into $\mathbb T := \{ z \in \C \mid \lvert z \rvert = 1 \}$. Such maps are called \textbf{characters} of $G$. Denote by $\hat G$ the \emph{set} of irreducible representations of $G$. 

We call the $\hat G$ the \textbf{Pontryagin dual} of $G$. It is an abelian group under pointwise multiplication. See Exercise 2 for more on this.

\begin{remark}
  If $G$ is non-abelian, there will always exist irreducible representations of dimension $\geq 2$. This follows because the regular representation $G \to \GL \left( \C[G] \right)$ is injective.
\end{remark}

\section{Lecture 2 - Density theorems}

\subsection{Density theorems}

Let $(V,\pi)$ be an irreducible representation. The set of operators $\pi(g)$ for $g \in G$ is quite large. By definition, if $x \neq 0$, then
$$
V = \mathrm{Span} \{ \pi(g)x \mid g \in G \}.
$$
By Schur's lemma, we also know that 

$$
\End(\pi) = \{ T \in \End(V) \mid T\pi(g) = \pi(g) T \, \forall \, g \in G \} = \C \cdot \id_V.
$$

\begin{thm}[The density theorem]
\label{thmdensity}
 Assume $\pi_1,\ldots,\pi_n$ are pairwise inequivalent irreducible representations, with $V_i = V_{\pi_i}$. Consider the direct sum representation $V_1 \oplus \ldots \oplus V_n$.

Then
\[ 
\Span {\pi(G)} = \End(V_1) \oplus \ldots \oplus \End(V_2).
\]
\end{thm}
\begin{proof}[Proof/exercise:]
We deduce the first theorem from the second: First break $(V,\pi)$ into irreducible representations $V_i$. Then it follows directly from Schur's lemma that $\pi(G)' = \C \id_{V_1} \oplus \ldots \oplus \C \id_{V_n}$. 

Now, the elements of $\C \id_{V_1} \oplus \ldots \oplus \C \id_{V_2}$ are block diagonal matrices. It is an easy exercise with matrices to see that the commutator of this set is just
$$
\End(V_1) \oplus \ldots \oplus \End(V_2).
$$
\end{proof}

First we need some notation. Let $V$ be some vector space and $X \subset \End(V)$ a subset of the endomorphisms of $V$. Let 
\[
X' \stackrel{\Delta}{=}  \{ T \in \End(V) \mid TS = ST \text{ for all } S \in X \}.
\]
We call $X'$ the \textbf{commutant} of $X$. Thus if $(V,\pi)$ is a representation, then by definition:
\[
\End(\pi) = \pi(G)'.
\]

\begin{thm} 
 For any finite-dimensional representation $(V,\pi)$ we have 
\[
\pi(G)'' = \Span{\pi(G)}.
\]
\end{thm}
\begin{proof}
Let $T \in \pi(G)''$. Let $x_1,\ldots,x_n$ be a basis of $V$. Consider the representation $\theta = \pi \oplus \ldots \oplus \pi$ (n times) on $W = \oplus_{i=1}^n V$. Consider $x=(x_1,\ldots,x_n) \in W$ and the operator $S = T \oplus \ldots \oplus T$ on $W$. 

It is an exercise to show that $S \in \Theta(G)''$.

Now $\Span{\theta (G) x }$ is an invariant subspace of $W$. Then there exists an invariant complementary subspace. Let $P:W \to \Span{\theta(G)x}$ be the projection with kernel that invariant subspace, so that $P \in \Theta(G)'$ (that is, $P$ is a $G$-morphism). Then
$$
PSx = SPx = Sx
$$
since $P x \in \Span{\theta(G)x}$. Hence $Sx \in \Span { \theta(G)x }$ as well. This means that there exist $\alpha_g \in \C$ such that
$$
Sx = \sum_g \alpha_g \theta(g)x
$$
This is the same as saying that
$$
Tx_i = \sum_g \alpha_g \pi(g)x_i,
$$
hence $T = \sum \alpha \pi(g)$ .
\end{proof}


\subsection{Orthogonality relations}

Let $(V,\pi)$ be a representation and let $\rho \in V^\ast = \Hom(V,\C)$. The functions $\alpha_{\rho,x}^\pi$ on $G$ defined by $\alpha_{\rho,x}^\pi(g)=\rho(\pi(g)x)$ is called a \textbf{matrix coefficient} of $\pi$. If we fix a basis $e_1,\ldots,e_n$ of $V$ and consider the dual basis $e_1^\ast,\ldots, e_n^\ast$ of $V^\ast$, then we write $\alpha_{ij}^\pi$ instead of $\alpha_{e_i^\ast,e_j}^\pi$.

In the basis $e_1,\ldots,e_n$ we have
$$
\pi(g) = \left( \alpha_{ij}^\pi(g) \right)_{ij}
$$

\begin{thm}
 We have:
 \begin{enumerate}
 \item If $\pi$ and $\theta$ are inequivalent irreducible representations, then
\[
\frac 1{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi(g) \alpha_{\rho,y}^\theta(g^{-1}) = 0
\]
for all $f \in V_\pi^\ast$, $\rho \in V_\theta^\ast$, $x \in V_\pi$ and $y \in V_\theta$.
\item If $\pi$ is irreducible, then
\[
\frac{1}{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi(g) \alpha_{\rho,y}^\pi (g^{-1}) = \frac{f(x) \rho(y)}{\dim \pi}.
\]
 \end{enumerate}
\end{thm}
\begin{proof}
It is the avering trick again. First observe that if $T:V_\theta \to V_\pi$ is any linear operator, then 
\[
S = \frac{1}{\lvert G \rvert} \sum_{g \in G} \pi(g) T \theta(g^{-1}) 
\]
is in $\Hom_G(\theta,\pi)$ by averaging. Thus, since $\pi$ and $\theta$ are in-equivalent, it follows from Schur's lemma that this must be zero.

Now let $T(v) = \rho(v)x$. This is a linear operator. Then
$$
0 = f(Sy) = \frac{1}{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi (g) \alpha_{\rho,y}^\theta(g^{-1}).
$$
This proves part $1$.

Now suppose $\pi=\theta$. Then $S \in \End(\pi) = \C \cdot \id_V$. Thus $S = \alpha \cdot \id_V$. Taking traces on both sides, we get $\alpha = Tr T/\dim \pi$ (note that $T$ and $S$ have the same trace).

Then
$$
\frac 1{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi(g) \alpha_{\rho,y}^\pi(g^{-1}) = f(S(y)) = f(y) \frac{Tr T}{\dim \pi}
$$
(make this nicer some time)
\end{proof}

Instead of writing expressions like $\sum_g \alpha_g \pi(g)$ it is convenient to introduce the following notation. Define the \textbf{convolution} of two functions $f_1,f_2 \in \C[G]$ by
$$
(f_1 \ast f_2)(g) = \sum_{g=g_1g_2} f_1(g_1)f_2(g_2) = \sum_{h \in G} f_1(h)f_2(h^{-1}g).
$$
We have $\delta_{g_1} \ast \delta_{g_2} = \delta_{g_1g_2}$ (easy check!). The convolution product is associative and makes $\C[G]$ into an algebra, called the \textbf{group algebra} of $G$. 

Given a representation $\pi:G \to \GL(V)$ we can define an algebra homomorphism $\C[G] \to \End(V)$ by $\pi(f) = \sum_{g \in G} f(g) \pi(g)$. Thus $V$ becomes a left $\C[G]$-module. Conversely, given any united algebra homomorphism $\pi:\C[G] \to \End(V)$, we get a representation by $g \mapsto \pi(\delta_g)$. Thus we have a correspondence between representations of $G$ and left $\C[G]$-modules. Using these notions, the Density Theorem (Theorem \ref{thmdensity}) becomes $\pi(\C[G]) = \oplus_i \End(V_i)$.

\begin{thm}
Let $\hat G$ be the set of equivalence classes of irreducible representations of $G$. Then $\hat G$ is finite and $\sum_{[\pi] \in \hat G} (\dim \pi)^2 = \lvert G \rvert$. Furthermore, we have
$$
\lambda \sim  \bigoplus_{[\pi] \in \hat G} \pi^{\oplus \dim \pi}.
$$
Here $\lambda$ is the left regular representation of $G$.
\end{thm}
Proof to come later.

\section{Lecture 3 - More on orthogonality}

Where does the name ``orthogonality relations'' come from? We'll see now.

First of all, note that if $V_\pi$ is a representation of a finite group $G$, and $\langle,\rangle'$ is \emph{any} Hermitian scalar product on $V_\pi$, then 
$$
\langle v, w \rangle := \frac{1}{\langle G \rangle} \sum_{g \in G} \langle \pi(g) v, \pi(g) w \rangle'
$$
is another Hermitian scalar product on $V_\pi$, making the representation \textbf{unitary}.

If $\pi$ is any unitary representation, choose an orthonormal basis $e_1,\ldots,e_n \in V$. Then the matrices $\pi(g) = \left( a_{ij}^\pi(g) \right)$ are unitary matrices. Hence $\overline{a_{ij}^\pi} = a_{ji}^\pi(g^{-1})$.

There is a standard scalar product on $\C[G]$ defined by
$$
(f_1,f_2) = \frac 1{\lvert G \rvert} \sum_{g \in G} f_1(g) \overline{f_2(g)}.
$$

Then the orthogonality relations take the form:

\begin{thm}
 For every irreducible representation $\pi$ choose an invariant scalar product and an orthonormal basis $\{e_1^\pi, \ldots, e_n^{\dim \pi}$ and corresponding matrix coeffecients $a_{ij}^\pi$. Then the functions $a_{ij}^\pi$ are mutually orthogonal with
$$
\left (a_{ij}^\pi, a_{ij}^\pi\right) = \frac{1}{\dim \pi}.
$$
\end{thm}

\subsection{Characters of a representation}

Let $(\pi,V)$ be a representation. 

The function $\chi_\pi:G \to \C$ defined by $\tr \pi(g)$ is called the \textbf{character of $\pi$}.

We say that a function $f:G \to \C$ is \textbf{central} if $f(hgh^{-1})=f(g)$ for all $h,g \in G$. Note that characters are central. Also note that $\chi_\pi(e)=\dim \pi$. 

\begin{thm}
 The characters $\chi_\pi$ (for $[\pi] \in \widehat G$) form an orthonormal basis for the space of central functions on $G$.
\end{thm}
\begin{proof}
 We have
$$
\chi_\pi(g) = \sum_{i=1}^{\dim \pi} a_{ii}^\pi(g),
$$
and the orthogonality relations show that $\{ \chi_\pi \mid [\pi] \in \widehat G \}$ is an orthonormal system:
$$
(\chi_\pi, \chi_\pi) = \sum_{ij}^{\dim \pi} (a_{ii}^\pi, a_{jj}^\pi) = 
\sum_{i=1}^{\dim \pi} \frac{1}{\dim \pi} = 1.
$$

Thus we need to show that the characters \emph{span} the space of central functions. Consider the projection $P$ from $\C[G]$ to the space of central functions defined by
$$
f \mapsto (Pf)(g) = \frac{1}{\lvert G \rvert }\sum_{h \in G} f(hgh^{-1}).
$$
It is obviously a projection. Now consider $P(a_{ij})(g)$ (we skip the upper index $\pi$). Then this is equal to
$$
\frac{1}{\lvert G \rvert} \sum_h a_{ij}(hgh^{-1}) = \frac{1}{\lvert G \rvert} \sum_{h \in G} \sum_k \sum_l a_{ik}(h) a_{kl}(g) a_{lj}(h^{-1}).
$$

\end{proof}


\appendix
\section{Exercises}

\subsection{Lecture 1}
\begin{exc}
Suppose $V_1 \oplus \ldots \oplus V_r \sim W_1 \oplus \cdots \oplus W_s$ as representations and that the $V_i,W_i$ are irreducible. Show that $n=m$ and there exists $\rho \in S_r$ such that $V_i \sim W_{\rho(i)}$ for all $i$.
\end{exc}
\begin{sol}
First note a lemma: If $V \oplus W \sim V' \oplus W'$ and $V \sim V'$, then $W \sim W'$. This follows from the five-lemma.

Now consider the composition $V_1 \hookrightarrow V_1 \oplus \cdots \oplus V_r  \to W_1 \oplus \cdots \oplus W_s \to W_i$. This has to be non-zero for at least one $i$. Hence $V_1 \sim W_i$ for some $i$. By rearring, we are in the situation of the lemma above. Hence, inductively, if $r \leq s$, we find $0 \sim W_{r+1} \oplus \cdots \oplus W_s$, which is impossible. Similarly for $s \leq r$. Hence $r=s$ and we conclude.
\end{sol}

\begin{exc}
 Let $\hat G$ denote the Pontryagin dual of $G$. Then, for any finite abelian group $G$, we have $G \simeq \hat G$.
\end{exc}
\begin{sol}
We first do this when $G= \Z/n$ for some $n \geq 0$. Let $\varphi:\Z/n \to \C^\ast$ be a character. Then $\phi(1)=z$ for some $z$, but $\phi(n)=\phi(0)=z^n=1$, so $z$ must be a $n$'th root of unity.

Realize $\Z/n$ as the $n$th roots of unity. Then we can define a homomorphism $\widehat {\Z/n} \to \Z/n$ by $\varphi \mapsto \varphi(1)$. Similarly, we can define an inverse map by sending $e^{2\pi i/n}$  to the character $m \mapsto e^{2\pi i m /n}$. These are inverses.

Now, every finite abelian group is a product of these groups. So it remains to show (by induction) that if $G,H$ are two finite abelian groups, then $\widehat {G \times H} \simeq \widehat G \times \widehat H$. The inclusion maps $G \to G \times H$ and $H \to G \times H$ induces a map $\widehat G \times \widehat H \to \widehat{G \times H}$ by $(\varphi_1, \varphi_2) \mapsto ((g,h) \mapsto \varphi_1(g)\varphi_2(h))$.

It is easy to see that this map is injective. To see that it is surjective, let $\varphi:G \times H \to \C$ be a character. Write $\varphi$ as $gh \mapsto \varphi(gh)$. Then we can define characters on $G,H$ by $g \mapsto \varphi(g \cdot 1)$ which maps to $\varphi$. Ok.
\end{sol}

\begin{exc}
Show that the $S$ defined in the proof of Theorem \eqref{thmdensity} lies in $\Theta(G)''$.
\end{exc}
\begin{sol}
 This is, I think, definition-hunting. DETAILS COME LATER
\end{sol}

\begin{exc}
  \begin{enumerate}
  \item Check that indeed 
$$
\langle v, w \rangle := \frac{1}{\langle G \rangle} \sum_{g \in G} \langle \pi(g) v, \pi(g) w \rangle'
$$
is an invariant Hermitian scalar product.
\item Show that if $\pi$ is irreducible, then an invariant scalar product is unique up to a factor.
  \end{enumerate}
\end{exc}

\begin{sol}
i). Invariant means that $\langle \pi(h) v, \pi(h) w \rangle = \langle v, w \rangle $. This is clear from the definitions, since if $g \in G$ ranges over all of $G$, then so does $gh$.

The only (slightly) nontrivial thing to check is that $\langle,\rangle$ is positive definite. But this is so.


ii) If $\langle,\rangle$ is invariant, then it is an element of $\Hom_G(V \otimes V, \C)$. This is canonically isomorphism to $\Hom_G(V \otimes, V^\ast)$. If we can show that $V$ and $V^\ast$ are isomorphic as representations, then we are done by Schur's lemma. 

But we are given an inner product $\langle , \rangle$. We can define a map $V \to V^\ast$ by sending $v \in V$ to the function $w \mapsto \langle v, w \rangle$. This is clearly a linear isomorphism, and it is also a map of representations. Recall that the action of $G$ on $V^\ast$ is defined by $\pi^\ast(g) \varphi (v) = \varphi(g^{-1} v)$. Then in the diagram

$$
\xymatrix{
V \ar[r] \ar[d]^{\cdot g} & V^\ast \ar[d]^{\cdot g} \\
V \ar[r]  & V^\ast 
}
$$
we want $\langle gv, w \rangle$ to be equal to $\langle v, g^{-1} w \rangle$. But this is true since $\langle ,\rangle$ is invariant:
$$
\langle gv, w \rangle = \langle gv g g^{-1} w \rangle = \langle v, g^{-1}w \rangle.
$$
Hence $V$ and $V^\ast$ are isomorphic as representations and then $\Hom_G(V,V^\ast)$ (space of bilinear forms) is one-dimensional. 
\end{sol}

\section{Some worked examples}

\subsection{The representation ring of $S_3$}

We want to explicitly compute the representation ring of $S_3$.

First we find all irreducible representations. The first one is the trivial representation $\epsilon:S_3 \to \C$. We also have the \emph{sign} representation given by $g \mapsto  sgn(g) \in \C $. Both of these are one-dimensional representations.

$S_3$ have a natural action on $\R^3$ given by permuting the basis vectors. But it acts trivially on the subspace spanned by $e_1+e_2+e_3$, hence $\R^3$ decomposes as $\epsilon \oplus V$, where $V$ is some $2$-dimensional representation. It is irreducible: if not, any $v \in V$ would be sent to a scalar multiple of itself, but this is not the case. This representation is called the \textbf{standard representation} of $S_3$. We have also now found all representations of $S_3$, since $1^2+1^2+2^2=6$. 

Thus the representation ring $R(S_3)$ is $\Z[A,S]$ modulo some relations to be found. Here $A$ is the alternating representation and $S$ is the standard representation. The trivial representation is $1$. It is easy to see that $A \otimes A \sim \epsilon$, so $A^2=1 \in R(S_3)$. The representation $S \otimes S$ is $4$-dimensional. To compute how it decomposes, we use character theory.

Recall that characters are class functions on $G$, that is, they only depend on the conjugacy classes of $G$. So we write a character table:

\begin{center}
\begin{tabular}{ r | c c  c }
 & $e$ & $\tau$ & $\sigma$ \\
\hline
$\epsilon$ & 1 & 1 & 1  \\
$A$ & 1 & 1 & -1 \\
$S$ & 2 & -1 & 0 \\
\end{tabular}
\end{center}

To compute the character of the standard representation, we first note that it is, as a vector space given by $\R^3/(1,1,1)$. A basis is then given by the images of $e_1,e_2$. Let $\tau$ be the transposition $(123)$, sending $e_i$ to $e_{i+1}$. Let $\sigma$ be reflection fixing $e_1$ and exchanging $e_2$ and $e_3$. In this basis that means $e_2$ is sent to $-e_1-e_2$. Writing up the corresponding matrices lets us find the value of the character.

Now one can compute by hand (or use a result on characters), that the character of $S \otimes S$ is given by $\chi_S \cdot \chi_S$, so that its entry in the character table is $(4,1,0)$. If $S \otimes S = V_1 \oplus V_2$, then $\chi_S = \chi_{V_1} + \chi_{V_2}$. Using also that the characters are linearly independent, we see that the only option is $S \otimes S \sim \epsilon \oplus A \oplus S$.

Hence $S^2=1+A+S$ in the representation ring. Similarly, we find that $AS=S$ in the representation ring. All in all
$$
R(S_3) = \Z[A,S]/(A^2-1,S^2-1-A-S,AS-S).
$$


\end{document}