\documentclass[11pt, english]{article}
%\documentclass[12pt]{article}  
%\usepackage[papersize={108mm,144mm},margin=2mm]{geometry}  
\sloppy 
%\pagestyle{empty} 
%\usepackage[scaled]{helvet}
%\renewcommand{\familydefault}{\sfdefault}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}   % S P R A A K

\usepackage{amssymb, amsmath, amsthm, amssymb} % symboler, osv
\usepackage{mathrsfs,calligra}
\usepackage{url}
\usepackage{thmtools}
\usepackage{enumerate}  % lister $
\usepackage{float}
\usepackage{tikz}

\usepackage{young} 
\usepackage{youngtab} 

\usepackage[all]{xy}   % for comm.diagram
\usepackage{wrapfig} % for float right
\usepackage[colorlinks=true]{hyperref}
\usepackage{mystyle} % stilfilen      


\title{Representation theory}
\author{Fredrik Meyer} 
\date{}
\begin{document}
\maketitle

\abstract{These are notes from the course MAT4270 on representation theory, autumn 2015. The lectures were held by Sergey Neshyevey. The notes are mine. The first half is about representations of finite groups, the second  half about representations of compact Lie groups.}
\section{Lecture 1}

From now on $G$ is always a \emph{finite group} and $V$ a finite-dimensional vector space over the complex number. Most results will hold over any algebraically closed field of characteristic zero.

\subsection{Motivating example}

In 1896 Dedekind made the following observation. Let $\C[x_g \mid g \in G]$ be the free $\C$-algebra with basis the elements of $G$. Then one can form the following polynomial:
\[
P_G(x_{\rho_1},\ldots,x_{\rho_n}) = \det \left( (x_{\rho_i g_j})_{i,j=1}^n \right).
\]

Note that the matrix is just the multiplication table for the group $G$. The problem is to decompose $P_G$ into irreducible polynomials. 

\begin{example}
Let $G=S_3$. Then $G$ is generated by two elements $r$ and $s$ with the relation $srs=r^2$. If we write the elements of $G$ as $\{e,r,r^2,s,sr,sr^2\}$, then the multiplication table looks like
 $$ \bgroup\begin{pmatrix}
e&     r&     r^2&     s&     sr&     sr^2\\
     r&    r^2&     e&    sr^2&     s&     sr\\ 
    r^2&     e&     r&     sr&     sr^2&     s\\ 
    s&     sr&    sr^2&     e&     r&    r^2\\ 
    sr&     sr^2&     s&    r^2&    e&     r\\
  sr^2&     s&   sr&     r&    r^2&     e\\
     \end{pmatrix}\egroup.$$
The determinant is quite long, so I won't write it out. Suffice it to say it is a degree $6$ polynomial with 146 terms. Using a computer algebra system such as \verb|Macaulay2|, one can decompose it. It decomposes into three factors: one quadratic and two linear. They are the following (we change notation to avoid confusion about exponents):
\[
x_e+x_r+x_{r^2}+x_s+x_{sr}+x_{sr^2}
\]
and 
\[
x_e+x_r+x_{r^2}-x_s-x_{sr}-x_{sr^2}
\]
and 
\[
x_e^2-x_ex_r+x_{r^2}-x_e x_{r^2}-x_r x_{r^2} + x_{r^2}^2-x_s^2+x_s x_{sr} - x_{sr^2}^2 + x_s x_{sr^2}-x_{sr^2}^2-x_{sr^2}^2.
\]
We will see later that the first factor corresponds to the trivial representation, the second to the alternating representation, and the third is the so-called standard represenation of $G$.
\end{example}
Frobenius proved the following theorem:
\begin{thm}
  Let $P_G= \prod_{i=1}^r P_i^{m_i}$ be the decomposition of $P_G$ into irreducibles. Then
  \begin{enumerate}
  \item $m_i=\deg P_i$ for every $i$.
\item $r$ is the number of conjugacy classes in $G$. 
  \end{enumerate}
In particular, since $r=\lvert G \rvert $ if and only if $G$ is abelian, $P_G$ decomposes into linear factors if and only if $G$ is abelian.
\end{thm}

In trying to prove the above theorem, Frobenius had to develop representation theory.

\subsection{Representations}

A \textbf{representation of $G$ on $V$} is a homomorphism $\pi:G \to \GL(V)$. We will denote a representation interchangably by $\pi, (\pi,V), V_\pi$ or $V$, depending upon the situation.

This means that a representation is a \emph{linear} action of $G$ on $V$.

\begin{example}
  The trivial representation $\epsilon$ of any group is given by letting $V= \C$ and $\epsilon(g)=e$ for all $g \in G$.
\end{example}

\begin{example}[Left regular representation]
Let $\C[G]$ be the space of functions on $G$. It is a finite-dimensional vector space under pointwise addition. Define $\lambda:G \to \GL(\C[G])$ by
\[
g \mapsto \left(f \mapsto (h \mapsto f(g^{-1}h)) \right)
\]
This vector space have a basis consisting of the characteristic functions $e_g$ for $g \in G$. On these elements on sees that the action is given by $g \cdot e_h = e_{gh}$. 

\end{example}
\begin{example}
 Similarly, one has the \textbf{permutation representation}. Let $X$ be a $G$-set, i.e. a set on which $G$ acts. Then one forms the space $\C[X]$ of $X$-valued functions. It has a basis $e_x$ of characteristic functions, and the action of $G$ on $\C[X]$ is given by $g e_x = e_{gx}$. 
\end{example}

The notion of isomorphism is not surprising. An \textbf{equivalence} of representations $(\pi,V)$ and $(\theta,W)$ is given by a vector space isomorphism $T:V \to W$ such that $T(g \cdot v) = g \cdot T(v)$ for all $g \in G$.

In case $T:V \to W$ is not an isomorphism, we say that $T$ is an \textbf{intertwiner} of $V$ and $W$. The set of intertwiners is denoted by $\Mor(\pi,\theta)$ or $\Hom_G(V,W)$.

A subspace $W \subset V$ is \textbf{invariant} if $g \cdot W \subset W$ for all $g \in G$. Letting $\theta(g) = \restr{\pi(g)}{W}$, we get another representation of $G$, called a \textbf{subrepresentation} of $G$. We write $\restr{\pi}{W}$ for $\theta$. 

If we have two representation $(\pi,V)$ and $(\pi',V')$, we can form the \textbf{direct sum representation} by letting $g \in G$ act on $V \oplus V'$ componentwise. Note that $\pi$ is a subrepresentation of $V \oplus V'$.

\begin{prop}[Mascke's theorem]
\label{propmaschke}
Let $(\pi,V)$ be a representation of $G$ and $W \subset V$ an invariant subspace. Then there exists a complementary invariant subspace $W^\perp$. That is, $W$ is also invariant and such that $V = W \oplus W^\perp$.
\end{prop}

\begin{proof}
  We prove this by ``averaging''. Let $P:V \to W$ be \emph{any} projection from $V$ to $W$. Then define 
\[
\Pi(v) = \frac 1{\lvert G \rvert} \sum_{g \in G} g P(g^{-1}v).
\]
This is a $G$-linear morphism, because
\begin{eqnarray*}
\Pi(h\cdot v) &= \frac 1{\lvert G \rvert} \sum_{g \in G} g P(g^{-1} h \cdot v) \\  
&=  \frac 1{\lvert G \rvert} \sum_{g \in G} g P((h^{-1}g) \cdot v) \\
&=  \frac h{\lvert G \rvert} \sum_{g \in G} h^{-1}g P((h^{-1}g) \cdot v).
\end{eqnarray*}
It is also surjective, since if $v \in W$, then clearly $\Pi(v)=v$. Hence $\Pi$ is a $G$-linear surjection onto $W$. Then it is clear that $\ker \Pi$ is a $G$-invariant subspace of $V$ complementary to $W$.
\end{proof}

We say that a representation is \textbf{irreducible} if it has no proper invariant subspaces. A representation is \textbf{completely reducible} if it decomposes into a direct sum of irreducible representations.

\begin{example}
  Let $G = (\R,+)$ act on $\R^2$ by the matrices
\[
\begin{pmatrix}
1 & a \\ 
0 & 1
\end{pmatrix}.
\]
This leaves the $x$-axis fixed, so the representation is not irreducible. But it does not split into irreducible representations, since there is no complementary subspaces.
\end{example}

However, if $G$ is finite (or \textbf{compact}, as we shall see later), things are nicer:

\begin{thm}
 Any finitely-dimensional representation of a finite group $G$ is completely reducible.
\end{thm}
The proof follows directly from Maschke's theorem \eqref{propmaschke}.  

We next prove Schur's lemma, which although has a very simple proof, has great consequences.

\begin{prop}[Schur's lemma]
Let $(V,\pi)$ and $(W,\theta)$ be irreducible representations. Then
\begin{enumerate}
\item If $\pi \not \sim \theta$, then $\Hom_G(V,W)=0$.
\item If $\pi \sim \theta$, then $\Hom_G(V,W)$ is $1$-dimensional. 
\end{enumerate}
\end{prop}
\begin{proof}
Both the kernel and the image of a morphism of representations is a representation. But since $V,W$ are irreducible, it follows that $\ker \varphi = 0$ or $\ker \varphi  = V$ for any $\varphi:V \to W$. This proves i). 

Now suppose $\Pi:V \to W$ is an equivalence of representations. Let $\varphi \in \Hom_G(V,W)$. Then $\varphi$ must be an equivalence as well, since the neither the kernel nor image can be non-zero. Consider $T=\varphi^{-1} \circ \Pi: V \to V$. This is a linear map, and since we work over $\C$, it has an eigenvalue $\lambda$. Now consider $T-\lambda \id_V$. This has non-zero invariant kernel, hence $T-\lambda \id_V=0$. 
\end{proof}

\begin{prop}
 If $G$ is abelian, then any irreducible representation of $G$ is 1-dimensional.
\end{prop}
\begin{proof}
Each $g \in G$ gives a map $\pi(g):V \to V \in \End(V)$. This is even an intertwining map, because $\pi(g)\pi(h)=\pi(gh)=\pi(hg)=\pi(h)\pi(g)$.

If $\pi$ is not trivial, by Schur's lemma, this map is just multiplication by some constant. But any 1-dimensional subspace of $V$ is invariant under this action, so $V$ must be 1-dimensional in order to be irreducible.
\end{proof}

Thus, up to equivalence, every irreducible representation of a finite abelian group is just a homomorphism $\chi:G \to \C$. But since $G$ is finite, this actually maps into $\mathbb T := \{ z \in \C \mid \lvert z \rvert = 1 \}$. Such maps are called \textbf{characters} of $G$. Denote by $\hat G$ the \emph{set} of irreducible representations of $G$. 

We call the $\hat G$ the \textbf{Pontryagin dual} of $G$. It is an abelian group under pointwise multiplication. See Exercise 2 for more on this.

\begin{remark}
  If $G$ is non-abelian, there will always exist irreducible representations of dimension $\geq 2$. This follows because the regular representation $G \to \GL \left( \C[G] \right)$ is injective.
\end{remark}

\section{Lecture 2 - Density theorems}

\subsection{Density theorems}

Let $(V,\pi)$ be an irreducible representation. The set of operators $\pi(g)$ for $g \in G$ is quite large. By definition, if $x \neq 0$, then
$$
V = \mathrm{Span} \{ \pi(g)x \mid g \in G \}.
$$
By Schur's lemma, we also know that 

$$
\End(\pi) = \{ T \in \End(V) \mid T\pi(g) = \pi(g) T \, \forall \, g \in G \} = \C \cdot \id_V.
$$

\begin{thm}[The density theorem]
\label{thmdensity}
 Assume $\pi_1,\ldots,\pi_n$ are pairwise inequivalent irreducible representations, with $V_i = V_{\pi_i}$. Consider the direct sum representation $V_1 \oplus \ldots \oplus V_n$.

Then
\[ 
\Span {\pi(G)} = \End(V_1) \oplus \ldots \oplus \End(V_2).
\]
\end{thm}
\begin{proof}[Proof/exercise:]
We deduce the first theorem from the second: First break $(V,\pi)$ into irreducible representations $V_i$. Then it follows directly from Schur's lemma that $\pi(G)' = \C \id_{V_1} \oplus \ldots \oplus \C \id_{V_n}$. 

Now, the elements of $\C \id_{V_1} \oplus \ldots \oplus \C \id_{V_2}$ are block diagonal matrices. It is an easy exercise with matrices to see that the commutator of this set is just
$$
\End(V_1) \oplus \ldots \oplus \End(V_2).
$$
\end{proof}

First we need some notation. Let $V$ be some vector space and $X \subset \End(V)$ a subset of the endomorphisms of $V$. Let 
\[
X' \stackrel{\Delta}{=}  \{ T \in \End(V) \mid TS = ST \text{ for all } S \in X \}.
\]
We call $X'$ the \textbf{commutant} of $X$. Thus if $(V,\pi)$ is a representation, then by definition:
\[
\End(\pi) = \pi(G)'.
\]

\begin{thm} 
 For any finite-dimensional representation $(V,\pi)$ we have 
\[
\pi(G)'' = \Span{\pi(G)}.
\]
\end{thm}
\begin{proof}
Let $T \in \pi(G)''$. Let $x_1,\ldots,x_n$ be a basis of $V$. Consider the representation $\theta = \pi \oplus \ldots \oplus \pi$ (n times) on $W = \oplus_{i=1}^n V$. Consider $x=(x_1,\ldots,x_n) \in W$ and the operator $S = T \oplus \ldots \oplus T$ on $W$. 

It is an exercise to show that $S \in \Theta(G)''$.

Now $\Span{\theta (G) x }$ is an invariant subspace of $W$. Then there exists an invariant complementary subspace. Let $P:W \to \Span{\theta(G)x}$ be the projection with kernel that invariant subspace, so that $P \in \Theta(G)'$ (that is, $P$ is a $G$-morphism). Then
$$
PSx = SPx = Sx
$$
since $P x \in \Span{\theta(G)x}$. Hence $Sx \in \Span { \theta(G)x }$ as well. This means that there exist $\alpha_g \in \C$ such that
$$
Sx = \sum_g \alpha_g \theta(g)x
$$
This is the same as saying that
$$
Tx_i = \sum_g \alpha_g \pi(g)x_i,
$$
hence $T = \sum \alpha \pi(g)$ .
\end{proof}


\subsection{Orthogonality relations}

Let $(V,\pi)$ be a representation and let $\rho \in V^\ast = \Hom(V,\C)$. The functions $\alpha_{\rho,x}^\pi$ on $G$ defined by $\alpha_{\rho,x}^\pi(g)=\rho(\pi(g)x)$ is called a \textbf{matrix coefficient} of $\pi$. If we fix a basis $e_1,\ldots,e_n$ of $V$ and consider the dual basis $e_1^\ast,\ldots, e_n^\ast$ of $V^\ast$, then we write $\alpha_{ij}^\pi$ instead of $\alpha_{e_i^\ast,e_j}^\pi$.

In the basis $e_1,\ldots,e_n$ we have
$$
\pi(g) = \left( \alpha_{ij}^\pi(g) \right)_{ij}
$$

\begin{thm}
 We have:
 \begin{enumerate}
 \item If $\pi$ and $\theta$ are inequivalent irreducible representations, then
\[
\frac 1{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi(g) \alpha_{\rho,y}^\theta(g^{-1}) = 0
\]
for all $f \in V_\pi^\ast$, $\rho \in V_\theta^\ast$, $x \in V_\pi$ and $y \in V_\theta$.
\item If $\pi$ is irreducible, then
\[
\frac{1}{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi(g) \alpha_{\rho,y}^\pi (g^{-1}) = \frac{f(x) \rho(y)}{\dim \pi}.
\]
 \end{enumerate}
\end{thm}
\begin{proof}
It is the avering trick again. First observe that if $T:V_\theta \to V_\pi$ is any linear operator, then 
\[
S = \frac{1}{\lvert G \rvert} \sum_{g \in G} \pi(g) T \theta(g^{-1}) 
\]
is in $\Hom_G(\theta,\pi)$ by averaging. Thus, since $\pi$ and $\theta$ are in-equivalent, it follows from Schur's lemma that this must be zero.

Now let $T(v) = \rho(v)x$. This is a linear operator. Then
$$
0 = f(Sy) = \frac{1}{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi (g) \alpha_{\rho,y}^\theta(g^{-1}).
$$
This proves part $1$.

Now suppose $\pi=\theta$. Then $S \in \End(\pi) = \C \cdot \id_V$. Thus $S = \alpha \cdot \id_V$. Taking traces on both sides, we get $\alpha = Tr T/\dim \pi$ (note that $T$ and $S$ have the same trace).

Then
$$
\frac 1{\lvert G \rvert} \sum_g \alpha_{f,x}^\pi(g) \alpha_{\rho,y}^\pi(g^{-1}) = f(S(y)) = f(y) \frac{Tr T}{\dim \pi}
$$
(make this nicer some time)
\end{proof}

Instead of writing expressions like $\sum_g \alpha_g \pi(g)$ it is convenient to introduce the following notation. Define the \textbf{convolution} of two functions $f_1,f_2 \in \C[G]$ by
$$
(f_1 \ast f_2)(g) = \sum_{g=g_1g_2} f_1(g_1)f_2(g_2) = \sum_{h \in G} f_1(h)f_2(h^{-1}g).
$$
We have $\delta_{g_1} \ast \delta_{g_2} = \delta_{g_1g_2}$ (easy check!). The convolution product is associative and makes $\C[G]$ into an algebra, called the \textbf{group algebra} of $G$. 

Given a representation $\pi:G \to \GL(V)$ we can define an algebra homomorphism $\C[G] \to \End(V)$ by $\pi(f) = \sum_{g \in G} f(g) \pi(g)$. Thus $V$ becomes a left $\C[G]$-module. Conversely, given any united algebra homomorphism $\pi:\C[G] \to \End(V)$, we get a representation by $g \mapsto \pi(\delta_g)$. Thus we have a correspondence between representations of $G$ and left $\C[G]$-modules. Using these notions, the Density Theorem (Theorem \ref{thmdensity}) becomes $\pi(\C[G]) = \oplus_i \End(V_i)$.

\begin{thm}
Let $\hat G$ be the set of equivalence classes of irreducible representations of $G$. Then $\hat G$ is finite and $\sum_{[\pi] \in \hat G} (\dim \pi)^2 = \lvert G \rvert$. Furthermore, we have
$$
\lambda \sim  \bigoplus_{[\pi] \in \hat G} \pi^{\oplus \dim \pi}.
$$
Here $\lambda$ is the left regular representation of $G$.
\end{thm}
Proof to come later.

\section{Lecture 3 - More on orthogonality}

Where does the name ``orthogonality relations'' come from? We'll see now.

First of all, note that if $V_\pi$ is a representation of a finite group $G$, and $\langle,\rangle'$ is \emph{any} Hermitian scalar product on $V_\pi$, then 
$$
\langle v, w \rangle := \frac{1}{\langle G \rangle} \sum_{g \in G} \langle \pi(g) v, \pi(g) w \rangle'
$$
is another Hermitian scalar product on $V_\pi$, making the representation \textbf{unitary}.

If $\pi$ is any unitary representation, choose an orthonormal basis $e_1,\ldots,e_n \in V$. Then the matrices $\pi(g) = \left( a_{ij}^\pi(g) \right)$ are unitary matrices. Hence $\overline{a_{ij}^\pi} = a_{ji}^\pi(g^{-1})$.

There is a standard scalar product on $\C[G]$ defined by
$$
(f_1,f_2) = \frac 1{\lvert G \rvert} \sum_{g \in G} f_1(g) \overline{f_2(g)}.
$$

Then the orthogonality relations take the form:

\begin{thm}
 For every irreducible representation $\pi$ choose an invariant scalar product and an orthonormal basis $\{e_1^\pi, \ldots, e_n^{\dim \pi}\}$ and corresponding matrix coeffecients $a_{ij}^\pi$. Then the functions $a_{ij}^\pi$ are mutually orthogonal with
$$
\left (a_{ij}^\pi, a_{ij}^\pi\right) = \frac{1}{\dim \pi}.
$$
\end{thm}

\subsection{Characters of a representation}

Let $(\pi,V)$ be a representation. 

The function $\chi_\pi:G \to \C$ defined by $\tr \pi(g)$ is called the \textbf{character of $\pi$}.

We say that a function $f:G \to \C$ is \textbf{central} if $f(hgh^{-1})=f(g)$ for all $h,g \in G$. Note that characters are central. Also note that $\chi_\pi(e)=\dim \pi$. 

\begin{thm}
 The characters $\chi_\pi$ (for $[\pi] \in \widehat G$) form an orthonormal basis for the space of central functions on $G$.
\end{thm}
\begin{proof}
 We have
$$
\chi_\pi(g) = \sum_{i=1}^{\dim \pi} a_{ii}^\pi(g),
$$
and the orthogonality relations show that $\{ \chi_\pi \mid [\pi] \in \widehat G \}$ is an orthonormal system:
$$
(\chi_\pi, \chi_\pi) = \sum_{ij}^{\dim \pi} (a_{ii}^\pi, a_{jj}^\pi) = 
\sum_{i=1}^{\dim \pi} \frac{1}{\dim \pi} = 1.
$$

Thus we need to show that the characters \emph{span} the space of central functions. Consider the projection $P$ from $\C[G]$ to the space of central functions defined by
$$
f \mapsto (Pf)(g) = \frac{1}{\lvert G \rvert }\sum_{h \in G} f(hgh^{-1}).
$$
It is obviously a projection. Now consider $P(a_{ij})(g)$ (we skip the upper index $\pi$). Then this is equal to
$$
\frac{1}{\lvert G \rvert} \sum_h a_{ij}(hgh^{-1}) = \frac{1}{\lvert G \rvert} \sum_{h \in G} \sum_k \sum_l a_{ik}(h) a_{kl}(g) a_{lj}(h^{-1}).
$$
But after using that the orthogonality relations, this simplifies to
$$
\frac{1}{\dim \pi} \delta_{ij} \chi_\pi(g).
$$
But the $a_{ij}$ constitute a basis of $\C[G]$. [[HM!? TRUE??]]
\end{proof}

[[some comment about why the last claim is true...]]

\begin{corr}
Let $c(G)$ be the number of conjugacy classes in $G$. We have
$$
\lvert \widehat G \rvert = c(G).
$$
\end{corr}
\begin{proof}
 The left hand side is equal to $\dim_\C \text{span}_{\pi \in \widehat G} \{ \chi_\pi \}$. But this is, as just proved, equal to the dimension of the space of central functions.
\end{proof}

\begin{corr}
 Two finite-dimensional representations $\pi$ and $\theta$ are equivalent if and only if $\chi_\pi = \chi_\theta$.
\end{corr}
\begin{proof}
  You can read off the multiplicities from the character.
\end{proof}

\begin{corr}
 For any $[\pi] \in \widehat G$, the multiplicity of $\pi$ in the regular representation $\lambda$ equals $\dim \pi$.
\end{corr}
\begin{proof}
 We are interested in $(\chi_\lambda, \chi_\pi)$. But note that
$$
\chi_\lambda(g) = \sum_{h \in G} \tr ( \delta_h \mapsto \delta_{hg} ) = \begin{cases} 0 & \text{ if } g \neq e \\
\lvert G \rvert & \text{ if } g = e.
\end{cases}
$$
Then $(\chi_\lambda,\chi_\pi) = \frac{1}{\lvert G \rvert} \chi_\lambda(e) \cdot \overline{\chi_\pi(e)} = \dim \pi$.
\end{proof}

\subsection{Isotypic component and can. decomposition of $V$}

[[isotypic component ...]]

\section{Lecture 4 - The Frobenius determinant problem}

Let $G$ be a finite group and $\C[x_g \mid g \in G]$ the algebra on generators indexed by $g \in G$. Then one can form the following determinant:
$$
P_G  = \det \left( (x_{gh})_{gh} \right).
$$
It is the determinant of the multiplication table of $G$. The problem is to decompose $P_G$ into irreducible polynomials.

It is conventient to instead work with $\widetilde{P_G}=\det( {(x_{gh^{-1}})}_{gh})$. This has the same determinant as $P_G$ up to multiplication by $\pm 1$ since this just corresponds to permuting some of rows of the multiplication table.

Now here comes the \emph{key} observation: the matrix $(x_{gh^{-1}})$ is the matrix of the operator 
$$
\sum_{g \in G} x_g \lambda(g)
$$
in the basis $\delta_g \in \C[G]$. Here you are supposed to view elements of $\C[x_g \mid g \in G]$ as \textbf{functions} on $G$.

That this operator actually has matrix $(x_{gh^{-1}})$ can be seen by applying the operator to basis elements:
$$
\left(\sum_{g \in G} x_g \lambda(g)\right)(\delta_h) = \sum{g \in G} x_g \delta_{gh}
$$
by definition of the left regular action. Reparametrizing this last sum by setting $g' = gh$ we get
$$
\sum_{g \in G} x_g \delta_{gh} = \sum_{g' = gh} x_{gh^{-1}} \delta_g,
$$
as wanted.

Now, the regular representation decomposes as
$$
\lambda \sim \bigoplus_{[\pi] \in \widehat G}  \pi^{\oplus \dim \pi}
$$
Hence the determinant decomposes as well (since the operator is $G$-invariant) and we get
$$
\widehat{P_G} = \prod_{[\pi] \in \widehat G} \det\left( \sum_{g \in G} x_g \pi(g) \right)^{\dim \pi}
$$

The question is now of course if we can decompose further. The answer is no:

\begin{thm}[Frobenius]
The polynomials $\det\left(\sum_{g \in G} x_g \pi(g) \right)$ ($[\pi] \in \widehat G$) are irreducible and no two of them are associates.
\end{thm}

We begin with a lemma:
\begin{lemma}
 The polynomial $p=\det (x_{ij})$ is irreducible.
\end{lemma}

\begin{proof}
  To come.
\end{proof}

\begin{proof}[Proof of theorem]
  
Suppose that $P_\pi=p_1p_2$. The polynomials $p_1,p_2$ are homogeneous. Fix a basis $e_1,\ldots,e_n$ in $V_\pi$. Consider the corresponding matrix units $m_{ij}$ defined by
$$
m_{ij} e_k = \delta_{jk}e_i.
$$
Since $\pi(\C[G]) = \End(V_\pi)$ by the density theorem,we can find $a_{ij}(g) \in \C$ such that
$$
m_{ij} = \sum_{g \in G} \alpha_{ij}(g) \pi(g).
$$

Consider the ring map $\C[x_g \mid g \in G] \to \C[x_{ij}]$ defined by
$$
x_g \mapsto \sum_{ij} \alpha_{ij}(g) x_{ij}.
$$

Under this map the operator $\widehat{P_G}$ becomes
$$
\sum_{g \in G} x_g \pi(g) = \sum_{g \in G} \sum_{i,j} \alpha_{ij}(g) x_{ij} \pi(g) = \sum_{ij} m_{ij} x_{ij} = (x_{ij}).
$$

Since the determinant is functorial with respect to ring maps, a decomposition $P_G=p_1p_2$ would induce a decomposition of $\det (x_{ij})$, which was just proved to be impossible.

We still have to check that no two of the determinants are equal (up to associates). But note that $\restr{P_\pi}{x_g = 0, g \neq e}=x_e^{\dim \pi}$. So we can recover the dimension of $\pi$ from the determinant. Also note that if we fix $g \in G$, then
$$
\restr{P_\pi}{x_e=1, x_h =0 \text{ for } h \neq g} = \det(1+x_g\pi(g))=1+\tr \pi(g)x_g + h.o.t.
$$,
so we can recover the trace as well. But a representation is determined by its character, so if the polynomials are equal, then the representations are equivalent. The converse is similar.
\end{proof}

\subsection{Two constructions on representations}

Recall that the tensor product of $V$ and $W$ have a basis $v_i \otimes v_j$. Hence $\dim_\C V \otimes W = \dim_\C V \cdot \dim_\C W$.

Assume $(V,\pi)$ is a finite-dimensional representation and consider $V^\ast = \Hom_\C(V,\C)$. Then we define the \textbf{contragradient representation} $\pi^c$ to be the representation of the dual space defined by 
$$
(\pi(g)f)(v) = f(\pi(g^{-1})v).
$$

If $v_1,\ldots,v_n$ is a basis for $V$ and $\pi(g)=(a_{ij}(g))$, then in this basis 
$$
\pi^c(g) = (a_{ji}(g^{-1}))_{ij}.
$$
In particular, the character  $\chi_{\pi^c}(g)=\chi_\pi(g^{-1})=\overline{\chi_\pi(g)}$. 

Also, we can define the \textbf{tensor product of two representations} $\pi$ and $\theta$ by $(\pi \otimes \theta)(g)(v \otimes w) = \pi(g)v \otimes \theta(g)w$. 

See the exercises for some properties.

Also: $\Hom(U, W \otimes V^\ast)= \Hom(U \otimes V, W)$. 

Frobenius reciprocity:
$$
\Mor(\pi, \eta \otimes \theta^c) \simeq \Mor(\pi \otimes \theta, \eta).
$$

Denote by $R(G)$ the abelian group generated by classes $[\pi] \in \widehat G$ of finite-dimensional representations and relations $[\pi]+[\pi'] = [\pi \oplus \pi']$.  Then it is an exercise to show that $R(G)$ is a free abelian group with basis $[\pi] \in \widehat G$.

Via the tensor product we can form a product on $R(G)$, making it into a ring.


\section{Lecture 5 - Dimension of irreps and the symmetric group}

Recall that $$
\sum_{[\pi] \in \widehat G} (\dim \pi)^2 = \lvert G \rvert. $$

In this lecture we will prove the following theorem:

\begin{thm}
\label{thmzg}
 The dimension of any irreducible representation divides the number $\lvert G/Z(G) \rvert$, where $Z(G)$ is the center of $G$. 
\end{thm}
Later we will strengthen this and show that $Z(G)$ can be replaced by any normal abelian subgroup of $G$.

In order to prove this, we need to introduce some results from commutative algebra. Let $R$ be a unital commutative ring and $S \subset R$ a united subring. Then we say that an element $a \in R$ is \textbf{integral over $S$} if it satisfies a monic polynomial $a^n+s_1a^{n-1}+\ldots+s_{n-1}=0$ with coefficients in $S$.

We say that a complex number integral over $\Z$ is an \textbf{algebraic integer}. An integral domain $S$ is called \textbf{integrally closed} if any element in the fraction field of $S$ integral over $S$ is already in $S$. It is an easy exercise to see that $\Z$ is integrally closed (and in fact any UFD). 

\begin{lemma}
 Let $S \subset R$ be as above. Then $a \in R$ is integral over $S$ if and only if the subring $S[a]$ is a finitely-generated $S$-module.
\end{lemma}
\begin{proof}
This is Proposition 5.1 in Atiyah-MacDonald.
\end{proof}

It is an exercise to see that the set of elements of $R$ integral over $S$ actually form a ring. Alternatively, consult Corollary 5.3 in Atiyah-MacDonald.

\begin{prop}
 Assume that $\pi$ is an irreducible representation. Let $g \in G$. Let $C(g)$ be the conjugacy class of $G$. Then
 \begin{enumerate}
 \item The number $\chi_\pi(g)$ is an algebraic integer.
\item The number $\frac{\lvert C(g) \rvert}{\dim \pi} \chi_\pi(g)$ is also an algebraic integer.
 \end{enumerate}
\end{prop}
\begin{proof}
i). Since $G$ is finite, we have $g^n=e$ for some $n$. Hence all eigenvalues of $g$ are $n$th roots of unity which are algebraic integers. But $\chi_\pi(g)$ is the sum of the eigenvalues, and the set of algebraic integers form a subring of $\C$, hence $\chi_\pi(g)$ is an algebraic integer as well.

The second part is more difficult. Let $p$ be the characteristic function of $C(g)$. Then $p$ lies in the center of $\C[G]$. Consider the subring $\Z[G] \subset \C[G]$ (the \textbf{group ring} of $G$). Let $R \subset \Z[G]$ be the subring of \emph{central functions}. As $R$ is a finitely generated abelian group, any element of $R$ is integral over $\Z \cdot 1 \subset R$. 

It follows that $\pi(p)$ is integral over $\Z \cdot \id_{V_\pi} \subset \End(V_\pi)$. Since $p$ is central $\pi(p) \in \End_G(V_\pi)=\C \cdot 1$. Hence $\pi(p) = \alpha \cdot 1$ for some complex number $\alpha$. This $\alpha$ is an algebraic integer.

But now
\begin{align*}
  \alpha \cdot \dim \pi &= \tr( \alpha \cdot 1) \\
&= \tr \pi(p) \\
&= \sum_{h \in C(g)} \tr \pi(h) \\
&= \sum_{h \in C(g)} \chi_\pi(h) \\
&= \lvert C(g) \rvert \chi_\pi(g).
\end{align*}
The last equality is because characters are constant on conjugacy classes. This proves the claim.
\end{proof}

\begin{lemma}
 If $\pi$ is irreducible, then $\dim \pi \mid \lvert G \rvert$.
\end{lemma}
\begin{proof}
Recall that
$$
(\chi_\pi , \chi_\pi) = 1.
$$
This can be rewritten as
$$
\frac{\lvert G \rvert}{\dim \pi} = \sum_{g \in G} \frac{\chi_\pi(g) \chi_\pi(g^{-1})}{\dim \pi}.
$$
Now let $C(G)$ denote the set of conjugacy classes in $G$. $C$ is then a partition of $G$. Then the above sum can be rewritten as
$$
\sum_{C \in C(G)} \sum_{h \in C} \frac{\chi_\pi(h) \chi_\pi(h^{-1})}{\dim \pi} = \sum_{C \in C(G)}  \frac{\lvert C \rvert \chi_\pi(g) }{\dim \pi}  \chi_\pi(g^{-1}).
$$
The right-hand-side is a sum of product that we know are algebraic integers. They form a ring, hence the sum is an algebraic integer as well.

But the left hand side is a fraction, so we must have $\lvert G \rvert / \dim \pi \in \Z$, which is equivalent to what was to be proven.
\end{proof}

Now we can prove Theorem \ref{thmzg}. Recall that we want to show that $\dim \pi$ divides $\lvert G/Z(G) \rvert$. 

\begin{proof}
 For every $n \in \N$, consider the representation of $G^n = G \times \cdots \times G$ on $V_\pi \otimes \ldots \otimes V_\pi$ defined by $\pi_n(g_1,\ldots,g_n) = \pi_1(g_1) \otimes \ldots \otimes \pi_n(g_n)$.  It is an \textbf{exercise} to see that this representation is irreducible as well.

Now consider the subgroup $Z_n = \{ (g_1,\ldots,g_n) \in Z(G)^n \mid \prod g_i = e \}$. It is isomorphic to $Z(G)^{n-1}$. 

If $g \in Z(G)$, then by Schur's lemma, $\pi(g)$ is a scalar operator. So if $(g_1,\ldots,g_n) \in Z_n$, then $\pi(g_i)=\alpha_i \cdot 1$, hence
\[
\pi_n(g_1,\ldots,g_n) = \alpha_1,\ldots,\alpha_n \id_{V^{\otimes n}} = \id_{V^{\otimes n}}
\]
since $g_1\cdots g_n = e$. Therefore $Z_n \subset \ker \pi_n$. It follows that $\pi_n$ induces a representation of $G^n/Z_n$. Then by the previous lemma
$$
(\dim \pi)^n \mid \frac{\lvert G \rvert^n }{\lvert Z(G) \rvert ^{n-1}}
$$
That is:
$$
\left( \frac{\lvert G \rvert}{\dim \pi \lvert Z(G) \rvert } \right)^n \in \Z[\frac{1}{\lvert Z(G) \rvert}]
$$
for any $n$. But this implies that the left-hand-side is a finitely-generated $\Z$-module, hence what is inside the brackets is an algebraic integer. But is also a fraction, so it must be an integer.
\end{proof}

\section{Lecture 6 - Representation theory of $S_n$}

It is easy to understand conjugacy classes in $S_n$. Every $\sigma \in S_n$ defined a partition of $\{ 1,\ldots n\}$ into orbints of $\sigma$. Let $O_1,\ldots,O_m$ be these orbits. Assume that they are decreasing in size. Let $n_i=\lvert O_i \rvert$. These numbers $n_i$ sum to $n$.

We say that a \textbf{partition of $n$} is a decreasing sequence of integers $n_1 geq \ldots \geq n_m \geq 1$ such that $n=\sum n_i$. 

Thus every $\sigma \in S_n$ gives a partition of $n$. Two elements of $S_n$ are conjugate if and only if they define the same partition. This is straightforward to see. First suppose that $\sigma$ and $\tau$ are conjugate, that is, that $\sigma = g^{-1} \tau g$ for some $g \in S_n$. The orbit of $1$ under $\sigma$ is defined by $O(\sigma,1) = \{ \sigma^n(1) \mid n \geq 0 \}$. But this is $g^{-1} O(\tau, g(1))$. This defines a bijection the orbit of $1$ under $\sigma$ and the orbit of $1$ under $\tau$. Hence their sizes are equal. Conversely, assume that the orbits of $\tau$ and $\sigma$ have the same sizes. Let $g$ be an arbitrary bijection $[n] \to [n]$ between sending orbits to orbits. [[HOW TO PROCEED?????]]

Our goal is to produce an irreducible representation for every partition of $n$.

Recall that for any finite group $G$, we have
$$
\C [G] \simeq \bigoplus_{[\pi] \in \widehat G} \End(V_\pi),
$$
the isomorphism sending $g$ to the corresponding endomorphism of $V = \oplus V_\pi$. Now one can ask if it is possible to recover the space $V_\pi$ from its matrix algebra? (essentially, yes)

We need a few definitions. An idempotent $e$ in an algebra $A$ is called \textbf{minimal} if $e \neq 0$ and $eAe =\C e$. 

Here's an exercise (to be proven in the appendix!):
\begin{exc}
 Let $V$ be a finite-dimensional vector space. Show that $e \in \End(V)$ is a minimal idempotent if and only if it is a projecting onto a $1$-dimensional subspace $\C v \subset V$. Then we have an isomorphism
$$
\End(V)e \simeq V
$$
of $\End(V)$-modules given by $Te \mapsto Tv$. 
\end{exc}
Therefore finding irreducible representations of $G$ is the same as finding minimal idempotents in the group algebra $\C[G]$: if $e \in \C[G]$ is a minimal idempotent, then $\C[G]e$ defines an irreducible representation ([[WHY IS IT IRREDUCIBLE??]].

Thus, returning to $S_n$, we want to to construct minimal idempotents in $\C[S_n]$ for every partition.

It is convenient to present partitions as \textbf{Young diagrams}. Given a partition $(n_1,\ldots,n_m)$ of $n$, we draw a diagram having $n_1$ boxes in the first row, $n_2$ boxes in the second, and so on. For example, for the partition $(6,5,2,1)$ of $14$, we draw the following diagram:
$$
\begin{Young}
&&&&&\cr
&&&&\cr
&\cr
\cr
\end{Young}
$$
We can also fill these with numbers: a \textbf{Young tableau} (plural \emph{tableaux}) is a Young diagram filled with numbers $i \in [n]$ without repetitions. For example:
$$
\begin{Young}
3&1\cr
2\cr
\end{Young}
$$
Two Young tableaux are said to be of the same \textbf{shape} if they arise from the same underlying Young diagram.

Note that the symmetric group acts on the set of Young tableaux of the same shape $\lambda$. 

Fix a Young tableaux $T$. Let $R(T) \subset S_n$ be the subgroup of elements of $S_n$ permuting numbers in the \emph{rows} of $T$. Let $C(T)$ be the same group, but permuting columns instead. Define the following two elements of $\C[S_n]$:

$$
a_T = \frac{1}{\lvert R(T) \rvert} \sum_{g \in R(T)} g 
$$
and
$$
b_T = \frac{1}{\lvert C(T) \rvert} \sum_{g \in C(T)} sgn(g) \cdot g.
$$
Then we define $c_T=a_T b_T$. The element $c_T$ is called a \textbf{Young symmetrizer}. Our main theorem is this:

\begin{thm}
  \begin{enumerate}
  \item For any $T$, the element $c_T$ is (up to a scalar) a minimal idempotent in $\C[S_n]$, so it defines an irreducible representation of $S_n$.
\item If $T_1,T_2$ are two Young tableaux, then the representations corresponding to them are equivalent if and only if $T_1$ and $T_2$ have the same shape.
  \end{enumerate}
\end{thm}

The modules $\C[S_n]c_T$ are called \textbf{Specht modules}.

\begin{proof}
  TOO LONG FOR NOW. WILL PROB. COME LATER
\end{proof}

\subsection{Tabloids}

A bit more explicitly the Specht modules can be described as follows.

Fix a Young diagram $\lambda$. Introduce an equivalence relation on Young tableaux of shape $\lambda$:
$$
T_1 \sim T_2 
$$
if $T_1 = r(T_2)$ for some $r \in R(T_2)$. The equivalence class of a Young tableau $T$ is called a \textbf{tabloid} (of shape $\lambda$) and denoted by $\{ T \}$. 

Note that $S_n$ act on the set of tabloids. Let $(M_\lambda,S_n)$ be the corresponding permutation representation. Note also that action on the set of tabloids is transitive. Thus the basis of $M_\lambda$ can be identified with $S_n/R(T)$\footnote{Every $\{T \}$ can be written as $\sigma \{ T_0\}$ for some fixed $T_0$. But the ambiguity lies in $R(T)$.}.  

Thus we get isomorphisms of $\C[S_n]$-modules:
$$
\C[S_n]a_T \simeq \C[S_n/R(T)] \simeq M_\lambda.
$$
The first isomorphism is given by sending $ga_T$ to $\partial_{gR(T)}$ (the delta function), and the second is given by sending a coset $\partial_{gR(T)}$ to $\{g(T)\}$. 

Under these isomorphisms, the image of the  submodule $\C[S_n]b_T a_T \subset \C[S_n]a_T$ is spanned by the elements $b_{g(T)} \{ g(T) \}$. In other words, $V_\lambda$ is spanned by $e_{T'} := b_{T'} \{ T' \}$ by all elements of shape $\lambda$. This gives us a description of $V_\lambda \simeq V_T$ only in terms of $\lambda$.

This is a spanning set. We would like a basis. We say that that tableau $T$ is \textbf{standard} if the numbers in every row and column are increasing.

Here's a theorem that we wont prove:
\begin{thm}
 For any Young diagram $\lambda$ the elements $e_T$ for all standard tableaux $T$ of shape $\lambda$ form a basis in $V_\lambda$.
\end{thm}

The complication is of course that $g e_T = c_{g(T)}$ is a combination of standard tableaux! 

[[two examples]]

\subsection{Characters and the Hook length formula}

Here we prove two theorems. 

Let $I=(i_1,i_2,\ldots,)$ consist of non-negative integers such that
$$
\sum_{k=1}\infty ki_k=n.
$$
Denote by $c_I$ the conjugacy class in $S_n$ consisting of elements $\sigma$ which decompose into $i_1$ orbits of length $1$, $i_2$ orbits of length two and so on. 

This corresponds to an obvious partition of $n$.

Let $\chi_{\pi_\lambda}(C_I)$ denote the value of the character of $\pi_\lambda$ on any representating of the conjugacy class of $C_I$. Then
\begin{thm}[Frobenius character formula]
  
Assume $\lambda=(\lambda_1,\ldots,\lambda_r)$. Take any number $N \geq r$. Then $\chi_{\pi_\lambda}(C_I)$ is the coefficient of $\prod_{i=1}^N x_i^{\lambda_i+N-i}$ in the polynomial
$$
\Delta(x) \prod_{i \geq 1} \sum_{i=1}^N (x_i^k)^{i_k}.
$$
where $\Delta(x) = \prod (x_i-x_j)$ is the Vandermonde determinant.
\end{thm}

This was not proved, but the idea of the proof was given.

Now we quote the \textbf{hook length} formula. Let $\lambda$ be Young diagram and let $(i,j)$ be the element in position row $i$ and column $j$. Then the \textbf{hook length} $h(i,j)$ is the number of boxes below and to the right of $(i,j)$ including $(i,j)$ itself. Then:

\begin{thm}
  Let $\lambda$ be partition and let $\pi_\lambda$ be the corresponding irreducible representation of $S_n$. Then 
$$
\dim \pi_\lambda = \frac{n!}{\prod_{(i,j) \in \lambda} h(i,j)}.
$$
\end{thm}

Prooof later.


\section{Induced representations}

Let $G$ be a finite group and $H \subset G$ a subgroup. Assume $(\pi,V)$ is a representation of $H$. We want to construct a representation of $G$ out of this.

We define the \textbf{induced representation} $\mathrm{Ind}_H^G \pi$ to be the representation defined by the $\C[G]$-module
$$
\C[G] \otimes_{\C[H]} V.
$$

It is ``somehow completely fundamental''.

We have three equivalent description of the induced representation, some of the descriptions being easier to work with than others.

\begin{thm}
Let $V$ be a representation of $H$. The following representations are isomorphic.
\begin{enumerate}
\item $\C[G] \otimes_{\C[H]} V$ where $G$ acts by $g \cdot (g' \otimes v) = gg' \otimes v$. 
\item $\Hom_H(\C[G],V) \simeq \{ f:G \to V \mid f(hg)=hf(g) \forall h \in H, g \in G \}$, where $g$ acts by $(g' \cdot f)(g) = f(gg')$.
\item $W = \bigoplus_{\sigma \in G/H} V_\sigma$, where each $V_\sigma$ is a copy of $V$. Let $x_\sigma \in V_\sigma$. Then the action of $G$ is defined as follows: Let $r_\sigma \in \sigma$ be a representative for the coset $\sigma$. Then $g$ can be written as $g=r_{\sigma'}h$ for some $h \in H$. Then we define $g \cdot  x_\sigma = h \cdot x_{g \sigma}$.
\end{enumerate}
\end{thm}

\begin{proof}
Start with 1). We want to show that this is the same as number 3). We will do this in a non-canonical way. The algebra $\C[H]$ have a vector space basis $\{e_{h_1}, \ldots, e_{h_r}\}$ where $r=\lvert H \rvert$. By properties of cosets, this implies that $\C[G]$ have a basis 
$$\{e_{h_1},\ldots, e_{h_r},e_{r_1h_1},\ldots, e_{r_1h_r},\ldots,e_{r_kh_1},\ldots,e_{r_kh_r} \}$$
where $k=[G:H]$ and the $r_i$'s are a set of fixed representatives for the cosets $G/H$. This means that we can write
$$
\C[G] = \bigoplus_{i=1}^k r_i \C[H].
$$
This implies that $\C[G] \otimes_{\C[H]} V$ decomposes as
$$
\C[G] \otimes_{\C[H]} V = \left(\bigoplus_{i=1}^k r_i \C[H]\right) \otimes_{\C[H]} V \simeq \bigoplus_{i=1}^k \left( r_i \C[H] \otimes_{\C[H]} V \right)
$$
This is exactly the description in 3), because each $r_i \C[H] \otimes_{\C[H]} V$ is isomorphic to $V$ via the map $r_ih \otimes v \mapsto h^{-1}v$ (we need the inverse in order for this to be a map of representations). The representation $V$ is endowed with a left action of $H$ (this is what a representation \emph{is}), but it also has a right action, defined by $v \cdot g := g^{-1}v$. In this way, $V$ becomes a left-right-$H$-module.

One can check that the action in 3) and the natural $G$-action on $r_i\C[H] \otimes_{\C[H]} V$ are the same.
[[more to come]]
\end{proof}

We say that the collection $\{ V_\sigma \}\subset W$  is called a \textbf{system of imprimitivity} of the representation $V$. 

\subsection{Frobenius reciprocity}

and a proof of this...

\subsection{More on induction}

Here are some basic properties of induction. Most of them follow from basic properties of tensor products.

\begin{enumerate}
\item If $N \subset M \subset G$ are subgroups, then
$$
\Ind_H^G \Ind_N^M \pi \sim \Ind_N^G \pi
$$
\item If $\pi$ is finitedimensional, then
$$
(\Ind_H^G \pi)^\vee \simeq \Ind_H^G  \pi^\vee.
$$
Here $\pi^\vee$ is the contragradient representation of $\pi$.
\end{enumerate}

\subsection{Characters of induced representations}

\begin{prop}
 Assume $G \supset H$ and that $\pi$ is a finite-dimensional representation of $H$ and $\chi$ its character. Then the character $\Ind_H^G \chi$ of $\Ind_H^G \pi$ is given by
$$
(\Ind \chi)(g) = \frac{1}{\lvert H \rvert} \sum_{s \in G \mid s^{-1}gs \in H} \chi(s^{-1}gs).
$$
\end{prop}

\section{The Frobenius subgroup theorem}

In this section we will prove a theorem of group theory, the proof of which relies heavily upon representation theory. To this day, no ``elementary'' proof is known.

\begin{thm}
  Assume a finite group $G$ acts transitively on a set $X$ such that every $g \neq e$ has at most one fixed point. Then there exists a unique normal subgroup $K$ of $G$ acting freely transitively on $X$.
\end{thm}

\begin{proof}

Put
$$
K \stackrel{\Delta}{=} \{ e \} \cup \{ g\in G \mid g  \text{ has no fixed points } \}.
$$
We have to show that $K$ is a normal subgroup and that it acts freely transitively on $X$. Once this is done, we are finished, since $K$ is clearly the largest possible subset of $G$ satisfying the conclusion of the theorem.

To show that $K$ acts freely transitively on $X$, it suffices to show that $\# K=\#X$. Let $x \in X$, and consider the stabilizer
$$
H = G_x = \{ g \in G \mid g \cdot x = x \}.
$$
If $g \not \in H$, by definition $g \cdot x \neq x$. Also note that
$$
H \cap g H g^{-1} = G_x \cap G_{gx} = \{ e \},
$$
since otherwise $h$ in the intersection would act trivially on both $x$ and $gx$, but we assumed that every element acted with at most one fixpoint.

Hence we can write $G$ as a disjoint union as follows:
$$
G = K \coprod \left( \coprod_{y \in X} G_y \bs \{ e\} \right) = K \coprod \left( \coprod_{[g] \in G/H} gHg^{-1} \bs \{e \} \right).
$$

Therefore
$$
\# G = \#K  + \frac{ \# G}{\# H}( \# H  -1 )
$$
so that $\# K = \# G / \# H = \# X$.

It remains to show that $K$ is a normal subgroup. We will do this by showing that it is the kernel of some representation of $G$.

For an irreducible representation $\pi$ of $H$, consider the function $\widetilde{\chi_\pi}$ on $G$ defined by
\begin{align*}
\widetilde{\chi_\pi} &= \Ind_H^G \chi_\pi - (\dim \pi) \Ind_H^G \chi_{\epsilon_H} + (\dim \pi) \chi_{\epsilon_G} \\
&= \Ind_H^G \chi_\pi - (\dim \pi) \Ind_H^G 1 + (\dim \pi) 1.
\end{align*}
Recall that in general, if $f:H \to \C$ is any class function, we can induce a new class function on $G$ by the formula
$$
(\Ind_H ^G f)(h) = \sum_{[g] \in G/H, g^{-1}hg \in H} f(s^{-1} g s).
$$
Here the sum chooses one representative from each coset. Now one sees easily that
$$
\widetilde{\chi_\pi}(g) = \begin{cases} \dim \pi & \text{ if } g \in K \\
\chi_\pi(h) & \text{ if $g$ is conjugate to $h \in H$}
\end{cases}
$$
In the first case we get $0-0+\dim \pi$ in the definition, and in the second case we get $\Ind_H^G \chi_\pi(g)-\dim \pi + \dim \pi$. That this completely describes $\widetilde{\chi_\pi}(g)$ is clear because of our description of $G$ as a disjoint union above.

Using this decomposition, we can calculate $(\widetilde{\chi_\pi},\widetilde{\chi_\pi})$:

$$
(\widetilde{\chi_\pi},\widetilde{\chi_\pi}) = \frac{1}{\lvert G \rvert} \sum_{g \in G} \lvert \widetilde{\chi_\pi}(g) \rvert^2 = \frac{1}{\lvert G \rvert} \frac{\lvert G \rvert }{\lvert H \rvert } \dim \pi^2 + \frac{1}{\lvert G \rvert} \frac{\lvert G \rvert }{\lvert H \rvert} \sum_{h \in H\bs \{e\} } \lvert \chi_\pi(h) \rvert^2
$$
But this last expression is equal to $(chi_\pi,\chi_\pi)=1$.

As $\widetilde{\chi_\pi}$ is a linear combination of characters with integer coefficients, we must have $\widetilde{\chi_\pi} = \pm \chi_{\widetilde \pi}$ for some irreducible representation $\widetilde \pi$.\footnote{To see this, note that the norm of $\widetilde{\chi_\pi}$ is a sum of squares of integers, summing to $1$.}. But $\widetilde{\chi_\pi}(e) = \dim \pi > 0$, so that actually $\widetilde{\chi_\pi} = \chi_{\widetilde \pi}$. 

Note that as $\restr{\chi_{\widetilde \pi}}{H} = \chi_\pi$, we have $\Res_H^G \widetilde \pi \sim \pi$.

Now we claim that
$$
K = \bigcap_{[\pi] \in \hat H} \ker \widetilde \pi.
$$
This implies that $K$ is a normal subgroup. This would finishing the proof.

First we look at $\subseteq$: Let $g \in K$. Then $\chi_{\widetilde \pi}(g) = \dim \pi = \dim \widetilde \pi$. But $\widetilde \pi(g)^n = 1$ for some $n \geq 1$. Hence all the eigenvalues of $\widetilde \pi (g)$ are roots of unity. The matrix $\widetilde \pi(g)$ is diagonalizable, hence the sum of $\dim \widetilde \pi$ roots of unity is equal to $\dim \widetilde \pi$. This is only possible if all the eigenvalues are $1$ by the triangle inequality, i.e. that $\widetilde \pi(g)=\id$. Thus $g \in \ker \widetilde \pi$.

Now look at $\supseteq$. Let $g \in G \bs K$. Then $g$ is conjugate to an element $h \in H \bs \{e\}$. Then we can find some irreducible representation $[\pi] \in \hat H$ such that $\pi(h) \neq 1$. Hence $\widetilde \pi(g) \neq 1$. 

This finishes the proof.
\end{proof}

\begin{example}
Let $k$ be a finite field and let $G$ be the translation group of $\Aa^1$, or in other words the ``ax+b''-group. It is isomorphic to the matrix group
$$
G \simeq \left\{ \begin{pmatrix}
a & b \\
0 & 1 
\end{pmatrix} \mid a \in k^\times, b \in k \right\}.
$$
Then $G$ satisfies the conditions of the theorem (we say that $G$ is a \textbf{Frobenious group}). Then the group $K$ in the theorem is the group of translations:
$$
K = \left\{ \begin{pmatrix}
1 & b \\ 0 & 1 
\end{pmatrix}
\mid b \in k \right \}.
$$
\end{example}

\section{The theorems of Artin and Brauer and fields of definition}

\begin{thm}[Artin]

Let $G$ be a finite group and $\mathscr C$ a collection of subgroups of $G$. Then the following two conditions are equivalent:
\begin{enumerate}
\item Any character of $G$ is a rational combination of characters of representations induced from subgroups in $\mathscr C$.
\item Any $g \in G$ is conjugate to an element in a subgroup in $\mathscr C$.
\end{enumerate}

\end{thm}

\section{Mackey's irreducibility criterion}

...

\section{Induction from normal subgroups}

thu 22 and wed 23.

\section{Part II - Compact groups}

When one wants to develop a representation theory for infinite groups, one has to restrict the scope somewhat. Infinite groups are too wild in general, and they can have quite bad representation theory. For example, $\Z$ acting on $\C^2$ by $(x,y) \mapsto (x+ny,y)$ has the $y$-axis as an irreducible subspace, but the representation does not split, because there is no complementary invariant subspace. Thus the property of complete reducibility fails. 

We want to at least restrict to groups with a topology. But what made wonders for the theory of finite groups was the presence of an averaging operator. If we restrict to \emph{compact} groups, we will see that we can mimic this operator in this setting as well.

Recall that a \textbf{topological group} is a group $G$ equipped with a topology such that the group law and the inverse are continous maps. 

Here is a key fact:
\begin{prop}[Haar, von Neumann, André Weil]
For any locally compact group $G$ there exists a nonzero left-invariant Radon measure on $G$ which is unique up to scalar. We call such a measure a \textbf{Haar measure}.  
\end{prop}

Recall that a \textbf{Radon measure} $\mu$ on a locally compact space is a Borel measure which is outer regular, inner regular on open subsets and $\mu(K) < \infty$ for all compacts $K$.

To be given a Radon measure on a locally compact space $X$ is equivalent to be given a linear functional $F:C_c(X) \to \C$ such that $F(f) \geq 0$ if $f \geq 0$ (here $C_c(X)$ is the space of compactly supported functions on $X$). Thus we can think of a Radon measure as equivalent to having a way to integrate functions.

If $G$ is compact, we usually normalize so that $\mu(G)=1$. This makes the Haar measure unique.

\begin{example}
  Let $G=(\R,+)$. The the Haar measure is the usual Lebesgue measure.
\end{example}

There are also right-invariant measures. If the left- and right-invariant Haar measures coincide, then we say that the group $G$ is \textbf{unimodular}.

\begin{lemma}
Any compact group is unimodular.  
\end{lemma}
\begin{proof}
 Let $\mu_l$ be the left-invariant measure. Then the measure $\mu_l'(U)= \mu_l(Ug)$ is left-invariant as well. Hence $\mu_l' = \alpha \mu_l$ for some $\alpha \in \R$. But $1=\mu_l'(G) = \alpha \mu_l(G) = \alpha$. Hence $\mu_l'=\mu$.
Thus $\mu_l(Ug)=\mu_l'(U)=\mu_l(U)$, so $\mu_l$ is right-invariant as well.
\end{proof}

Many of the results for finite groups carry over to compact groups: the proofs are the same except expressions like $\frac{1}{\lvert G \rvert}$ are replaced by $\int_G f d \mu$.

A \textbf{representation} of a compact group $G$ is a continous homomorphism $\pi:G \to \GL(V)$.

Here are some results that holds for compact groups as well (with the same proofs):
\begin{itemize}
\item \textbf{Maschke's theorem:} Any finite-dimensional representation of $G$ is completely reducible.
\item Any finite-dimensional representation is unitarizable.
\item The orthogonality relations. In particular, two finite-dimensional representations of a $G$ are equivalent if and only if the characters coincide. 
\end{itemize}

The notion of regular representation is however more complicated. We are forced to (briefly) introduce infinite-dimensional spaces.

A \textbf{unitary} representation of a topological group $G$ on a Hilbert space $\mathcal H$ is a homomorphism $\pi:G \to U(\mathcal H)$, continous in the \textbf{strong operator topology}, meaning the following: if $g_i \to g$ in $G$, then $\pi(g_i) \zeta \to \pi(g)\zeta$ for all $\zeta \in \mathcal H$. This can be rephrased as saying that the map $G \to \mathcal H$ given by $g \mapsto \pi(g) \zeta $ is continous for all $\zeta \in \mathcal H$.

\begin{example}
 Let $G$ be a locally compact group with fixed Haar measure. Consider $L^2(G)$ (the vector space of square integrable functions on $G$) with respect to the given measure. Define
$$
\xymatrix @ R = 0mm{
G \ar[r] &U(L^2(G)) \\
g \ar@{|->}[r] & (\lambda(g)f)(h) = f(g^{-1}h).
}
$$
Then $\lambda$ is continous in the above sense.

We call $\lambda$ the \textbf{regular representation of the compact group $G$}.
\end{example}

\begin{thm}[Peter-Weyl]

Let $G$ be a compact group and $\pi:G \to U(\mathcal H)$ a unitary representation. Then $\pi$ decomposes into a direct sum (in the sense of Hilbert spaces) of finite-dimensional irreducible representations.
  
\end{thm}

\begin{proof}
  [[a sketch was given in the lecture]]
\end{proof}

\begin{corr}
For any compact group $G$, the intersection of all kernels of irreducible representations on $G$ is trivial.
\end{corr}
\begin{proof}
The regular representation decomposes into a sum of irreducibles, and is injective. 
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\section{Exercises}

\subsection{Lecture 1}
\begin{exc}
Suppose $V_1 \oplus \ldots \oplus V_r \sim W_1 \oplus \cdots \oplus W_s$ as representations and that the $V_i,W_i$ are irreducible. Show that $n=m$ and there exists $\rho \in S_r$ such that $V_i \sim W_{\rho(i)}$ for all $i$.
\end{exc}
\begin{sol}
First note a lemma: If $V \oplus W \sim V' \oplus W'$ and $V \sim V'$, then $W \sim W'$. This follows from the five-lemma.

Now consider the composition $V_1 \hookrightarrow V_1 \oplus \cdots \oplus V_r  \to W_1 \oplus \cdots \oplus W_s \to W_i$. This has to be non-zero for at least one $i$. Hence $V_1 \sim W_i$ for some $i$. By rearring, we are in the situation of the lemma above. Hence, inductively, if $r \leq s$, we find $0 \sim W_{r+1} \oplus \cdots \oplus W_s$, which is impossible. Similarly for $s \leq r$. Hence $r=s$ and we conclude.
\end{sol}

\begin{exc}
 Let $\hat G$ denote the Pontryagin dual of $G$. Then, for any finite abelian group $G$, we have $G \simeq \hat G$.
\end{exc}
\begin{sol}
We first do this when $G= \Z/n$ for some $n \geq 0$. Let $\varphi:\Z/n \to \C^\ast$ be a character. Then $\phi(1)=z$ for some $z$, but $\phi(n)=\phi(0)=z^n=1$, so $z$ must be a $n$'th root of unity.

Realize $\Z/n$ as the $n$th roots of unity. Then we can define a homomorphism $\widehat {\Z/n} \to \Z/n$ by $\varphi \mapsto \varphi(1)$. Similarly, we can define an inverse map by sending $e^{2\pi i/n}$  to the character $m \mapsto e^{2\pi i m /n}$. These are inverses.

Now, every finite abelian group is a product of these groups. So it remains to show (by induction) that if $G,H$ are two finite abelian groups, then $\widehat {G \times H} \simeq \widehat G \times \widehat H$. The inclusion maps $G \to G \times H$ and $H \to G \times H$ induces a map $\widehat G \times \widehat H \to \widehat{G \times H}$ by $(\varphi_1, \varphi_2) \mapsto ((g,h) \mapsto \varphi_1(g)\varphi_2(h))$.

It is easy to see that this map is injective. To see that it is surjective, let $\varphi:G \times H \to \C$ be a character. Write $\varphi$ as $gh \mapsto \varphi(gh)$. Then we can define characters on $G,H$ by $g \mapsto \varphi(g \cdot 1)$ which maps to $\varphi$. Ok.
\end{sol}

\subsection{Exercises 3}

\begin{exc}
Show that the $S$ defined in the proof of Theorem \eqref{thmdensity} lies in $\Theta(G)''$.
\end{exc}
\begin{sol}
 This is, I think, definition-hunting. DETAILS COME LATER
\end{sol}

\begin{exc}
  \begin{enumerate}
  \item Check that indeed 
$$
\langle v, w \rangle := \frac{1}{\langle G \rangle} \sum_{g \in G} \langle \pi(g) v, \pi(g) w \rangle'
$$
is an invariant Hermitian scalar product.
\item Show that if $\pi$ is irreducible, then an invariant scalar product is unique up to a factor.
  \end{enumerate}
\end{exc}

\begin{sol}
i). Invariant means that $\langle \pi(h) v, \pi(h) w \rangle = \langle v, w \rangle $. This is clear from the definitions, since if $g \in G$ ranges over all of $G$, then so does $gh$.

The only (slightly) nontrivial thing to check is that $\langle,\rangle$ is positive definite. But this is so.


ii) If $\langle,\rangle$ is invariant, then it is an element of $\Hom_G(V \otimes V, \C)$. This is canonically isomorphism to $\Hom_G(V \otimes, V^\ast)$. If we can show that $V$ and $V^\ast$ are isomorphic as representations, then we are done by Schur's lemma. 

But we are given an inner product $\langle , \rangle$. We can define a map $V \to V^\ast$ by sending $v \in V$ to the function $w \mapsto \langle v, w \rangle$. This is clearly a linear isomorphism, and it is also a map of representations. Recall that the action of $G$ on $V^\ast$ is defined by $\pi^\ast(g) \varphi (v) = \varphi(g^{-1} v)$. Then in the diagram

$$
\xymatrix{
V \ar[r] \ar[d]^{\cdot g} & V^\ast \ar[d]^{\cdot g} \\
V \ar[r]  & V^\ast 
}
$$
we want $\langle gv, w \rangle$ to be equal to $\langle v, g^{-1} w \rangle$. But this is true since $\langle ,\rangle$ is invariant:
$$
\langle gv, w \rangle = \langle gv g g^{-1} w \rangle = \langle v, g^{-1}w \rangle.
$$
Hence $V$ and $V^\ast$ are isomorphic as representations and then $\Hom_G(V,V^\ast)$ (space of bilinear forms) is one-dimensional. 
\end{sol}

\begin{exc}
 Let $(V,\pi)$ be an irreducible representation and $(W,\theta)$ a finite-dimensional representation. Let $W(\pi)$ be the isotypic component corresponding to $\pi$.
 \begin{enumerate}
 \item Show that the operator
$$
P = \frac{\dim \pi}{\lvert G \rvert} \sum_{g \in G} \chi_\pi(g^{-1})\theta(g)
$$
on $W$ is the projection onto $W(\pi)$ along $\sum_{\pi' \not \simeq \pi} W(\pi')$. In particular:
$$
W = \bigoplus_{[\pi] \in \widehat G} W(\pi).
$$
\item Show that $\restr{\theta}{W(\pi)} \sim \pi^{n_\pi}$ where $n_\pi = \dim \Mor(\pi,\theta)$.
 \end{enumerate}
\end{exc}

\begin{sol}
dddd
\end{sol}


\subsection{Lecture 4}

\begin{exc}
  \begin{enumerate}
  \item $\pi^{cc}=\pi$.
\item $(pi \otimes \theta)^c = \pi^c \otimes \pi^c$.
\item $\pi$ is irreducible if and only if $\pi^c$ is.
  \end{enumerate}
\end{exc}

\subsection{Exercises 11}

\begin{exc}
  \begin{enumerate}
  \item Find a Haar measure on $\GL_2(\R)$ and check that this group is unimodular\footnote{Recall that this means that the left and right invariant Haar measures coincide}.
\item Find left- and right-invariant Haar measures on the $ax+b$ group over $\R$, and check that this group is not unimodular.
  \end{enumerate}
\end{exc}
\begin{sol}
For the first part, we start with the usual measure on $\R^4$, and see what happens when we translate by an element of $\GL_2(\R)$. 

We assume the Haar measure has the following form, for some yet unknown function $f$.
$$
\mu(S) = \int_S f(A) \lvert da_{11} d a_{12} da_{21} da a_{22} \rvert.
$$

Now consider the same formula on the set $gS$. Then the change of variable formula tells us that
$$
\mu(gS) = \int_S f(gS) \lvert \det D(g) \rvert \lvert da_{11} d a_{12} da_{21} da a_{22} \rvert.
$$
where $\det D(g)$ is the Jacobian matrix of the map $A \mapsto gA$. A computation shows that this map is row-equivalent to a block diagonal matrix with two copies of $g$. Thus $\det D(g) = (\det g)^2$. Hence a left-invariant Haar measure on $\GL_2(\R)$ is given by
$$
\mu(S) = \int_S \frac{1}{\lvert \det A\rvert ^2} dA.
$$
The same computation with $g mapsto Ag$ gives the same result. Hence $\GL_2(\R)$ is unimodular.

ii). For the second part, note that the $ax+b$-group is topologically $\R \times \R^\ast$, so that we can use the measure $dxdy$ here. Then a similar computation gives that a left-invariant Haar measure is given by
$$
\mu(S) = \int_S \frac{1}{a^2} da\, db
$$
and a right-invariant Haar measure is given by
$$
\mu(S) = \int_S \frac{1}{a} da\, db.
$$
\end{sol}

\subsection{Lecture 13}
\begin{exc}
 Let $G = \GL_n(\C)$. Show that $\exp:\frak g \to G$ is surjective. Show also that it is not open.
\end{exc}
\begin{sol}
Note that for matrix groups, the exponential is given by
$$
\exp(A) = I + A + \frac 12 A^2 + \frac 16+A^3 + \ldots+\frac{1}{n!}A^n + \ldots
$$
Also note that
$$
\exp(P^{-1}AP) = P^{-1} \exp(A) P
$$
for invertible matrices $P \in \GL_n(\C) \subset \frak g=\End(\C^n)$. Thus, if $A$ is diagonalizable with eigenvalues $\lambda_i$, the matrix $P^{-1}\text{diag}(\log \lambda_1,\ldots,\log \lambda_n)P$ (with $P$ diagonalizing $A$) is mapped to $A$. Here $\log$ is of course the complex logarithm (which is multi-valued, so choose one value for each).

Now if $A$ is not diagonalizable, the matrix $A+\epsilon I$ is invertible and diagonalizable for generic $\epsilon$. Thus we can find a sequence $A_n$ with all $A_n$ diagonalizable and $A_n \to A$ with corresponding $B_n$ with $\exp(B_n)=A_n$. I claim that the $B_n$ can be chosen such that $\{ B_n \}$ is a convergent sequence.  This is because the eigenvalues of $A_n$ are continous with respect to $\epsilon$, and as $\log:\C^\ast \to \C$ is continous, we can choose the logs of close eigenvalues to be close. Thus we get a convergent sequence $B_n \to B$, and by continuity of $\exp$, $\exp(B)=A$.

Now we explain why $\exp$ is not open. [[[HOW????]]
\end{sol}




\section{Some worked examples}

\subsection{The representation ring of $S_3$}

We want to explicitly compute the representation ring of $S_3$.

First we find all irreducible representations. The first one is the trivial representation $\epsilon:S_3 \to \C$. We also have the \emph{sign} representation given by $g \mapsto  sgn(g) \in \C $. Both of these are one-dimensional representations.

$S_3$ have a natural action on $\R^3$ given by permuting the basis vectors. But it acts trivially on the subspace spanned by $e_1+e_2+e_3$, hence $\R^3$ decomposes as $\epsilon \oplus V$, where $V$ is some $2$-dimensional representation. It is irreducible: if not, any $v \in V$ would be sent to a scalar multiple of itself, but this is not the case. This representation is called the \textbf{standard representation} of $S_3$. We have also now found all representations of $S_3$, since $1^2+1^2+2^2=6$. 

Thus the representation ring $R(S_3)$ is $\Z[A,S]$ modulo some relations to be found. Here $A$ is the alternating representation and $S$ is the standard representation. The trivial representation is $1$. It is easy to see that $A \otimes A \sim \epsilon$, so $A^2=1 \in R(S_3)$. The representation $S \otimes S$ is $4$-dimensional. To compute how it decomposes, we use character theory.

Recall that characters are class functions on $G$, that is, they only depend on the conjugacy classes of $G$. So we write a character table:

\begin{center}
\begin{tabular}{ r | c c  c }
 & $e$ & $\tau$ & $\sigma$ \\
\hline
$\epsilon$ & 1 & 1 & 1  \\
$A$ & 1 & 1 & -1 \\
$S$ & 2 & -1 & 0 \\
\end{tabular}
\end{center}

To compute the character of the standard representation, we first note that it is, as a vector space given by $\R^3/(1,1,1)$. A basis is then given by the images of $e_1,e_2$. Let $\tau$ be the transposition $(123)$, sending $e_i$ to $e_{i+1}$. Let $\sigma$ be reflection fixing $e_1$ and exchanging $e_2$ and $e_3$. In this basis that means $e_2$ is sent to $-e_1-e_2$. Writing up the corresponding matrices lets us find the value of the character.

Now one can compute by hand (or use a result on characters), that the character of $S \otimes S$ is given by $\chi_S \cdot \chi_S$, so that its entry in the character table is $(4,1,0)$. If $S \otimes S = V_1 \oplus V_2$, then $\chi_S = \chi_{V_1} + \chi_{V_2}$. Using also that the characters are linearly independent, we see that the only option is $S \otimes S \sim \epsilon \oplus A \oplus S$.

Hence $S^2=1+A+S$ in the representation ring. Similarly, we find that $AS=S$ in the representation ring. All in all
$$
R(S_3) = \Z[A,S]/(A^2-1,S^2-1-A-S,AS-S).
$$

\subsection{Explicit Specht modules}

Again, we work with $G=S_3$. Consider the following Young-diagram:
$$
T = \young(12,3)
$$

We want to use the theorem from Lecture 5 (?) to find the standard representation of $S_3$. The elements of $S_3$ are generated by $\rho=(123)$ and $s=(23)$ with the relations $\rho^3=e$ and $s\rho s =\rho^2$. 

First off, the elements permuting the rows is the subgroup consisting of $e$ and $(12)=s\rho^2$. The elements permuting the columns is the subgroup generated by $(13)=s\rho$. Then
$$
a_T = \frac 12 \left(e+(12)\right)
$$
and
$$
b_T = \frac 12 \left( e+(13) \right).
$$
Thus
$$
c_T= \frac 14 \left( e -(13) + (12)-(132) \right).
$$

This gives us as in the lecture a map
$$
\C[S_3] \to V \subseteq \C[S_3]
$$
given by $g \mapsto g c_T$, whose image is supposed to be an irreducible representation of $S_3$. Let's find this. One computes the action of $c_T$ on the basis elements of $\C[S_3]$ by direct computation:
\begin{align*}
  c_T      &= \frac 14 \left( e -s\rho  + s\rho^2-\rho^2 \right) \\
 \rho c_T  &= \frac 14 \left( \rho - s + s\rho -e \right) \\
 \rho^2 c_T &= \frac 14 \left( \rho^2 - s\rho^2 + s -\rho \right) \\
sc_T &= \frac 14 \left( s-\rho + \rho^2-s\rho^2 \right)  \\
s \rho c_T &= \frac 14 \left( s \rho -e+\rho-s \right) \\
s \rho^2 c_T &= \frac 14 \left( s\rho^2-\rho^2+e - s\rho \right) \\
\end{align*}
We claim that $c_T$ and $\rho c_T$ span the image. For we have $\rho^2 c_T = -c_T-\rho c_T$. And $sc_T=\rho^2 c_T$. And $s \rho c_T = \rho c_T$. And $s \rho^2 c_T = c_T$. 

Thus we have some $2$-dimensional representation of $S_3$ with basis $c_T, \rho c_T$. We compute the matrices of $S_3$ with respect to this basis:
\begin{align*}
e =
\begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}
&&
\rho = 
\begin{pmatrix}
0 & -1 \\ 1 & -1
\end{pmatrix}
&&
\rho^2 =
\begin{pmatrix}
-1 & 1 \\ -1 & 0
\end{pmatrix} \\
s =
\begin{pmatrix}
-1 & 0 \\ -1 & 1
\end{pmatrix}
&&
s\rho  =
\begin{pmatrix}
0 & 1 \\ 1 & 0
\end{pmatrix}
&&
s\rho^2  =
\begin{pmatrix}
1 & -1 \\ 0 & -1
\end{pmatrix}.
\end{align*}
As expected, the character of this representation is exactly the character of the standard representation from the previous example (as is seen by computing traces). This is no coincidence.
\end{document}