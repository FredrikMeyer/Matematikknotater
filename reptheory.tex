\documentclass[11pt, english]{article}
%\documentclass[12pt]{article}  
%\usepackage[papersize={108mm,144mm},margin=2mm]{geometry}  
\sloppy 
%\pagestyle{empty} 
%\usepackage[scaled]{helvet}
%\renewcommand{\familydefault}{\sfdefault}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}   % S P R A A K

\usepackage{amssymb, amsmath, amsthm, amssymb} % symboler, osv
\usepackage{mathrsfs,calligra}
\usepackage{url}
\usepackage{thmtools}
\usepackage{enumerate}  % lister $
\usepackage{float}
\usepackage{tikz}
\usepackage[all]{xy}   % for comm.diagram
\usepackage{wrapfig} % for float right
\usepackage[colorlinks=true]{hyperref}
\usepackage{mystyle} % stilfilen      


\title{Representation theory}
\author{Fredrik Meyer} 
\date{}
\begin{document}
\maketitle

\abstract{These are notes from the course MAT4270 on representation theory, autumn 2015. The lectures were held by Sergey Neshyevey. The notes are mine. The first half is about representations of finite groups, the second  half about representations of compact Lie groups.}
\section{Lecture 1}

From now on $G$ is always a \emph{finite group} and $V$ a finite-dimensional vector space over the complex number. Most results will hold over any algebraically closed field of characteristic zero.

\subsection{Motivating example}

In 1896 Dedekind made the following observation. Let $\C[x_g \mid g \in G]$ be the free $\C$-algebra with basis the elements of $G$. Then one can form the following polynomial:
\[
P_G(x_{\rho_1},\ldots,x_{\rho_n}) = \det \left( (x_{\rho_i g_j})_{i,j=1}^n \right).
\]

Note that the matrix is just the multiplication table for the group $G$. The problem is to decompose $P_G$ into irreducible polynomials. 

\begin{example}
Let $G=S_3$. Then $G$ is generated by two elements $r$ and $s$ with the relation $srs=r^2$. If we write the elements of $G$ as $\{e,r,r^2,s,sr,sr^2\}$, then the multiplication table looks like
 $$ \bgroup\begin{pmatrix}
e&     r&     r^2&     s&     sr&     sr^2\\
     r&    r^2&     e&    sr^2&     s&     sr\\ 
    r^2&     e&     r&     sr&     sr^2&     s\\ 
    s&     sr&    sr^2&     e&     r&    r^2\\ 
    sr&     sr^2&     s&    r^2&    e&     r\\
  sr^2&     s&   sr&     r&    r^2&     e\\
     \end{pmatrix}\egroup.$$
The determinant is quite long, so I won't write it out. Suffice it to say it is a degree $6$ polynomial with 146 terms. Using a computer algebra system such as \verb|Macaulay2|, one can decompose it. It decomposes into three factors: one quadratic and two linear. They are the following (we change notation to avoid confusion about exponents):
\[
x_e+x_r+x_{r^2}+x_s+x_{sr}+x_{sr^2}
\]
and 
\[
x_e+x_r+x_{r^2}-x_s-x_{sr}-x_{sr^2}
\]
and 
\[
x_e^2-x_ex_r+x_{r^2}-x_e x_{r^2}-x_r x_{r^2} + x_{r^2}^2-x_s^2+x_s x_{sr} - x_{sr^2}^2 + x_s x_{sr^2}-x_{sr^2}^2-x_{sr^2}^2.
\]
We will see later that the first factor corresponds to the trivial representation, the second to the alternating representation, and the third is the so-called standard represenation of $G$.
\end{example}
Frobenius proved the following theorem:
\begin{thm}
  Let $P_G= \prod_{i=1}^r P_i^{m_i}$ be the decomposition of $P_G$ into irreducibles. Then
  \begin{enumerate}
  \item $m_i=\deg P_i$ for every $i$.
\item $r$ is the number of conjugacy classes in $G$. 
  \end{enumerate}
In particular, since $r=\lvert G \rvert $ if and only if $G$ is abelian, $P_G$ decomposes into linear factors if and only if $G$ is abelian.
\end{thm}

In trying to prove the above theorem, Frobenius had to develop representation theory.

\subsection{Representations}

A \textbf{representation of $G$ on $V$} is a homomorphism $\pi:G \to \GL(V)$. We will denote a representation interchangably by $\pi, (\pi,V), V_\pi$ or $V$, depending upon the situation.

This means that a representation is a \emph{linear} action of $G$ on $V$.

\begin{example}
  The trivial representation $\epsilon$ of any group is given by letting $V= \C$ and $\epsilon(g)=e$ for all $g \in G$.
\end{example}

\begin{example}[Left regular representation]
Let $\C[G]$ be the space of functions on $G$. It is a finite-dimensional vector space under pointwise addition. Define $\lambda:G \to \GL(\C[G])$ by
\[
g \mapsto \left(f \mapsto (h \mapsto f(g^{-1}h)) \right)
\]
This vector space have a basis consisting of the characteristic functions $e_g$ for $g \in G$. On these elements on sees that the action is given by $g \cdot e_h = e_{gh}$. 

\end{example}
\begin{example}
 Similarly, one has the \textbf{permutation representation}. Let $X$ be a $G$-set, i.e. a set on which $G$ acts. Then one forms the space $\C[X]$ of $X$-valued functions. It has a basis $e_x$ of characteristic functions, and the action of $G$ on $\C[X]$ is given by $g e_x = e_{gx}$. 
\end{example}

The notion of isomorphism is not surprising. An \textbf{equivalence} of representations $(\pi,V)$ and $(\theta,W)$ is given by a vector space isomorphism $T:V \to W$ such that $T(g \cdot v) = g \cdot T(v)$ for all $g \in G$.

In case $T:V \to W$ is not an isomorphism, we say that $T$ is an \textbf{intertwiner} of $V$ and $W$. The set of intertwiners is denoted by $\Mor(\pi,\theta)$ or $\Hom_G(V,W)$.

A subspace $W \subset V$ is \textbf{invariant} if $g \cdot W \subset W$ for all $g \in G$. Letting $\theta(g) = \restr{\pi(g)}{W}$, we get another representation of $G$, called a \textbf{subrepresentation} of $G$. We write $\restr{\pi}{W}$ for $\theta$. 

If we have two representation $(\pi,V)$ and $(\pi',V')$, we can form the \textbf{direct sum representation} by letting $g \in G$ act on $V \oplus V'$ componentwise. Note that $\pi$ is a subrepresentation of $V \oplus V'$.

\begin{prop}[Mascke's theorem]
\label{propmaschke}
Let $(\pi,V)$ be a representation of $G$ and $W \subset V$ an invariant subspace. Then there exists a complementary invariant subspace $W^\perp$. That is, $W$ is also invariant and such that $V = W \oplus W^\perp$.
\end{prop}

\begin{proof}
  We prove this by ``averaging''. Let $P:V \to W$ be \emph{any} projection from $V$ to $W$. Then define 
\[
\Pi(v) = \frac 1{\lvert G \rvert} \sum_{g \in G} g P(g^{-1}v).
\]
This is a $G$-linear morphism, because
\begin{eqnarray*}
\Pi(h\cdot v) &= \frac 1{\lvert G \rvert} \sum_{g \in G} g P(g^{-1} h \cdot v) \\  
&=  \frac 1{\lvert G \rvert} \sum_{g \in G} g P((h^{-1}g) \cdot v) \\
&=  \frac h{\lvert G \rvert} \sum_{g \in G} h^{-1}g P((h^{-1}g) \cdot v).
\end{eqnarray*}
It is also surjective, since if $v \in W$, then clearly $\Pi(v)=v$. Hence $\Pi$ is a $G$-linear surjection onto $W$. Then it is clear that $\ker \Pi$ is a $G$-invariant subspace of $V$ complementary to $W$.
\end{proof}

We say that a representation is \textbf{irreducible} if it has no proper invariant subspaces. A representation is \textbf{completely reducible} if it decomposes into a direct sum of irreducible representations.

\begin{example}
  Let $G = (\R,+)$ act on $\R^2$ by the matrices
\[
\begin{pmatrix}
1 & a \\ 
0 & 1
\end{pmatrix}.
\]
This leaves the $x$-axis fixed, so the representation is not irreducible. But it does not split into irreducible representations, since there is no complementary subspaces.
\end{example}

However, if $G$ is finite (or \textbf{compact}, as we shall see later), things are nicer:

\begin{thm}
 Any finitely-dimensional representation of a finite group $G$ is completely reducible.
\end{thm}
The proof follows directly from Maschke's theorem \eqref{propmaschke}.  

We next prove Schur's lemma, which although has a very simple proof, has great consequences.

\begin{prop}[Schur's lemma]
Let $(V,\pi)$ and $(W,\theta)$ be irreducible representations. Then
\begin{enumerate}
\item If $\pi \not \sim \theta$, then $\Hom_G(V,W)=0$.
\item If $\pi \sim \theta$, then $\Hom_G(V,W)$ is $1$-dimensional. 
\end{enumerate}
\end{prop}
\begin{proof}
Both the kernel and the image of a morphism of representations is a representation. But since $V,W$ are irreducible, it follows that $\ker \varphi = 0$ or $\ker \varphi  = V$ for any $\varphi:V \to W$. This proves i). 

Now suppose $\Pi:V \to W$ is an equivalence of representations. Let $\varphi \in \Hom_G(V,W)$. Then $\varphi$ must be an equivalence as well, since the neither the kernel nor image can be non-zero. Consider $T=\varphi^{-1} \circ \Pi: V \to V$. This is a linear map, and since we work over $\C$, it has an eigenvalue $\lambda$. Now consider $T-\lambda \id_V$. This has non-zero invariant kernel, hence $T-\lambda \id_V=0$. 
\end{proof}

\section{Exercises}

\subsection{Lecture 1}

\begin{exc}
Suppose $V_1 \oplus \ldots \oplus V_r \sim W_1 \oplus \cdots \oplus W_s$ as representations and that the $V_i,W_i$ are irreducible. Show that $n=m$ and there exists $\rho \in S_r$ such that $V_i \sim W_{\rho(i)}$ for all $i$.
\end{exc}
\begin{sol}
First note a lemma: If $V \oplus W \sim V' \oplus W'$ and $V \sim V'$, then $W \sim W'$. This follows from the five-lemma.

Now consider the composition $V_1 \hookrightarrow V_1 \oplus \cdots oplus V_r  \to W_1 \oplus \cdots \oplus W_s \to W_i$. This has to be non-zero for at least one $i$. Hence $V_1 \sim W_i$ for some $i$. By rearring, we are in the situation of the lemma above. Hence, inductively, if $r \leq s$, we find $0 \sim W_{r+1} \oplus \cdots \oplus W_s$, which is impossible. Similarly for $s \leq r$. Hence $r=s$ and we conclude.
\end{sol}

\end{document}