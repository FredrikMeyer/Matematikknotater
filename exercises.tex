\documentclass[11pt, english]{article}
%\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}   % S P R A A K
% \usepackage{graphicx}    % postscript graphics
\usepackage{amssymb, amsmath, amsthm, amssymb} % symboler, osv
\usepackage{mathrsfs}
\usepackage{url}
\usepackage{thmtools}
\usepackage{enumerate}  % lister $  
\usepackage{float}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{calc}
%\usepackage{tikz-3dplot}
\usepackage{subcaption}
\usepackage[all]{xy}   % for comm.diagram
\usepackage{wrapfig} % for float right
\usepackage{hyperref}
\usepackage{mystyle} % stilfilen      

%\usepackage[a5paper,margin=0.5in]{geometry}

\begin{document}
\title{Exercises}
\author{Fredrik Meyer}
\maketitle

\tableofcontents 

\section{Algebra - Serge Lang}

\subsection{Chapter V}

\begin{exc}
 Let $E=\Q(\alpha)$, where $\alpha$ is a root of the equation
\[
\alpha^3+ \alpha^2+\alpha+2 = 0.
\]
Express $(\alpha^2+\alpha+1)(\alpha^2+\alpha)$ and $(\alpha-1)^{-1}$ in the form
\[
a\alpha^2+b\alpha + c 
\]
with $a,b,c \in \Q$.
\end{exc}

\begin{sol}
Note that $\alpha^3 = -\alpha^2-\alpha - 2$ and $\alpha^2+\alpha+1=\frac{\alpha^3-1}{\alpha-1}$ (it is the beginning of a geometric series). Then
\begin{align*}
(\alpha^2+\alpha+1)(\alpha^2+\alpha) &= \alpha(\alpha^2+\alpha+1)(\alpha+1) \\
&= \alpha \left(\frac{ \alpha^3 -1}{\alpha-1} \right) (\alpha+1) \\
&= \alpha \left( \frac{-\alpha^2-\alpha- 3}{\alpha-1} \right) (\alpha+1) \\
&= -\left( \frac{\alpha^3+\alpha^2+3\alpha}{\alpha-1} \right)(\alpha+1) \\
&= -\left( \frac{-\alpha^2-\alpha-2 + \alpha^2+3\alpha}{\alpha-1}\right) (\alpha+1) \\
&= -\left( \frac{2\alpha - 2}{\alpha-1} \right) (\alpha+1) \\
&= -2\alpha-2.
\end{align*}
Alternatively, there's a much easier solution.


For $(\alpha-1)^{-1}$, let 
\[
\frac{1}{\alpha-1} = a\alpha^2+b\alpha+ c.
\]
Then multiplaying on both sides and using that $1,\alpha, \alpha^2$ are linearly independent over $\Q$, we equate coefficients, and get
\[
(\alpha-1)^{-1} = -\frac 15 \alpha^2 -\frac 25 \alpha - \frac 35.
\]
\end{sol}

\begin{exc}
  Let $E=F(\alpha)$ where $\alpha$ is algebraic over $F$ of odd degree. Show that $E=F(\alpha^2)$.
\end{exc}
\begin{sol}
Cleary $F(\alpha^2) \subset F(\alpha)$. It will be enough to show $\alpha \in F(\alpha^2)$. 

If $\alpha \not \in F(\alpha^2)$, the extension $F(\alpha)/F(\alpha^2)$ must have degree $2$ because $\alpha$ is a zero of $X^2-\alpha^2$. Then $[F(\alpha):F]=[F(\alpha):F(\alpha^2)][F(\alpha^2):F]=2 [F(\alpha^2):F]$, but this is a contradiction.
\end{sol}

\begin{exc}
 Let $\alpha, \beta$ be two elements which are algebraic over $F$. Let $f(X)=\mathrm{Irr}(\alpha,F,X)$ and $g(X)=\mathrm{Irr}(\beta,F,X)$. Suppose that $\deg f$ and $\deg g$ are relatively prime. Show that $g$ is irreducible in the polynomial ring $F(\alpha)[X]$.
\end{exc}

\begin{sol}
Consider the tower of fields $F \subset F(\alpha) \subset F(\alpha, \beta)$. Then $[F(\alpha,\beta):F] = \deg f \cdot n \leq \deg f \cdot \deg g$, by the same argument as in the proof of Proposition 1.2. Similarly $[F(\alpha,\beta):F]=\deg g \cdot m \leq \deg f \cdot \deg g$. But then
\[
\frac{\deg f}{\deg g} = \frac{m}{n}.
\]
But $\deg f$ and $\deg g$ are relatively prime, and, and we must have $m \leq \deg f$ and $n \leq \deg g$. This forces $m = deg f$ and $n = \deg g$, and hence $[F(\alpha,\beta):F(\alpha)]=\deg g$ and $[F(\alpha,\beta):F(\beta)]=\deg f$.

Now, if $g$ were reducible in $F(\alpha)[X]$, we would have $[F(\alpha,\beta):F] < \deg f \deg g$. But we don't.
\end{sol}

\begin{exc}
Let $\alpha$ be the real positive fourth root of $2$. Find all intermediate fields in $\Q(\alpha)$ over $\Q$.
\end{exc}

\begin{sol}
This exercise is a lot easier if we are allowed to use Galois theory, but that is in the next chapter.

Any such extension must have degree $2$. One example is $E=\Q(\alpha^2)$, where $\alpha^2= \sqrt 2$.

Now suppose $E \neq \Q(\alpha^2)$. Then since it is of degree $2$, it is generated by an element $\beta$ with $\beta^2 \in \Q$ (all degree $2$ extensions are of this form). Hence we need to show that if $\sqrt{n} \in \Q(\alpha)$, we must have $n = 2r^2$, where $r$ is a square.

If $n$ is even, we can without loss of generality divide by $2$ (since $\sqrt{2} \in \E$, we can then produce another extension with even $n$, by dividing by high enough powers of $\sqrt{2}$). Hence we must show that $\sqrt n \not \in \Q(\alpha)$.

If $\sqrt n \in \Q(\alpha)$, we must have that $\alpha$ has degree $2$ over $\Q(\sqrt n)$ by degree reasons. Hence the polynomial $x^4-2$ must split into two factors over $\Q(\sqrt n)$. So supppose $x^4-2=h(x)g(x)$ in $\Q(\sqrt{n}[x]$. Also note that the left hand side is invariant under $x \mapsto ix$, where $i$ is a square root of $-1$. Hence also $h(x)g(x)=h(ix)g(ix)$. Letting $h(x)=x^2+bx+c$ and $g(x)=x^2+dx+e$, and computing, we find that we must have $d+b=0$, $e+c+bd=0$, $be+c+d=0$, and $ce=2$. We can eliminate $d$ from the equations, to get the three equations $e+c-b^2=0$, $ce=2$ and $be-bc=0$. Now there are two cases: if $b=0$, we must have $d=0$, and $e+c=0$, so that the polynomials simplify to $x^2+c$ and $x^2-c$. The product is then $x^4-c^2=x^4-2$. Hence we must have $c= \pm \sqrt 2$, which is not in $\Q(\sqrt n)$ unless $n=2$. So this is a contradiction.

Now assume $b \neq 0$. Then $e-c=0$, but also $e+c = b^2 \neq 0$, which is a contradiction! Hence we can only have one intermediate field, which is $\Q(\alpha^2)$. 
\end{sol}

\begin{exc}[Exc 6]
Show that $\sqrt 2 + \sqrt 3$ has degree $4$ over $\Q$.
\end{exc}
\begin{sol}
Let $\alpha = \sqrt 2 + \sqrt 3$. One computes that $\alpha^4-10\alpha^2+1=0$. By the rational root theorem, the polynomial $x^4-10x^2+1$ is irreducible over $\Q$, and so $\alpha$ has degree $4$. 
\end{sol}


\begin{exc}
Let $E,F$ be two finite extensions of a field $k$, both contained in a larger field $K$. Then $[EF:k] \leq [E:k][F:k]$. Equality holds if the two factors on the right hand side are relatively prime.
\end{exc}

\begin{sol}
If $\{ e_i \}$ is a basis of $E$ over $k$, and $ \{ f_i \}$ is a basis of $F$ over $k$, the products $\{ e_i f_j \}$ span $EF$ (but they are not necessarily linearly independent). The inequality follows.

If the orders are relatively prime, let $d=[FE:k]$, and let $a=[E:k]$ and $b=[F:k]$. Then $d=ak=bl$ for some integers $k,l$. But then we must have $k=b$ and $l=a$. 
\end{sol}


\begin{exc}
Let $f(x) \in k[x]$ be a polynomial of degree $n$. Let $K$ be its splitting field. Show that $[K:k]$ divides $n!$. 
\end{exc}


\begin{sol}
Let $\{ a_i \}^n_{i=1}$ be the different roots of $f(x)$. Suppose for simplicity that $f(x)$ is irreducible. Consider the extension $k - k(\alpha_1)$. This extension has degree $n$. If $k(\alpha_1) =K$, we're done. If not, choose some other root $\alpha_2$, such that we get proper extensions $k - k(\alpha_1) -k(\alpha_1,\alpha_2)$. I claim that $[k(\alpha_1,\alpha_2):k(\alpha_1)] < n$: $\alpha_2$ has $f(x)$ as irreducible polynomial over $k$. If it splits over $k(\alpha_1)$, the degree of one of the factors is the number $k[k(\alpha_1,\alpha_2):k(\alpha_1)]$, which is then lower than $n$. 

This way we can continue adding conjugates by making a tower of extensions, each having degree strictly lower than the next one. The total degree is then the product, which must be a factor of $n!$.

\end{sol}

%%%%%%%%%%%%
\section{Algebraic Geometry - Hartshorne}

\subsection{Chapter I - Varieties}

\begin{exc}[Exercise 1.1]
  \begin{enumerate}[a)]
  \item Let $Y$ be the plane curve $y=x^2$. Show that $A(Y)$ is isomorphic to a polynomial ring in one variable over $k$.
\item Let $Z$ be the plane curve $xy=1$. Show that $A(Z)$ is not isomorphic to a polynomial ring in one variable over $k$.
\item Let $f$ be any irreducible quadratic polynomial in $k[x,y]$, and let $W$ be the conic defined by $f$. Show that $A(W)$ is isomorphic to $A(Y)$ or $A(Z)$. Which one is it when?
  \end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item  We have $A(Y)=k[x,y]/(y-x^2)$. An isomorphism $A(Y) \to k[t]$ is given by $x \mapsto t$ and $y \mapsto t^2$. 
\item We have $A(Z) = k[x,y]/(xy-1) \simeq k[x,\frac 1x]$. So we must show that $k[x,\frac 1x] \not \approx k[x]$. It can be computed that the first one has automorphisms given by $x \mapsto cx^n$ for $c$ nonzero and $n \neq 0$. The second has as automorphisms $ax+b$ ($a \neq 0$). So the first one have an abelian automorphism group, the second has not.
\item What is special about $A(Y)$ and $A(Z)$? Staring at pictures, we see that any line in $\Aa^2$ intersects $Y$ in at least one point, but in the case of $Z$, there exist two lines which do not intersect $Z$. We claim that this is the only two things that can happen.

First we claim that if we are in the second situation, that is, if there exist a pair of lines $\ell,\ell'$ such that $W \cap \ell = W \cap \ell' =\emptyset$, then $W \simeq Z$. 

A general quadric can be written as
\[
ax^2+bxy+cy^2+dx+ey+f=0.
\]
Suppose now $\ell \cap W=\emptyset$. This is equivalent to $I(f,\ell^\vee)=(1)$. Without loss of generality, we can assumme $\ell = \{ x = 0 \}$. Then
\[
I(f,\ell) = (cy^2+ey+f,x).
\]
This generates $k[x,y]$ if and only if $c=e=0$ and $f \neq 0$. Thus $f$ must be of the form
\[
ax^2+bxy+dx+f=0
\]
with $f \neq 0$. But this can be written as
\[
x(ax+by+d)+f = 0.
\]
Put $y' = ax+by+d$. Then $I(W)$ takes the form $(xy'+f=0)$, which is clearly isomorphic to $Z$ after a linear change of coordinates. Note that the other line not meeting $W$ is the line given by $y'=ax+by+d=0$.

Assume now that we are in the other situation, namely that \emph{every} line in $\Aa^2$ meets $W$. Now pick a tangent line $\ell$ of $W$. Without loss of generality, we can assume that $\ell$ is $\{ y=0 \}$. This is a tangent line if and only if it meets $W$ doubly, meaning that $I(W) + (\ell^\vee)$ takes the form $(l^2,y)$ for some linear form $l$. We can also assume that $\ell \cap W = (0,0)$, so that $I(W) + (\ell^\vee) =(x^2,y)$. But this means that
\begin{align*}
  I(W) + I(\ell) &= (ax^2+bxy+cy^2+dx+ey+f,y) \\
&= (ax^2+dx+f,y)
\end{align*}
We want $ax^2+dx+f=x^2$. This can happen only if $d=f=0$ and $a \neq 0$. Thus the quadric takes the form
\[
ax^2+bxy+cy^2+ey=0.
\]
Now we claim that there exist one line at each point of $W$ that intersect $W$ transversally in exactly one point. This is the case for $Y$. Consider the pencil of lines through $(0,0)$ defined by $x=\lambda y$. We want to find $\lambda$ such that the intersection is transversal and only one point. We have
\[
( ax^2+bxy+cy^2+ey, x-\lambda y) = \left( (a\lambda ^2+b\lambda+c)y^2+ey,x-\lambda y \right).
\]
This have exactly one solution if and only if $a\lambda^2+b\lambda+c=0$. This is solvable since $a \neq 0$ and since all lines intersect $W$. Thus choose $\lambda$ as above. We can rotate this line such that it becomes $x=0$. Then the equation takes the form
\[
ax^2+bxy+ey=0.
\]
We have still not arrived at $y=x^2$. Let now $y=\lambda x$ be a general line through the origin. We demand that this intersect $W$ twice for every $\lambda$ such that the line is not tangent. We get that the intersection is given by
\[
ax^2+b\lambda x+ex = x((a+\lambda b)x+e) = 0.
\]
For this to have two solutions for every $\lambda$ we must have $a+\lambda b \neq 0$ for all $\lambda$. But this requires $b =0$.  Thus the equation is
\[
ax^2+ey = 0
\]
which is the conic we were looking for.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 1.2, the twisted cubic curve]

Let $Y \subseteq \Aa^3$ be the set $\{ (t,t^2,t^3) \mid t \in k\}$. Show that $Y$ is an affine variety of dimension $1$. Find generators for the ideal $I(Y)$. Show that $A(Y)$ is isomorphic to a polynomial ring in one variable over $k$. We say that $Y$ is given by the \emph{parametric equation} $x=t,y=t^2,z=t^3$.  
\end{exc}
\begin{sol}
An affine variety is by definition a closed irreducible subset of $\Aa^3$. So we must find an irreducible ideal $I$ such that $Z(I)=Y$ (forgive the abuse of notation).

I claim that $I(Y)=\langle x^2-y,x^3-z \rangle$. Clearly, every $P \in Y$ satisfies these equations. This shows the inclusion $Y \subset Z(I)$. Now suppose $P \in Z(I)$, that is, $f(P)=0$ for all $f \in I$. In particular $(x^2-y)(P)=0$ and $(x^3-z)(P)=0$. Thus $y=x^2$ and $z=x^3$. So if $P=(a,b,c) \in k^3$, then $P=(a,a^2,a^3)$, so $P \in Y$. This shows that $Z(I)=Y$. If we can show that $I$ is prime, then it follows that $I(Y)=I$ and that $Y$ is a variety.

In fact, we claim that $k[x,y,z]/I \simeq k[t]$, implying that $I$ is prime. The map $\varphi$ is given by $x \mapsto t$, $y \mapsto t^2$, $z \mapsto t^3$. Then clearly $I \subseteq \ker \varphi$. We must show equality. So suppose $\varphi(f)=0$. 

First we claim that any $f \in k[x,y,z]$ can be written as $f=R(x)+S(x)y+T(x)z+i(x,y,z)$ where $i$ is a polynomial in $I$. We prove this by induction on $\deg f$. If $\deg f = 1$, this is trivially true.  The rest of the proof proceeds by tedious induction.
\end{sol}

\subsection{Chapter II - Schemes}

\begin{exc}[Exercise 1.2]
  \begin{enumerate}[a)]
  \item For any morphism of sheaves $\varphi:\FF \to \mathscr G$, show that for each point $P$, $(\ker \varphi)_P = \ker (\varphi_P)$ and $(\im \varphi)_P =  \im(\varphi_P)$. 
\item Show that $\varphi$ is injective (resp. surjective) if and only if the induced map on the stalks $\varphi_P$ is injective (resp. surjective) for all $P$.
\item Show that a sequence $\ldots \FF^{i-1} \xrightarrow{\varphi^{i-1}} \FF^i \xrightarrow{\varphi^{i}}  \FF^{i+1} \to \ldots$ of sheaves and morphisms is exact if and only if for each $P \in X$, the corresponding sequence of stalks is exact as a sequence of abelian groups.
\end{enumerate}
\end{exc}

  \begin{sol}
    \begin{enumerate}[a)]
    \item An element of $(\ker \varphi)_P$ is represented by a pair $(U,f)$ with $f \in \mathscr F(U)$ satisfying $\varphi(U)(f)=0$. We have $(U,f) \simeq (V,g)$ if there is a neighbourhood $W$ of $p$ contained in $U \cap V$ such that $\restr{f}{W}=\restr{g}{W}$ (then automatically $\varphi(W)(f)=0$, since $\varphi(W)=\restr{\varphi(U)}{W}$).

On the other hand, an element of $\ker \varphi_P$ is represented by a pair $(U,f)$ satisfying the same conditions.

A similar argument works for $\im \varphi$. Alternatively, one can show that finite limits commute with direct limits. 
\item Suppose $\varphi:\FF \to \mathscr G$ is injective. Then by definition all $\varphi(U):\FF(U) \to \mathscr G(U)$ are injective, hence $(\ker \varphi)_P=\ker \varphi_P=0$, hence $\varphi_P$ is injective. Suppose $\varphi:\FF \to \mathscr G$ is surjective. By definition, this means that $\im \varphi=\mathscr G$, hence $\mathscr G_P = (\im \varphi)_P = \im \varphi_P$, so the stalks are surjective. 
\item Exactness means that $\ker \varphi^i = \im \varphi^{i-1}$. Taking stalks, gives one implication. Assume that the stalks are exact. Then the same argument works.
    \end{enumerate}
  \end{sol}

  \begin{exc}
    \begin{enumerate}[a)]
    \item Let $\varphi:\FF \to \mathscr G$ be a morphism of presheaves such that $\varphi(U):\FF(U) \to \mathscr G(U)$ is injective for each $U$. Show that the induced map $\varphi^+:\FF^+ \to \mathscr G^+$ of associated sheaves is injective.
\item Use part a) to show that if $\varphi:\FF \to \mathscr G$ is a morphism of sheaves, then $\im \varphi$ can be naturally identified with a subsheaf of $\mathscr G$, as mentioned in the text.
    \end{enumerate}
  \end{exc}

  \begin{sol}
    \begin{enumerate}[a)]
    \item From the universal property of the sheafification functor, we have a commutative square:
\[
\xymatrix{
\FF \ar[r]^\varphi \ar[d]_\theta & \mathscr G \ar[d]^\theta \\
\FF^+ \ar[r]^{\exists !} & \mathscr G^+
}
\]
The lower arrow follows from the universal property of sheafification applied to $\theta \circ \varphi$. Taking stalks induced the identity map on the vertical arrows, and since a map is injective if it is injective on stalks, the statement follows.
\item $\im \varphi$ is the sheafification of $(\im \varphi)_{pre}(U)=\{U \mapsto \varphi(U)\} $.  We have $\im \varphi(U) \subset \mathscr G(U)$ for all $U$, hence $\im \varphi_P \subset \mathscr G_P$ for all $P$, hence $\im \varphi \to \mathscr G$ is injective.
    \end{enumerate}
  \end{sol}

\begin{exc}[Exercise 1.14, Support]
Let $\FF$ be a sheaf on $X$, and let $s \in \FF(U)$ be a section over an open set $U$. The \emph{support of $s$} denoted $\Supp (s)$, is defined to be the set $\{ P \in U \mid s_P \neq 0\}$ where $s_P$ denotes the germ of $s$ in the stalk $s_P$. Show that $\Supp (s)$ is a closed subset of $U$. We define the \emph{support} of $\FF$ by $\Supp \FF$ to be $\{P \in X \mid \FF_P \neq 0 \}$. It need not be a closed subset.
\end{exc}

\begin{sol}
Showing that $\Supp(s)$ is closed is equivalent to showing that the complement is open. So let $P \in X \bs \Supp(s)$. Then $s_P=0$. But every germ is represented by a pair $(s,U)$ (with $(s',U') \simeq (s,U)$ if $\restr{s}{W}=\restr{s'}{W}$ for some open $W \subset U \cap U'$). But since $s_P=0$, there must be some neighbourhood $U$ such that $s_P$ is represented by $s=0$, hence $X \bs \Supp(s)$ can be covered by those open $U$'s.

To see that $\Supp \FF$ need not be closed, let $X=\Aa_k^1$ with $k$ an infinite field. Let $\Z$ be the constant sheaf and let $\mathscr L$ be the direct sum of infinitely many skyscraper sheaves, but not everyone. Let $\FF/\mathscr L$ be the quotient. This has support on the infinitely many points chosen, which is not closed.
\end{sol}

\begin{exc}[Exercise 1.16, Flabby/flasque sheaves]
A sheaf $\FF$ on a topological space $X$ is \emph{flasque} (flabby) if for every inclusion $U \subseteq V$, the restriction map $\FF(U) \to \FF(V)$ is surjective.
\begin{enumerate}[a)]
\item Show that a constant sheaf on an irreducible topological space is flasque.
\item If $0 \to \FF' \to \FF \to \FF'' \to 0$ is an exact sequence of sheaves, and if $\FF'$ is flabby, then for any open set $U$, the sequence
$$
0 \to \FF'(U) \to \FF(U) \to \FF''(U) \to 0
$$
is exact.
\item Same as above, but suppose $\FF'$ and $\FF$ are flabby. Show that $\FF''$ is flabby.
\item If $f:X \to Y$ is a continous map, and $\FF$ is a flabby sheaf on $X$, then $f_*\FF$ is flabby on $Y$.
\item Let $\FF$ be any sheaf on $X$. We define a new sheaf $\mathscr G$, called the \emph{sheaf of discontinous sections of $\FF$}, as follows: For each open set $U \subset X$, $\mathscr G(U)$ is the set of maps $s:U \to \cup_{P \in U} \FF_P$, such that for all $P \in U$, $s(P) \in \FF_P$. Show that $\mathscr G$ is a flabby sheaf, and that there is a natural injective morphism from $\FF$ to $\mathscr G$.
\end{enumerate}
\end{exc}

\begin{sol}
\begin{enumerate}[a)]
\item Every open set in $X$ is irreducible and dense, and dense sets are connected. Hence a constant sheaf is actually constant, and all the restriction maps are identities (except if one of them is the empty set).
\item The sheaf axiom for a sheaf $\FF$ is equivalent to the following: for every covering $\{U_i \}$ of $U$, the following sequence is exact:
$$
0 \to \FF(U) \to \prod_i \FF(U_i) \to \prod_{ij} \FF(U_{ij}),
$$
where $U_{ij}= U_i \cap U_j$. The first map sends a section $s$ to the product of all its restrictions, and the second map sends $(s_i) \mapsto (s_i-s_j)_{ij \in I \times I}$.

Since the sequence of sheaves in the exercise is exact, for small enough $U_i$, the sequence $0 \to \FF'(U_i) \to \FF(U_i) \to \FF''(U_i) \to 0$ is exact (for sheaves, exactness is a local property). Hence we can form the following diagram: 
\[
\xymatrix{
 & 0\ar[d] & 0 \ar[d] & 0 \ar[d] \\
 0 \ar[r] & \FF'(U) \ar[r]\ar[d] & \FF(U) \ar[r]\ar[d] & \FF''(U)\ar[d] \\
 0 \ar[r] & \prod_i \FF'(U_i) \ar[r]\ar[d]^f & \prod_i \FF(U_i) \ar[r]\ar[d] & \prod_i\FF''(U_i) \ar[r]\ar[d] & 0  \\
 0 \ar[r] &\prod_{ij} \FF'(U_{ij}) \ar[r]\ar[d] & \prod_{ij} \FF(U_{ij}) \ar[r] & \prod_{ij}\FF''(U_{ij}) \ar[r] & 0 \\
 & \coker f
}
\]
Hm! If $f$ was surjective, we could apply the snake lemma!! But $f$ is not surjective. (...) All proofs I've found use Zorns lemma...
\item Use the same diagram. The middle column is surjective at the bottom, and by commutativity, the right column must be as well.
\item This is obvious, since $f_\ast \FF(V) = \FF(f^{-1}(V))$.
\item It is clear that $\mathscr G$ is a sheaf. If $U \subset V$, let $s \in \mathscr G(U)$ be given. Then define $s' \in G(V)$ as follows: $s'(P)=s(P)$ if $P \in U$ and zero elsewhere. This element will be sent to $s$.

The injective morphism from $\FF$ to $\mathscr G$ is defined as follows: send $s \in \FF(U)$ to the function $s(P)=s_P$ in $\mathscr G(U)$.
\end{enumerate}
\end{sol}



\begin{exc}[Exercise 2.19]
Let $A$ be a ring. The following are equivalent:
\begin{enumerate}
\item $\Spec A$ is disconnected.
\item There exists nonzero elements $e_1,e_2 \in A$ such that $e_1e_2=0$, $e_1^2=e_1$, $e_2^2=e_2$ and $e_1+e_2=1$ (these are called \emph{orthogonal idempotents}).
\item $A$ is isomorphic to a direct product $A_1 \times A_2$ of two nonzero rings.
\end{enumerate}
\end{exc}
\begin{sol}
$1 \Rightarrow 3$: Let $U$ be a nonempty connected compontent of $X=\Spec A$. Let $V = X \bs U$ be its complement, and let $i_1:U \to X$ and $i_2=V \to X$ be the natural inclusions on topological spaces. This can be extended to a map of schemes as well: we need to give a morphism $f^\#:\OO_X \to f_\ast \OO_U$. But $f_\ast \OO_U(W)=\OO_X(W \cap U)$, so $f_\ast \OO_U = \restr{\OO_X}{U}$. Hence we just choose $f^\$:\OO_X \to \OO_U$ to be the natural map provided by the sheaf axioms.

We now have two morphisms $i_1:U \to X$ and $i_2:V \to X$ which are closed immersions, hence the induced ring morphisms $A \to A_1$ and $A \to A_2$ are surjective. Also, the universal property for products hold because the universal property for coproducts hold in the category of affine schemes. Hence $A \simeq A_1 \times A_2$.  (a bit clumsy??)

$2 \Rightarrow 3$: Let $\pi_i: A \to A$ be given by multiplication by $e_i$ and let $A_i$ be its image. Then $\ker \pi_1 = A_2$, because  if $e_1f$ then $f=e_2f$, so $f \in A_2$. The splitting maps are the natural inclusions. 

$3 \Rightarrow 2$: If $A = A_1 \times A_2$, let $e_i=\pi_i(1)$. 

$3 \Rightarrow 1$: Similar to the first argument, just opposite.
  
\end{sol}

\begin{exc}[Excercise 7.1]
Let $(X,\OO_X)$ be a locally ringed space and let $f:\mathscr L \to \mathscr M$ be a surjective map of invertible sheaves on $X$. Show that $f$ is an isomorphism.  
\end{exc}
\begin{sol}
Since $\mathscr L, \mathscr M$ are invertible, we have isomorphisms $\mathscr L_x \approx \OO_{X,x}$ and $\mathscr M_x \approx \OO_{X,x}$ for each $x \in X$.

But $\Hom_{\OO_{X,x}}(\OO_{X,x},\OO_{X,x})=\OO_{X,x}$, that is, all homomorphisms are given by multiplication by some $h \in \OO_{X,x}$. But since $f$ was surjective, we conclude that $h$ is outside $\mm_x$, the maximal ideal of $\OO_{X,x}$. But then $h$ is a unit, so $f$ is an isomorphism.
\end{sol}

\begin{exc}[Exercise 7.3]
Let $\varphi: \PP^n \to \PP^m$ be a morphism. Then
\begin{enumerate}
  \item Either $\varphi(\PP^n)=\ast$ or $m \geq n$ and $\dim \varphi(\PP^n)=n$.
  \item In the second case, $\varphi$ an be obtained as the composition of a $d-$uple embedding $\PP^n \to \PP^n$ for a uniquely determined $d \geq 1$, a linear projection $\PP^N \bs L \to \PP^m$ and an automorphism of $\PP^m$. Also $\varphi$ has finite fibers.
\end{enumerate}
\end{exc}
\begin{sol}
  a). Since $\varphi$ is a morphism, the base locus of the corresponding linear system must be empty. If $x_i$ are coordinates on $\PP^m$, then the base locus is given by zeros of $\varphi^\ast(x_i)$ (here $x_i$ are interpreted as section of $\OO_{\PP^m}(1)$). If $Z(\varphi^\ast(x_i))= \varnothing$, then we must have $m \geq n$, because by Krull's Hauptidealsatz, the dimension of $Z(\varphi^\ast(x_i))$ is at most $n-m-1$. We want this to be less than $0$, so $n < m+1$, or in other words $n\le m$. If not, the only way $\varphi$ can be a morphism, is if the $\varphi^\ast(x_i)$'s are constant.

  To see that $\dim \varphi(\PP^n)=n$, note that we clearly must have $\le n$. ------
\end{sol}


%%%
\subsection{Chapter III - Cohomology}

\begin{exc}[Exercise 2.1]
  \begin{enumerate}[a)]
  \item Let $X=\Aa_k^1$ be the affine line over an infinite field $k$. Let $P,Q$ be distinct closed points on $X$ and let $U=X - \{ P,Q\}$. Show that $H^1(X,\Z_U)\neq 0$.
  \end{enumerate}
\end{exc}

\begin{sol}
  \begin{enumerate}[a)]
  \item We have an exact sequence
\[
0 \to \Z_U \to \Z \to i_\ast(\restr{\Z}{Z}) \to 0,
\]
where $Z=P \cup Q$. The last sheaf is equal to the skyscraper sheaf $\Z_P \oplus \Z_Q$. Since $\Z$ is flabby, we have $H^1(X,\Z)=0$. Hence the long exact sequence reads 
\[
0 \to \Z \to \Z \to \Z \oplus \Z \to H^1(\Z_U) \to 0.
\]
It follows that $H^1(\Z_U)=\Z^2$. In fact, this should please us, because if $k=\C$, we have that $U$ is the complex plane minus two points, which is homotopic to the figure eight, which indeed have $H_{sing}^1(U,\C)=\C^2$.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 4.3]
Let $X= \Aa^2_k=\Spec k[x,y]$ and let $U = X \bs \{(0,0)\}$. Use a suitable open cover of $X$ by open affine subsets to show that $H^1(U,\OO_U)$ is isomorphic to the $k$-vector space spanned by $\{ x^i y^j \mid i,j < 0 \}$. In particular, it is infinitedimensional, and so $U$ cannot be affine (not projective either).  
\end{exc}
\begin{sol}
We can cover $U$ by $U_1= \Aa^2 \bs \{ x= 0\}$ and $U_2 = \Aa^2 \bs \{ y = 0\}$. We have $U_1 \cap U_2 = \Aa^2 \bs \{ xy=0\}$. Also, $\OO(U_1)=k[x,y,\frac 1x]$ and $\OO(U_2)=k[x,y,\frac 1y]$ and $\OO(U_1 \cap U_2) = k[x,y,\frac {1}{xy}]$. Then the \v{C}ech complex takes the form
\[
0 \to k[x,y,\frac 1x] \times k[x,y, \frac 1y] \xrightarrow{d} k[x,y,\frac{1}{xy}] \to 0,
\]
the differential being difference. Then $H^1(U,\OO_U)$ can be computed as the homology at the second term. But nothing on the left side can hit anything of the form $x^iy^j$ with $i,j < 0$. Anything else is hit. Thus we have
\[
H^1(U, \OO_U) \simeq \{ x^i y^j \mid i,j < 0 \}
\]
as $k$-vector spaces.
\end{sol}

\begin{exc}[Exercise 4.7]
Let $X$ be the subscheme of $\PP_k^2$ defined by a single homogeneous polynomial $f(x_0,x_1,x_2)=0$ of degree $d$. Assume that $(1,0,0)$ is not on $X$. Then show that $X$ can be covered by the two open affine subsets $U= X \cap \{ x_1 \neq 0\}$ and $V = X \cap \{ x_2 \neq 0\}$. Now calculate the \v Cech complex
\[
\Gamma(U,\OO_X) \oplus \Gamma(V,\OO_X) \to \Gamma(U \cap V, \OO_X)
\]
explicitly, and thus show that
\begin{align*}
  \dim_k H^0(X,\OO_X) &= 1 \\
\dim _k H^1(X,\OO_X) &= \frac 12 (d-1)(d-2).
\end{align*}
\end{exc}

\begin{sol}
 $X$ can be covered by just two open affines since $\PP^2 \bs (U \cup V) = \{(1:0:0)\}$, which was assumed not to lie on the curve.

The open affine subset $\Gamma(U, \OO_X)$ can be identified with the polynomial ring $k[u,v]/\langle f(u,1,v) \rangle$, and $\Gamma(V,\OO_X) = k[x,y]/f(x,y,1)$. The differential is then given by 
\[
\left( g(u,v), h(x,y) \right) \mapsto g(xy^{-1},y^{-1})-h(x,y) \in k[x,y,\frac 1y].
\]

We can assume that $f=x_0^d$, since what really matters is the degree, and we are just doing linear algebra.

We first calculate $H^0(X,\OO_X)$. So suppose $g(xy^{-1}, y^{-1})-h(x,y)=0$ in $k[x,y,y^{-1}]/\langle f(x,y,1) \rangle$. By definition this means that
\[
g(xy^{-1},y^{-1}) - h(x,y) = f(x,y,1) \cdot \tilde f(x,y,\frac 1y)
\]
for some polynomial $\tilde f$. Write $\tilde f$ as $\tilde f_0 + \tilde f_1$, where $\tilde f_0=\sum_{j < 0} a_{ij} x^i y^j$ and $\tilde f_1 \in k[x,y]$. Then we have the equality
\[
g(xy^{-1},y^{-1}) - h(x,y) = \sum_{j < 0} a_{ij}x^{i+d}y^j + \sum_{j \geq 0} x^{i+d} y^j.
\]
First of all, we see that the constant terms of $g$ and $h$ must be equal, because there are no constant terms on the right hand side. Secondly, $g(xy^{-1},y^{-1})$ consists solely of terms with $j < 0$. Thus the non constant terms of  $g(xy^{-1},y^{-1})$ must be equal to the left term of the right hand side above. But both terms of the right hand side are zero modulo $f$, so the constant terms of $g(xy^{-1},y^{-1})$ are also zero mod $f$. The same holds for $h(x,y)$. Thus $H^0(X,\OO_X)= \{ (c,c) \mid c \in k \} \simeq k$.

Now we compute $H^1(X,\OO_X)$. Consider a monomial $x^iy^j$ in the target. If both $i,j \geq 0$, then it is hit by $(0,-x^iy^j)$. Likewise, if $j \geq i$, then $(x^iy^{j-i},0) \mapsto x^i x^{-j}$. Thus all monomials $x^iy^{-j}$ with $j \geq i$ is zero in the cokernel. Further, if $i \geq d$, then $x^i y^j$ is already zero! Thus, we can draw the non-zero monomials in the cokernel as points in the lattice $\Z^2$. This is a triangle of length $d-2$. Thus the dimension of $H^1(X,\OO_X)$ is 
\[
1 + 2 + \ldots+ d-3 + d-2 = \frac 12 (d-2)(d-2+1) = \frac 12 (d-2)(d-1).
\]
\end{sol}

\begin{exc}[Exc 7.1]
Let $X$ be an integral projective scheme of dimension $\ge 1$ over a field $k$, and let $\mathscr L$ be an ample invertible sheaf on $X$. Then $H^0(X, \mathscr L^{-1})=0$.
\end{exc}
\begin{sol}
We prove this by a series of reductions. First suppose (1) that $k$ is algebraically closed. Also (2),replace $X$ by its normalization $\pi: \widetilde X \to X$ (which we denote by $X$ henceforth). Also suppose that $H^n(X, \mathscr L \otimes \omega_X^\circ)=0$. This we can achieve by Prop 5.3, by replacing $\mathscr L$ with some tensor power of itself.

Then $H^0(X,\mathscr L^{-1})=H^n(X, \mathscr L \otimes \omega_X^\circ)=0$ by Serre duality.

Now assume only (1) and (2), and suppose that $H^n(X,\mathscr L^n \otimes \omega_X^\circ)=0$. Then if $s \in H^0(X, \mathscr L^{-1})$, we have that $s^n \in H^0(X, \mathscr L^{-n})=0$. But $X$ is integral, so $s=0$. Hence $H^0(X, \mathscr L^{-1})=0$.


\end{sol}

\subsection{Chapter IV - Curves}

\begin{exc}[Exercise 1.1]
Let $X$ be a curve and $P \in X$ a point. Show that there exists a nonconstant rational function $f \in K(X)$ which is regular everywhere except at $P$.
\end{exc}
\begin{sol}
Let $D$ be the divisor $D=nP$. The linear system 
$$
\{ E = D + f \geq 0 \}
$$
consists of all divisors linearly equivalent to $D$. But these are classified by those $f$ with $(f) \geq -nP$, i.e. those $f$ with at most poles of order $n$ at $P$.

By Riemann-Roch we have
$$
l(D)-l(K-D) = \deg D +1 -g = n+1-g.
$$
If $n$ is large enough, $K-D$ will have negative degree, so $l(K-D)=0$. Thus for large $n$, we can get $l(D)$ as big as we want.
\end{sol}

\begin{exc}[Exercise 1.2]
Again let $X$ be a curve and let $P_1,\cdots,P_r$ be points. Then there is a rational function $f \in K(X)$ having poles only at the $P_i$ and regular elsewhere.
\end{exc}
\begin{sol}
Again, this follows by Riemann-Roch. Let $D=n\sum_i P_i$. Then, as in the previous exercise, we get that the set
$$
\{ f \in K(X) \mid (f) + \sum nP_i \geq 0 \}
$$
is non-empty. But the condition is equivalent to $(f)_{P_i} \geq -nP_i$ and $(f)_P \geq 0$ for $P \neq P_i$. But this is exactly what is to be shown.
\end{sol}


\begin{exc}[Exercise 1.5]
For an effective divisor $D$ on a curve $X$ of genus $g$, show that $\dim \lvert D \rvert \leq \deg D$. Furthermore, equality holds if and only if $D=0$ or $g=0$. 
\end{exc}
\begin{sol}
This is a simple consequence of Riemann-Roch. Note that the statement is equivalent to $l(D) - 1 \leq \deg D$. So by Riemann-Roch:
\[
l(D)-1 = \deg D - g + l(K-D).
\]
So the statement is equivalent to $l(K-D) \leq g$. Now, by definition, $l(K)=g$, so we need only show that $l(K-D) \leq l(K)$ for any two divisors $K,D$. But by the identification
$$
H^0(K-D)=\{ f \in K(C) \mid (f) + K-D \leq 0 \}
$$
this is trivial since $D$ is effective.

Now assume $l(K-D)=g$. If $D=0$, then this is equal by definition. If not, then if $f$ is such that $(f) + K \geq 0$, then $(f) + K-D \geq 0$. We must have $\deg f = 0$ and $f$ must have at least $2g-2$ zeros and the same number of poles. ....................
\end{sol}

\subsection{Chapter V - Surfaces}

\begin{exc}[Exercise 1.1]
Let $C,D$ be any two divisors on a surface $X$, and let the corresponding invertible sheaves be $\mathscr L, \mathscr M$. Show that
\[
C.D = \chi(\OO_X) -\chi(\mathscr L^{-1})-\chi(\mathscr M^{-1})+\chi(\mathscr L^{-1} \otimes \mathscr M^{-1}).
\]
\end{exc}

\begin{sol}
We have an exact sequence
\[
0 \to \mathscr L^{-1} \to \OO_X \to \OO_C \to 0,
\]
and similarly with $\mathscr L$ and $C$ replaces by $\mathscr M$ and  $D$, from which we obtain that $\chi(\OO_C) = \chi(\OO_X)-\chi(\LL^{-1})$. We want to use the equality $C.D = \chi(\OO_C)- \chi(\mathscr L(-D) \otimes \OO_C)$ in the proof of Proposition 1.4.

Using what we've found, we have
$$
C.D = -\chi(\mathscr L^{-1}) + \chi ( \OO_{C \cap D}).
$$
Using the exact sequences 
\[
0 \to \mathscr M^{-1} \otimes \OO_C \to \OO_C \to \OO_{C \cap D} \to 0
\]
and 
\[
0 \to \mathscr M^{-1} \otimes \mathscr L^{-1} \to \mathscr M^{-1} \to \mathscr M^{-1} \otimes \mathscr L^{-1} \to 0,
\]
together with additivty of Euler characteristics, we obtain the desired result.
\end{sol}

\begin{exc}[Exercise 1.4]
  \begin{enumerate}[a)]
  \item If a surface $X$ of degree $d$ contains a straight line $C = \PP^1$, show that $C^2=2-d$.
\item Assume that $char k = 0$ and show that for every $d \geq 1$, there exists a nonsingular surface $X$ of degree $d$ in $\PP^3$ containing the line $x=y=0$.
  \end{enumerate}
\end{exc}
\begin{sol}
  a) This follows from the adjunction formulas. We have that $K_X = (d-4)H$ by the adjunction formula and also that $-2=C^2+C.K$ by Prop 1.5. Thus
$$
C^2 = -2-C.K = -2-C.((d-4)H)=-2-d+4=2-d
$$
since $C.H$ is the degree of $C$ which is $1$.

b) Let $X$ be the surface defined by $f=x^d+y^d-xz^{d-1}-yw^{d-1}$. Then $f$ is non-singular and contains $x=y=0$. We check nonsingularity by the Jacobian criterium. The ideal generated by the partial derivates is 
$$
Jac(f) = \langle dx^{d-1}-z^{d-1},dy^{d-1}-w^{d-1}, xz^{d-2}, yw^{d-2} \rangle
$$
Takin radicals gets rid of some of the powers:
$$
\sqrt{Jac(f)} = \langle dx^{d-1}-z^{d-1},dy^{d-1}-w^{d-1}, xz, yw \rangle
$$
So suppose $(x:y:z:w)$ is a singular point. Then $xz=0$. So, say, $x=0$. This implies $z=0$ (by the first equation), which implies $y(y^{d-1}-w^{d-1})=0$ by the equation of $f$. If $y=0$, we must have $w=0$, so all coordinates are zero! Contradiction. So assume $y^{d-1}-w^{d-1}=0$. Then by the second equation, we must have $dy^{d-1}-w^{d-1}=(d-1)y^{d-1}=0$, so $y=0$ now as well. So $w=0$ again! So either way, we don't get a point in projective space.

So suppoze $z=0$. Then $x=0$ by the first equation (and we repeat the arguments). 
\end{sol}

\begin{exc}[Exercise 1.5]
  \begin{enumerate}[a)]
  \item If $X$ is a surface of degree $d$ in $\PP^3$, then $K^2=d(d-4)^2$. 
\item If $X$ is a product of nonsingular curves $C,C'$ og genus $g,g'$, then $K^2=8(g-1)(g'-1)$.
  \end{enumerate}
\end{exc}

\begin{sol}
  a) By the adjunction formula, we have $\omega_X=\omega_{\PP^3} \otimes \OO_\PP(d) \otimes \OO_X=\OO_X(d-4)$. Thus, taking classes, we find that
$$
K_X = (d-4)H,
$$
where $H$ is the pullback of the hyperplane class in $\PP^3$. Hence $K^2=(d-4)^2 H^2$. Now, $H^2$ is the number of points in the intersection of $H \cap X$ and $H' \cap X$ where $H,H'$ are generic hyperplanes. But $H \cap X$ is a plane curve of degree $d$. Intersecting this with the line $H \cap H'$ gives $d$ points. Hence $K^2=d(d-4)^2$.

b).  
\end{sol}




%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Categories for the working mathematician - Saunders MacLane}
\subsection{Chapter 1.1}

\begin{exc}[1.1]
Show that each of the following constructions can be regarded as a functor: The field of quotiens of an integral domain; the Lie algebra of a Lie group.
\end{exc}
\begin{sol}
The first is a functor $\catname{Rings} \to \catname{Fields}$, since "obviously" the assignment $R \mapsto K(R)$ is functorial, since a morphism is determined by what it does to elements of $R$.

The second is a functor from the category of Lie groups to the category of Lie algebras. It sends a Lie group $G$ to its tangent space $T_eG$ at the identity.
\end{sol}

\begin{exc}[1.2]
Show that functors $1 \to C$, $2 \to C$ and $3 \to C$ correspond respectively to objects, arrows and composable pairs of arrows of $C$.
\end{exc}
\begin{sol}
A functor $1 \to C$ need not satisfy any compatability conditions, so the only data is an object in $C$.

A functor $F:2 \to C$ correspond to a choice of two objects $F(1),F(2)$ in $C$ such that there is an arrow $F(1) \to F(2)$.

A functor $F:3 \to C$ correspond to a choice of three objects in $C$ and arrows between them such that that the corresponding triangle commutes.
\end{sol}

\begin{exc}[1.4]
Prove that there is no functor $\catname{Grp} \to \catname{Ab}$ sending a group to its center.
\end{exc}
\begin{sol}
We take the hint and consider maps $S_2 \to S_3 \to S_2$. Let the first map be given by sending a permutation $(a_1a_2)$ to $(a_1a_23)$\footnote{Notation: $(a_1\ldots a_n)$ denotes the permutation sending $i$ to $a_i$.} Let the map $S_3 \to S_2$ be given by sending $\sigma$ to its signature $\pm 1$. Then the composite is the identity.

Denote the purported functor by $Z$.

But the center of $S_3$ is trivial. This forces $Z(f \circ g)$ to be the constant function $g \mapsto e$. However, as $f \circ g=\id_{S_2}$, this sshould be the identity, which it is not.
\end{sol}

\begin{exc}[1.5]
Find two different functors $T:\catname{Grp} \to \catname{Grp}$ with object function $T(G)=G$ for every group $G$.
\end{exc}
\begin{sol}
Here are two different functors: let the first one be the identity functor, sending each morphism $G \to H$ to itself. 

Let the other be the "trivial" functor, sending each morphism $G \to H$ to the trivial morphism $\epsilon:G \to H$, $g \mapsto e \in H$.

It is trivial that both of these are functors.
\end{sol}










%%%%%%%%%%%%%%%%%%%%
\section{Calculus on Manifolds - Spivak}

\subsection{Functions on Euclidean Space}

\begin{exc}[Exercise 1.1]
Prove that $\lvert x \rvert \leq \sum_{i=1}^n \lvert x^i  \rvert$.  
\end{exc}
\begin{sol}
 By induction, one can prove that $\sqrt{\sum_i a_i} \leq \sum_i \sqrt{a_i}$. The claim then follows trivially.
\end{sol}

\begin{exc}[Exercise 1.7]
A linear transformation $T:\R^n \to \R^n$ is \emph{norm preserving} if $\lvert T(x)\rvert = \lvert x \rvert$ for all $x \in \R^n$. It is inner product preserving if $\langle Tx,Ty \rangle = \langle x,y \rangle y$. 
\begin{enumerate}[a)]
\item Prove that $T$ is norm preserving if and only if it is inner product preserving.
\item Prove that such a linear transformation is $1-1$ and $T^{-1}$ is of the same sort.
\end{enumerate}
\end{exc}
\begin{sol}
a). The direction $\Leftarrow$ is trivial. For the other direction, choose a basis $\{x_1,\ldots,x_n\}$ of $\R^n$ such that $x=x_1$ and $y=\sum a_ix_i$. 
Then $\langle Tx ,a_ix_i \rangle = a_i \langle T x, x_i \rangle = 0$ if $i \neq 1$ and $a_1$ else. Then since $T(0)=0$ it follows that 
\[
\langle Tx, Ty \rangle = \langle Tx,T(a_1x_1) \rangle = a_1 \langle Tx_1,Tx_1 \rangle = a_1 \lvert Tx_1\rvert ^2 = a_1 \lvert x_1 \rvert ^2 = a_1\langle x_1,x_1 \rangle.
\]

b). Suppose $T(x)=0$. Then $0=\langle Tx,Tx \rangle = \langle x,x \rangle$, but this happens if and only if $x=0$. Also $\langle T^{-1} y,T^{-1}y \rangle = \langle T^{-1}T(x),T^{-1}T(x) \rangle = \langle TT^{-1}(x),TT^{-1}(x) \rangle = \langle T^{-1}x,T^{-1}x \rangle = \langle y,y \rangle$. 
\end{sol}

%%%%%%%%%%%%%%%
\section{Commutative Algebra - Eisenbud}

\subsection{Chapter 16 - Modules of Differentials}
\begin{exc}[Exercise 16.1]
Show that if $b \in S$ is an idempotent ($b^2=b$), and $d:S \to M$ is any derivation, then $db=0$.  
\end{exc}
\begin{sol}
This is trivial. $db=d(b^2)=2db$. If $2=0$, then the statement is automatically true. If not, then $db=0$ by subtraction. 
\end{sol}

%%%%%%%%%%%%%%%%%%%%%%%
\section{Complex Geometry - Daniel Huybrechts}

\subsection{1 Local Theory}

\begin{exc}[1.1.1]
Show that every holomorphic map $f:\C \to \mathbb H = \{ z \mid \Im z > 0 \}$ is constant.
\end{exc}
\begin{sol}
Note that $\mathbb H$ is holomorphic to the open unit disc via the Möbius transformation $z \mapsto i/z$. Then it follows from Liouville's theorem that any such map must be constant.
\end{sol}

\begin{exc}[1.1.2]
Show that the real and imaginary part $u$ and $v$, respectively, of a holomorphic function $f=u+iv$ are harmonic, i.e.
$$
\sum_i \frac{\partial^2 u}{\partial x_i ^2 } + \sum_i \frac{\partial^2 u}{\partial y_i^2} = 0,
$$
and similarly for $v$.
\end{exc}
\begin{sol}
It will be clear from the solution that without loss of generality, we can do this for the one-dimensional case. Then this follows trivially from the Cauchy-Riemann equations:
\begin{align*}
\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} &= \frac{\partial}{\partial x} \frac{\partial u}{\partial x} + 
\frac{\partial}{\partial x} \frac{\partial u}{\partial y} \\
&= \frac{\partial}{\partial x} \frac{\partial v}{\partial y} - 
\frac{\partial}{\partial y} \frac{\partial v}{\partial x} \\ 
&= 0.
\end{align*}
\end{sol}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Deformation Theory - Hartshorne}

\subsection{Chapter I.3 - The $T^i$ functors}

\begin{exc}[Exercise 3.1]
Let $B=k[x,y](xy)$. Show that $T^1(B/k,M)=M \otimes k$ and $T^2(B/k,M)=0$ for any $B$-module $M$.  
\end{exc}
\begin{sol}
Since $B$ is defined by a principal ideal in $P=k[x,y]$, it follows that $L_2=0$ in the cotangent complex. Thus $T^2(B/k,M)$ is automatically zero.

We have that $L_1 = B$ and $L_0 = B dx \oplus B dy$ with $d_1$ being $f \mapsto (fy,fx)$. Applying $\Hom(-,M)$, we get $\Hom(L_0,M)=M \oplus M$ and $\Hom(L_1,M)=M$.

We have $\Hom(B \oplus B,M) \simeq M \oplus M$ by $\phi \mapsto (\phi(1,0),\phi(0,1)$. We have a diagram
\[
\xymatrix{
\Hom(B \oplus B, M) \ar[d]_{\simeq} \ar[r]^{\psi^\ast} & \Hom(B,M) \ar[d]^{\simeq} \\
M \oplus M  \ar[r] & M
}
\]
Under these isomorphisms, it is easy to see that the bottom map is given by
\[
(\phi(1,0),\phi(0,1)) \mapsto y \phi(1,0) + x\phi(0,1).
\]
Thus since $T^1$ is the cokernel of this map, we must have $T^1(B/k,M) = M \otimes k$. 
\end{sol}

\begin{exc}[Exercise 3.3]
Let $B = k[x,y]/(x^2,xy,y^2)$. Show that $T^0(B/k,B) = k^4$, $T^1(B/k,B)=k^4$ and $T^2(B/k,B)=k$.  
\end{exc}

\begin{sol}
Let's compute $L_2$ first. For that we need part of a resolution of $I$. We have in fact
\[
0 \to \im \begin{pmatrix} -y & 0 \\ x & -y \\ 0 & x \end{pmatrix} \to P(-2)^3 \to I \to 0.
\]
The Koszul relations are given by 
\[
\im \begin{pmatrix}
-y^2 & -xy & 0 \\
0 & x^2 & -y^2 \\
x^2 & 0 & xy
\end{pmatrix}.
\]
Let's compute $Q/F_0$ (relations modulo Koszul relations). Since $Q$ is generated in degree $3$, and $F_0$ is of degree $4$, we have $\dim_k (Q/F_0)_3 = 2$. Let's consider degree $4$. As a $k$-vector space $Q_4$ is spanned by the four elements
\[
\begin{pmatrix}
  -y^2 \\ xy \\ 0 
\end{pmatrix},
\begin{pmatrix}
  0 \\ -y^2 \\ xy 
\end{pmatrix},
\begin{pmatrix}
  -yx \\ x^2 \\ 0
\end{pmatrix},
\begin{pmatrix}
  0 \\ -yx \\ x^2
\end{pmatrix}.
\]
The two in the middle are already Koszul relations, so that $(Q/F_0)_4$ have dimension $\leq 2$. But we also have
\[
\begin{pmatrix}
  -y^2 \\ xy \\ 0
\end{pmatrix} = 
\begin{pmatrix}
0 \\ yx \\ -x^2 
\end{pmatrix}
+
\begin{pmatrix}
-y^2 \\ 0 \\ x^2
\end{pmatrix}.
\]
Thus $\dim_k (Q/F_0)_4=1$, since the second term above is a Koszul relation. Similarly we find that $\dim_k (Q/F_0)_5 =0$. Hence, $L_2$ is the $3$-dimensional $k$-vector space spanned by $Q_3$ and one more relation. $L_1$ is $F \otimes B=B^3$, and $L_0$ is $B \oplus B$, spanned by $dx,dy$.

Taking duals, we get that $L_2 = \Hom(Q/F_0,B)$. This set can be identified with
\begin{align*}
\Hom(Q/F_0,B) &= \{ \varphi: Q \to B \mid \restr{\varphi}{F_0} = 0 \} \\
&= \{ \varphi: Q \to P \mid \im \restr{f}{F_0} \subseteq I \}
\end{align*}
Thus, since $I= \mm^2$, we must have that $\varphi$ sends the two generators of $Q$ to something of degree $1$ (degree $0$ is not ok, since then $F_0$ would be sent outside $I$). Thus $\Hom(Q/F_0,B)$ is $2 \times 2=4$-dimensional, spanned by 
\[
\im 
\begin{pmatrix}
  y & x & 0 & 0 \\
0 & 0 & x & y
\end{pmatrix}.
\]
But $d_2$ is the dual of the inclusion $Q \to F$ from the exact sequence above. The dual is given by transposing, and we are left with one column - in conclusion, $T^2(B/k,B)$ is one-dimensional.

The Jacobian of $I$ is given by
\[
\begin{pmatrix}
  2x & y & 0 \\
0 & x & 2y 
\end{pmatrix},
\]
and it is easily seen that the kernel of $\text{Jac} \otimes B$ is given by $\mm \oplus \mm \oplus \mm \subset B^3$. The two relations kill off two dimensions, so $\dim_k T^1(B/k,B) = \dim_k \mm^{\oplus 3} - 2 = 6-2=4$.

Also $T^0(B/k,B)$ is $B^2$ modulo the image of the Jacobian. The constants are left untouched, so $\dim_k T^0(B/k,B) = 2+2+2-3=3$. A basis is given by $(1,0),(0,1)$ and $(x,y)$. (thus Hartshorne is wrong?)
\end{sol}

\section{Geometry of differential forms - Morita}

\subsection{Chapter 1 - Manifolds}

\begin{exc}[1.1] For a natural number $m$, define a map $f_m:\C \to \C$ by $z \mapsto z^m$. Let $z=x+iy$, and consider $f_m$ as a function of $x$ and $y$. Compute the Jacobian matrix of $f_m$.
\end{exc}
\begin{sol}
We consider $f_m$ as a map $\R^2 \to \R^2$. Write $f_m = r_m + i j_m$. Then we want compute $\dd{r_m}{x}$,$\dd{r_m}{y}$ and $\dd{j_m}{x}$ and $\dd{j_m}{y}$. Now
\[
\dd{}{x} \left( x+iy\right) ^m  = m (x+iy)^{m-1}
\]
and 
\[
\dd{}{y} (x+iy)^m = im(x+iy)^{m-1}.
\]

Now taking real parts ($\Re$) and taking imaginary parts ($\Im$) are continous operations $\C \to \R$, so they commute with limits and hence derivatives. Hence
\[
\dd{r_m}{x} = \Re \left( m(x+iy)^{m-1} \right) = m \Re(z^{m-1})
\]
and 
\[
\dd{r_m}{y} = \Re \left( mi(x+iy)^{m-1}  \right) = -m \Im(z^{m-1})
\]
since in general $\Re(iz)=-\Im(z)$. Similarly 
\[
\dd{j_m}{x} = \Im \left( m(x+iy)^{m-1} \right) = m \Im(z^{m-1})
\]
and 
\[
\dd{j_m}{x} = \Im \left( im(x+iy)^{m-1} \right) = \Re( z^{m-1}).
\]
Hence the Jacobian matrix is
\[
\begin{bmatrix}
m \Re(z^{m-1}) & -m\Im(z^{m-1}) \\
m \Im(z^{m-1}) & m\Re(z^{m-1})
\end{bmatrix},
\]
with determinant $m^2 \lvert z \rvert ^2$.
\end{sol}

\begin{exc}[1.2]
Prove that the set of all the orthogonal matrices of order $2$, denoted $O(2)$ becomes a $C^\infty$ manifold in a natural way.
\end{exc}
\begin{sol}
Let $a,b,c,d$ be coordinates on $M_2(\R)$. Then the equations of $O(2)$ are given by
\begin{align*}
 a^2+b^2- 1 &= 0 \\
ac+bd &= 0 \\
c^2+d^2 -1&= 0
\end{align*}
Hence the Jacobian is
\[
\begin{bmatrix}
2a & 2b & 0 & 0 \\
c & d & a & b \\
0 & 0 & 2c & 2d
\end{bmatrix}.
\]
We want this to have maximal rank. The determinant of the first minor (choosing the first three columns) is $4c(ad-bc)$. Hence this has maximal rank if and only if $c \neq 0$. So suppose $c=0$. Then $d^2=\pm 1$, hence $d=\pm 1$, hence $b = 0$, hence $a^2=1$, hence $a= \pm 1$. Hence the only two matrices in $O(2)$ with $c=0$ are the identity matrix $I$ and $-I$. But by inspection, both these values are regular, hence $O(2)$ is a $C^\infty$ submanifold of $M_2(\R)$ by the inverse function theorem.

In fact, since the Jacobian have rank 3, it follows that $O(2)$ is one-dimensional. In fact it is diffeomorphic to two disjoint copies of $S^1$.
\end{sol}

\begin{exc}[1.3]

Show that the $1$-dimensional complex projective space $\C P^1$ is diffeomorphic to $S^2$.
\end{exc}

\begin{sol}
We define a map $\C P^1 \to S^2$ locally. That is, both spaces are covered by two charts, and we check that the maps agree on intersections. It will be clear from the construction that it is injective and surjective and $C^\infty$, and since the spaces are compact, there exists an inverse.

$\C P ^1$ is covered by two charts $i_1:(x,y) \mapsto [x+iy,1]$ and $i_2:(x,y) \mapsto [1,x+iy]$. Similarly, $S^2$ is covered by two charts, given by stereographic projection. The formulas are $j_1^{-1} (x,y,z) = \left (\frac{x}{1-z}, \frac{y}{1-z}\right)$ and $j_2^{-1}(x,y,z) = \left( \frac{x}{1+z},\frac{y}{1+z} \right)$ with inverses $j_1(a,b) = \left( \frac{2a}{1+a^2+b^2}, \frac{2b}{1+a^2+b^2}, \frac{-1+a^2+b^2}{1+a^2+b^2}\right)$ and $j_2(a,b) = \left( \frac{2a}{1+a^2+b^2}, \frac{2b}{1+a^2+b^2}, \frac{1-a^2-b^2}{1+a^2+b^2} \right)$.

Define a map $\C P^1 \to S^2$ by the identity map on the chart corresponding to $i_1$ and on the other chart, let the map be given by $\varphi: (a,b) \mapsto (a,-b)$. Then one can check that $ j_2 \circ \varphi \circ i_2^{-1} \circ i_1 = j_1$.

Hence the diagram
\[
\xymatrix{
 & \C P^1 \ar[r] & S^2 & \\
\R^2 \ar[ur]^{i_1} \ar[dr]^{i_2^{-1} \circ i_1} \ar[rr] & & \R^2 \ar[dr]_{j_2^{-1} \circ j_ 1} \ar[u]^{j_1} & \\
& \R^2 \ar[uu]_{i_2} \ar[rr]^\varphi & & \R^2 \ar[uul]_{j_2} 
}
\]
And this defines a map $\C P^1 \to S^2$. 

This map globalizes to
\[
\C P ^1 \ni [x+iy, a+ib] \mapsto \left( \frac{2ax+2by}{a^2+b^2+x^2+y^2}, \frac{2ay-2bx}{a^2+b^2+x^2+y^2}, \frac{a^2+b^2-x^2-y^2}{a^2+b^2+x^2+y^2}\right) \in S^2
\]
\end{sol}


%%%%%%%%%%%%%%%%%%%
\section{Foundations of Algebraic Geometry - Vakil}

\subsection{Chapter 21 - Differentials}

\begin{exc}[Excercise 21.2.F]
\begin{enumerate}[a)]
\item Suppose $K/k$ is a separable algebraic field extension. Show that $\Omega_{K/k}=0$.
\item Suppose $char k = p$ and and let $K = k(t^p)$ and $L=k(t)$. Compute $\Omega_{L/K}$. 
\end{enumerate}
\end{exc}
\begin{sol}
\begin{enumerate}
\item Choose a nonzero $\alpha \in K$. By definition it satisfies a polynomial equation $f(\alpha)=0$ such that $f'(\alpha) \neq 0$. Then a computation gives that
$$
0 = d(f\alpha) = f'(\alpha)d\alpha.
$$
This implies $d \alpha = 0$, so $\Omega_{K/k}=0$.
\item Write $L=K[x]/(x^p-t^p)$. Then $\Omega_{L/K}=L dx/df$. But $df=d(x^p-t^p)=px^{p-1}dx=0$. Hence $\Omega_{L/K}$ is just the free $L$-module generated by $t$. 
\end{enumerate}
\end{sol}



%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hodge theory and algebraic geometry - Voisin}

\subsection{Chapter 1 - Holomorphic functions of many variables}

\begin{exc}
Let $\phi:U \to \C$ be a holomorphic map from an open subset of $\C^n$ to an open subset of $\C^n$. Show that the set 
$$
R = \{ x \in U \mid d\phi_x \text{ is not an isomorphism}\}
$$
is defined $U$ by precisely one holomorphic equation.
\end{exc}
\begin{sol}
The function $d\phi_x$ is precisely the Jacobian matrix of $\phi$. Hence $R = V(\det d\phi_x)$. 
\end{sol}

\begin{exc}
Let $f$ be a holomorphic function defined on an open subset $U$ of $\C^n$. We assume that $f$ does not vanish outside the set 
$$
\{ z = (z_1,\ldots,z_n) \in U \mid z_1=z_2 = 0\}.
$$
Show that $f$ does not vanish at any point of $U$.
\end{exc}
\begin{sol}
Let $V= \{ z = (z_1,\ldots,z_n) \in U \mid z_1=z_2 = 0 \}$. The condition implies that $1/f$ is holomorphic on $V$. Then it follows from Hartog's extension theorem that $1/f$ extends to a holomorphic function on $U$. But this implies that $f$ has no zeroes on $U$.
\end{sol}

\begin{exc}
Let $f$ be a meromorphic function defined on an open subset $U \subset \C$. This means that $f$ is locally the quotient of two holomorphic functions.
\begin{enumerate}
  \item Show that for any compact subset $K \subset U$, the number of zeros or poles of $f$ in $K$ is finite.
  \item Let $x \in U$. Show that there exists an integer $k_x \in \Z$ such that $f$ can be written as $(z-x)^{k_x}\phi$ in a neighbourhood of $x$, with $\phi$ holomorphic and invertible. The \emph{divisior} of $f$ is then defined as the locally formal finite sum
  $$
\sum_{x \in U} k_x x.
  $$

  \item Let $x \in U$ and $D \subset U$ be a disk centred in $x$, such that $x$ is the only pole or zero of $f$ in $D$. Show that
  $$
k_x = \int_{\partial D} \frac{1}{2\pi i}\frac{df}{f}.
  $$
\end{enumerate}
\end{exc}
\begin{sol}
\begin{enumerate}
  \item Suppose for contradiction that $f$ has infinitely many zeroes on $K$. Then since $K$ is compact, there is some accumulation point $0 \in K$. Write $f=\sum_{i=0}^\infty a_iz^i$ as a power series around $0$. Since $f(0)=0$, we know $a_0=0$. If $f \neq 0$, let $m$ be the least integer such that $a_m \neq 0$. Then $f(z)=z^{m-1}h(z)$, where $h(0) \neq 0$, and by continuity, is non-zero in a small ball around $0$. But this contradicts the assumption, since the only zero of $f$ in this ball is $0$, but $0$ was an accumulation point of zeroes.

  Repeat the same argument with $1/f$ to obtain finiteness of number of poles.
  \item Do the same as above. Write $f$ as a Laurent series at a zero or a pole. 
  \item Assume for simplicity that $x=0$. In a neighbourhood of $0$, we can write $f=z^{k_0} \phi$. Hence $df=k_0z^{k_0-1}\phi + z^{k_0}d\phi$. Hence
  $$
\frac{1}{2\pi i} \int_{\partial D} \frac{df}{f} = \frac{1}{2 \pi i} \left( \int_{\partial D} \frac{k_0 dz}{z} + \frac{d\phi}{\phi} \right).
  $$
  The term $\frac{d\phi}{\phi}$ is equal to $\dd{\phi}{z} dz$. The derivative is a holomorphic function, and by Lemma 1.12, the differential is closed. Hence it follows by Stoke's theorem, that the integral of the second term vanishes. 

  The first term evaluates to $k_0$ by a standard parametrization.
\end{enumerate}
\end{sol}

\subsection{Chapter 2 - Complex manifolds}

\begin{exc}[Double covers]
Let $X$ be a complex manifold and $L$ a holomorphic line bundle on $X$. Assume there exists a line bundle $K$ such that $K^{\otimes 2} \simeq L$. Assume we are given a non-zero holomorphic section $\sigma$ of $L$. We denote by $\Sigma \subset L$ the image of $\sigma$.

\begin{enumerate}
  \item Show that the map $\phi:K \to L$ given by $(x,\tau) \mapsto (x,\tau^2)$ is a proper holomorphic map.
  \item Let $R \subset X$ be the vanishing locus of $\sigma$. With the help of a local trivialization of $L$, $R$ is locally defined by one holomorphic equation.

  Show that $Y:= \phi^{-1}(\Sigma)$ is smooth if and only if $R$ is smooth.
  \item Show that when $R$ is smooth, $\phi:Y \to \Sigma \simeq X$ is ramified exactly along $\phi^{-1}(R) \simeq R$. Show that the fibre $\phi^{-1}(x)$ consist of two distinct points when $x \not \in \R$.
\end{enumerate}
\end{exc}

\begin{sol}
\begin{enumerate}
  \item For Hausdorff and locally compact spaces, properness is equivalent to having compact fibers over points (source/proof?). But clearly the fibers here are either two points or a single (doubled) point.
  \item If $\sigma$ is the section, it is locally $\sigma:\C^n \to \C^n \times \C$ given by $x \mapsto (x,f(x))$. Hence locally the vanishing locus is given by $f(x)=0$.

Locally $\Sigma = \{ (x,f(x)) \mid x \in \C^n \}$. Hence $Y$ is given locally by $\{ (x,z) \mid z^2=f(x) \}$. This is a manifold defined by a single equation, hence its smoothness is given by the simultaneous vanishing of the derivatives of $z$ and $x$. The singularities are thus $z=0$ and $\nabla (f) = 0$. But if $R$ is smooth, $\nabla(f)=0$ has no solutions. Hence $Y$ is smooth if and only if $R$ is smooth.
\item The map $\phi:Y \to \Sigma \simeq X$ is locally given by $(x,z) \mapsto x \in \C^n$. Hence it ramifies where $z^2=f(x)$ has two solutions for fixed $x$. But this occurs exactly at the zeroes of $f(x)$, which is $R$. 

If $x \not \in R$, there are two solutions. (I don' think we needed to use that $R$ was smooth anywhere?)
\end{enumerate}
\end{sol}


\begin{exc}[Degree of a map to $\PP^1$]

Let $X$ be a compact complex curve and let $f$ be a non-constant meromorphic function on $X$. 
\begin{enumerate}
  \item Show that we can view $f$ as a holomorphic map from $X$ to $\PP^1$. Here we see $\PP^1$ as the compactification $\C = \C \times \{1\} \subset \C^2$ obtained by adding the point $(1,0)=\infty$.
  \item Let $t \in PP^1$. Let $D$ be a disc in $\PP^1$ centred at $t$. Using exercise 3c above, show that 
$$
n_t := \frac{1}{2\pi i} \int_{f^{-1}(D)}  \frac{df}{f-t}
$$
is equal to the number of points of the fibre $f^{-1}(t)$, counted with multiplicities given by the order of vanishing $k_x$ of $f-t$.
\item Show that $n_t$ is independent of $t$.
\item Show that $f$ is ramified at a point $x$ if and only if the order of vanishing $k_x$ of $f-t$ is at least $2$. Deduce from Sard's theorem that for $t$ in a dense set of points the fibre $f^{-1}(t)$ is a set of finite cardinality $n$. We call it the degree of the map $n$.
\item Deduce the following result: the divisor $f^{-1}(0)-f^{-1}(\infty)$ of $f$ is of degree $0$. 
\item Show using the maximum principle that a connected compact complex manifold possesses no holomorphic functions other than the constant ones.
\end{enumerate}
\end{exc}
\begin{sol}
\begin{enumerate}
  \item A meromorphic map is locally given as $z \mapsto f(z)/g(z)$ where $f,g$ are holomorphic functions. We can assume they have no common zeroes. Hence we get a map given by $z \mapsto (f(z):g(z))$. This is clearly the same map, when restricted to the chart $t \neq \infty$.
  \item First note that there are only finitely many fibers because $X$ is compact. We can assume $t=0$ for simplicity. Hence we are looking at $f^{-1}(0) \subset X$, which is a finite set of points. Then we can find a simply-connected open subset $U$ containing all of them. This $U$ can be thought of as a subset of $\C$ (draw a picture). On this open subset, $f$ is given as $g/h$ where $g,h$ are holomorphic functions.

  The inverse image $f^{-1}(\partial D)$ is for a small enough disk a circle around each of the zeroes $x_i$ of $f$, where $f$ can be locally written as $f=(z-x_i)^{k_{x_i}}\phi$.  Summing all the $k_{x_i}$, we get the number of elements in the fibre.
  \item Note than $n_t$ is the composition of $f$ with the map
  $$
t \mapsto \frac{1}{2\pi i} \int_{f^{-1}(\partial D)} \frac{df}{f-t}.
  $$

  This is a continous map in $t$ with image $\Z$, which is a discrete set. Hence $n_t$ must be locally constant.
  \item Again, we can assume $t=0$. Assume the order is at least $k \geq 2$. Then $f$ can be written as $f=z^kg$ for some function $g$ holomorphic and nonzero in a neighbourhood of the zero $x$. Clearly $f$ is ramified at $x$, since now $f$ is locally a $k:1$ map, but the fibers over $0$ are $k$-fold.

  Conversely, assume $f$ is ramified at $x$. This means that in a neighbourhood of $x$, $f$ is $k:1$, but $l:1$ for $l < k$ at $x$. The fibers are counted with multiplicities of size $n$, so since $f$ is $l:1$ at $x$, this means that the zero must be of order $\geq 2$ (sketchy...).
  \item This says that the number of zeroes equals the number of poles. This follows directly from 3) as follows. The number of zeroes is the cardinality of $f^{-1}(0)$, while the number of poles is $f^{-1}(\infty)$. But this number is independent of $t$, hence they are equal!
  \item Let $f$ be a holomorphic function on $X$. The maximum principle says that a holomorphic function on a connected open subset of $\C$ cannot have local maxima. But since $X$ is compact, $f$ cannot be unbounded. Hence it has some local maximum, but this implies that $f$ must be constant.
\end{enumerate}
\end{sol}



%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction to Differential Geometry - Spivak}

\subsection{Chapter 1 - Manifolds}

\begin{exc}[Exercise 3]
  \begin{enumerate}[a)]
  \item Every manifold is locally compact.
\item Every manifold is locally pathwise connected, and a connected manifold is pathwise connected.
\item A connected manifold is arcwise connected. (\emph{Arcwise connected} means that any two points can be connected by a $1-1$ path.)
  \end{enumerate}
\end{exc}

\begin{sol}
  \begin{enumerate}[a)]
  \item Indeed, let $x:\R^n \to U \subset M$ be a homeomorphism of an open subset of $M$ with $\R^n$. Then the image of $[0,1]^n$ is compact in $M$. 
\item The first part follows in the same way, since $M$ is locally homeomorphic to $\R^n$. Now assume that $M$ is connected. Fix $q \in M$. Let $V$ be the set of all points in $M$ such that there is a path from $q$ to $p$. Clearly $V$ is non-empty, by the first part of the exercise.

$V$ is also open: For let $p \in V$. Choose a neighbourhood $U$ around $p$ homeomorphic to $\R^n$. By composing paths, any point in $U$ can be reached as well. Hence $V$ is open.

We show that $V$ is closed: let $\{p_i \}$ be a convergent sequence of points $p_i \in M$ with all $p_i \in V$. We want to show that the limit point is contained in $V$. Choose a compact neighbourhood around $\lim p_i = p$, which we can assume to be $\approx [0,1]^n$. Then $p \in [0,1]^n$, and this is path connected. Hence $V$ is closed.
\item For $n > 2$, one can always homotope away from the points of non-injectivity. For $n=2$, one can do ``Reidemeister'' moves.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 4]
A space $X$ is called locally connected if for each $x \in X$, it is the case that every neoughbourhood of $x$ contains a connected neighbourhood. 
\begin{enumerate}[a)]
\item Connectedness does not imply local connectedness.
\item An open subset of a locally connected space is locally connected.
\item $X$ is locally connected if and only if components of open sets are open, so every neigbourhood of a point in a locally connected space contains an \emph{open} connected neighbourhood.
\item A locally connected space is homeomorphic to the disjoint union of its components.
\item Every manifold is locally connected, and consequently homeomorphic to the disjoint union of its components, which are open submanifolds.
\end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item Consider the topologist's since curve. Every neighbourhood of $0$ is diconnected.
\item This is ``trivial''. Let $U$ be the said open subset. The open subsets of $U$ are intersections $U \cap V$ where $V$ is open in $X$. Hence local connectedness is trivially inherited.
\item Suppose $X$ is locally connected. Let $U \subset X$ be an open set, and let $U= \cup_i U_i$ be its decomposition into its components. We want to show that each $U_i$ is open. So let $x \in U_i$. Then $U_i$ contains a connected neighbourhood containing $x$, by definition, hence $U_i$ is open.

Conversely, assume components of open sets are open. Let $x \in X$, and let $U$ be an open neighbourhood of $x$. Then $U_i$ as above is connected and can be chosen to contain $x$, hence $x$ is locally connected.

\item This is trivial, since the components are open.

\item Pathwise local connectedness implies local connectedness.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 15]
  \begin{enumerate}[a)]
  \item   Show that $\PP^1$ is homeomorphic to $S^1$. (in fact, diffeomorphic)
\item Show that $\PP^n \bs \PP^{n-1}$ is homeomorphic to the interior $D^n=\{ x \in \R^n \mid d(x,0) < 1 \}$.
  \end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item Both $\PP^1$ and $S^1$ can be covered by two open subsets homeomorphic to $\R$, and it can be checked that in both cases, the transition mapping is given by $x \mapsto \frac 1x$, hence they are glued in the same way, hence they must be diffeomorphic.S
\item By using homogeneous coordinates, we see that $\PP^n \bs \PP^{n-1}$ is homeomorphic to $\R^n$ which is again homeomorphic to the interior of a disc.
  \end{enumerate}
\end{sol}

\subsection{Chapter 3 - The tangent bundle}
\begin{exc}
Show that in the definition of an equivalence it suffices to assume that the map $E_1 \to E_2$ is continous. 
\end{exc}
\begin{sol}
Okay, so the assumptions are now that there is a continous map $f:E_1 \to E_2$  and a commuting diagram
$$
\xymatrix{
E_1 \ar[dr]_{\pi_1} \ar[r]^f & E_2 \ar[d]^{\pi_2} \\
& B
}
$$
taking each fibre $\pi_1^{-1}(p)$ isomorphically onto $\pi_2^{-1}(p)$. We want to show that $f$ is a homeomorphism.

First we show that $f$ is bijective by defining a set-theoretic inverse $g:E_2 \to E_1$. Suppose $q \in E_2$. Then $q \in \pi_2^{-1}(\pi_2(q))$. But $\restr{f}{\pi_1^{-1}(\pi_2(q))}$ is a vector space isomorphism, so we define
$$
g(q) = \restr{f}{\pi_1^{-1}(\pi_2(q))}^{-1}(q).
$$

The next step is to show that $g$ is continous. This actually follows from the local triviality condition. For each open $U$ on $B$ on which $E_1,E_2$ both are trivial. Then there are isomorphisms $\restr{E_1}{U} \simeq U \times \R^n$ and $\restr{E_2}{U} \simeq U \times \R^n$, then we have a commutative diagram
$$
\xymatrix{
U \times \R^n  \ar[dr]^{\pi_1} \ar[r]^{f'} & U \times \R^n  \ar[d]^{\pi_2}\\
& U 
}
$$

The commuting condition implies that $f'$ is the identity on the first factor, and thus $f'$ is \emph{linear} map on the second factor. Linear maps are always continous.
\end{sol}

\begin{exc}
Show that in the definition of bundle map, continuity of $f:B_1 \to B_2$ follows automatically from continuity of $\widetilde f:E_1 \to E_2$. 
\end{exc}
\begin{sol}
Again, this is local triviality. Choose a trivialization so that the map is given by $U \times \R^n \to V \times R^m$. This is continous by assmuption. Choose open $W \subset V \subset B_2$. The map $\pi_2$ is continous (of course), and by continuity of $\widetilde f$ and openness of $\pi_1$, we have $f^{-1}(W)=\pi_1( \widetilde f ^{-1}(\pi_2^{-1}(W)))$ which is open.
\end{sol}

\begin{exc}
For a bundle map $(\tilde f, f)$, with $f:B_1 \to B_2$, let $K_p$ be the kernel of the map $\restr{\tilde f}{\pi_1^{-1}(p)}$ from $\pi_1^{-1}(p)$ to $\pi_2^{-1}(f(p))$.
\begin{enumerate}
\item If $p \mapsto \dim K_p$ is continous, then $\ker \tilde f$, the union of all $K_p$ is a bundle over $B_1$.
\item 
\end{enumerate}
\end{exc}
\begin{sol}
1. The condition says that $\dim \ker K_p$ is constant on connected components, so we may as well assume that $\dim \ker K_p$ is constant and $B_1$ is connected.

First choose a small open set $U \subset B_2$ such that $E_1,E_2$ are both trivial over $V=f^{-1}(U)$ and $E_2$, respectively.

Then the map $\restr{E_1}{V} \to \restr{E_2}{U}$ takes the form $(v,p) \mapsto (f(v),f_2(v,p))$, since this is a bundle map (follows from commutativity).

Then
$$
\restr{\ker \tilde f }{V} \simeq \left\{ (v,p) \in V \times \R^n \mid f_2(v,p)=0 \right\}.
$$
Since $\tilde f_2$ is linear in the second variable, we can write $\restr{\ker \tilde f }{V}$ as the kernel of matrix with functional entries. If the dimension of the kernel is $q$, then there is some $q \times q$-minor that doesn't vanish. 
\end{sol}

\subsection{Chapter 4 - Tensors}

\begin{exc}[Exc 1]
Let $f:M^n \to N^m$ and suppose $(x,U),(y,V)$ are coordinate systems around $p$ and $f(p)$, respectively.
\begin{enumerate}[a)]
\item If $g:N \to \R$, then
\[
\dd{(g \circ f)}{x^i}(p) = \sum_{j=1}^m \dd{g}{y^j}(f(p)) \dd{(y^j \circ f)}{x^i} (p).
\]
\item Show that
\[
f_\ast \left( \restr{\dd{}{x^i}}{p} \right) = \sum_{j=1}^m \dd{(y^j \circ f)}{x^i}(p) \restr{\dd{}{y^j}}{f(p)}.
\]
\item 
Show that
$$
(f^\ast dy^j)(p) = \sum_{i=1}^n \dd{(y^j \circ f)}{x^i}(p) dx^i(p).
$$
\end{enumerate}
\end{exc}
\begin{sol}
a)

This is of course the chain rule together with deciphering of the definitions. By definition
$$
\dd{ (g \circ f)}{x^i}(p) = D_i(g \circ f \circ x^{-1}).
$$
Which is equal to

$$
 D_i(g \circ f \circ x^{-1}) =  D_i(g \circ y^{-1} \circ y \circ  f \circ x^{-1})
$$
which by the chain rule is
$$
\sum_{j=1}^n D_j(g \circ y^{-1})(y \circ f(p)) \cdot D_i(y \circ f \circ x^{-1})^j ( x(p)) 
$$
which by definition is equal to what we want.

b)

This is easier. We know that $f_\ast( \dd{}{x^i})$ is a certain linear combination of $\dd{}{y^j}$'s. So we just have to verify the coefficients.

We use that $\dd{}{y^j} y^i = \delta_i^j$. That is, the coefficients are determined by the $m$ coordinate functions $y^i$. 

Thus each coefficient is given by $(f_\ast \dd{}{x^i})(y^j) \stackrel{def}{=} \dd{(y^j \circ f)}{x^i}$.


c)

Solved similarly as above. We know that $f^\ast dy^j$ is a certain linear combination of $dx^i$'s. To get the coefficients, we use that $dx_j(\dd{}{x^i})= \delta_i^j$. Then
$$
(f^\ast dy^j)_p(\dd{}{x^i}) \stackrel{def}{=} dy^j_{f(p)} \left(f_\ast \restr{\dd{}{x^i}}{p}\right).
$$
By the above, this is
$$
dy^j_{f(p)} \left( \sum_{j=1}^m \dd{(y^j \circ f)}{x^i}(p) \restr{\dd{}{y^j}}{f(p)}\right)
$$
The only surviving term in the sum is $\frac{(y^j \circ f)}{x^i}(p)$. This is exactly the coefficient we want.

\end{sol}


\subsection{Chapter 5 - Vector fields and differential equations}

\begin{exc}[Exercise 1]
\begin{itemize}
\item If $\alpha:M \to N$ is $C^\infty$, then $\alpha_\ast:TM \to TN$ is $C^\infty$. 
\item If $\alpha:M \to N$ is a diffeomorphism and $X$ is a vector field on $M$,then $\alpha_\ast M$ is a $C^\infty$ vector field on $N$.
\item If $\alpha: \R \to \R$ is $\alpha(t)=t^3$, then there is a $C^\infty$ vector field on $\R$ such that $\alpha_\ast X$ is not $C^\infty$.
\end{itemize}
\end{exc}

\begin{sol}
\begin{itemize}
\item This is clear, since the map from tangent bundles is just the Jacobian matrix. Explicitly, we can WLOG assume $M=\R^n$ and $N=\R^m$ with $TM=\R^n \X \R^n$ and $TN= \R^m \X \R^m$. Then $a_\ast$ is given by $(v,p) \mapsto (d\alpha(p)(v), \alpha(p))$, where $d\alpha(p)$ is the Jacobian matrix evaluated at $p$.
\item The same strategy. We assume $M= \R^n$ and $N=\R^m$. The difference between $\alpha_\ast$ and $\alpha_\ast X$ is that the former is a map between the tangent bundles and the latter is a section of $N$.

Then, chasing through the definitions, if the $X$ is given by $p \mapsto (f(p),p)$, the section $\alpha_\ast X ( q) $ is given by $ q \mapsto \left(d(\alpha^{-1}(q))(f(\alpha^{-1}(q))),q\right)$.

But this is clearly $C^\infty$ since $\alpha^{-1}$ is.

\item Every vector field on $\R$ have the form $X=f \dd{}{t}$ for some function $f$. Let $f=1$. That is, $X$ is the vector field $s \mapsto (1,s)$. Then by the above, $\alpha_\ast X(s)=(\restr{(3s^2)}{s^{\frac 13}} \cdot 1 , s) = (3s^{\frac 23},s)$ which is not $C^\infty$. 
\end{itemize}
\end{sol}

\begin{exc}[Exercise 10a]
Prove that
\[
L_X(f \omega ) = \omega L_X f + f L_X w.
\]
\end{exc}
\begin{sol}
Two things are needed for this: 1) Note that $\varphi_h^\ast(f \omega)(p) = f(\varphi_h(p)) \varphi_h^\ast \omega(p)$. 2) The standard proof of the product rule. The rest is routine.
\end{sol}





%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction to Commutative Algebra - Atiyah-MacDonald}

\subsection{Chapter 1 - Rings and ideals}

\begin{exc}
Let $x$ be a nilpotent element of a ring $A$. Show that $1+x$ is a unit of $A$. Deduce that the sum of a nilpotent element and a unit is a unit.
\end{exc}
\begin{sol}
Suppose $x^{n+1}=0$ and that $x^n \neq 0$. Consider
\[
s = 1-x+x^2-x^3+\ldots+x^n
\]
Then
\[
sx = x-x^2+x^3-x^4+\ldots-x^n
\]
since $x^{n+1}=0$. But then $s+sx=1$, so that $s(1+x)=1$. Hence $1+x$ is a unit. To prove that the sum of any unit and any nilpotent is a unit, note that if $u$ is any unit, then $u^{-1}x$ is still nilpotent. So since $u+x=u(1+u^{-1}x)$ and product of units are units, the claim follows.
\end{sol}

\begin{exc}[Exercise 11]
A ring $A$ is \emph{Boolean} if $x^2=x$ every $x \in A$. In a Boolean ring $A$, show that
\begin{enumerate}[i)]
\item $2x=0$ for all $x \in A$.
\item Every prime ideal $\pp$ is maximal, and $A/\pp$ is a field with two elements.
\item Every finitely generated ideal in $A$ is principal.
\end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[i)]
  \item We have $4x=4x^2=(2x)^2=2x$, hence $2x=0$.
\item Consider $A/\pp$. This is an integral domain in which $x^2=x$ for all $x \in A/\pp$. But then $x^2-x=x(x-1)=0$. Hence either $x=0$ or $x=1$, hence $A/\pp$ can have only two elements. Thus it is isomorphic to $\Z/2\Z$ which is a field, hence $\pp$ is maximal.
\item Let $I=(a_1,\cdots,a_r)$. Every ideal is contained in a maximal ideal $\mm$. Consider the image of $I$ in $A/\mm$. 
\item By induction we can assume that $I$ is generated by two elements, say $I=(a_1,a_2)$. Then I claim that $I=(a_1+a_2)$. Cleary $(a_1+a_2) \subseteq (a_1,a_2)$. The other direction will follow if we can see that $a_1a_2=0$ (or they can be assumed to satisfy this), because $a_1a_2+a_1 \in (a_1+a_2)$.  [[[[[[[[[[[????]]]]]]]]]]]
\end{enumerate}
\end{sol}

\begin{exc}[Exercise 12]
A local ring contains no nontrivial idempotents.  
\end{exc}
\begin{sol}
Suppose $x \neq 0,1$ and that $x^2=x$. Then $x^2-x=x(x-1)=0$. Both $x$ and $x-1$ cannot be contained in $\mm$ since they generate $A$. Hence one of the is unit. Hence either $x=0$ or $x=1$, contradiction. 
\end{sol}

\begin{exc}[Exercise 15, The prime spectrum of a ring]

Let $A$ be a ring and let $X$ be the set of prime ideals of $A$. For each subset $E$ of $A$, let $V(E)$ denote the set of prime ideals of $A$ which contain $E$. Prove that
\begin{enumerate}
\item If $\ia$ is the ideal generated by $E$, then $V(E)=V(\ia)=V(r(\ia))$\footnote{Here $r(\ia)$ denotes the radical of $\ia$}.
\item $V(0)=X$ and $V(1)=\emptyset$.
\item If $(E_i)_{i \in I}$ is a family of subsets of $A$, then
\[
V\left( \bigcup_{i \in I} E_i \right) = \bigcap_{i \in I} V\left(E_i\right).
\]
\item $V(\ia \cap \ib)=V(\ia \ib)=V(\ia) \cup V(\ib)$ for all ideals $\ia,\ib$ of $A$.
\end{enumerate}
These results show that the sets $V(E)$ satisfy the axioms for closed sets in a topological space. The resulting topolgoy is called the \emph{Zariski topology}. The topological space $X$ is called the \emph{prime spectrum of $A$} and denoted $\Spec A$.
\end{exc}

\begin{sol}
We do these one by one.
\begin{enumerate}
\item Clearly $\pp \supset \langle E \rangle \supset E$, where the brackets denote the ideal generated by $E$. Hence $V(\ia) \subset V(E)$. But if $\pp \supset E$, we must have $\pp \supset \ia$ since $\langle \pp \rangle = \pp$. Thus the first equality is established.

Since $r(\ia) \subset \ia$, we have $V(\ia) \subset V(r(\ia))$. Suppose $\pp \supset r(\ia)$ and suppose $a \in \ia$. We want to show $a \in \pp$. We know that $a^n \in r(\ia)$ for some $n$, hence $a^n \in \pp$. But $\pp$ is a prime ideal, so $a \in \pp$ also. Hence equality is established.
\item Every ideal contains the zero ideal and $(1)$ is not a prime ideal.
\item Suppose $\pp \supset \cup E_i$. Then $\pp \supset E_i$ for all $i$, so $\pp \in \cap V(E_i)$. Thus this is just a formal consequence of the contravariant nature of $V(-)$.
\item Since $\ia \ib  \subset \ia \cap \ib$, we automatically have $V(\ia \cap \ib) \subset V(\ia \ib)$. So suppose $\pp \supset \ia \ib$ and let $a \in \ia \cap \ib$. Then $a^2 \in \ia \ib \subset \pp$, but then $a \in \pp$ since $\pp$ is prime.

Now suppose $\pp \supset \ia$ or $\pp \supset \ib$. Then if $a \in \ia \cap \ib$, we have $a \in \pp$, so $V(\ia) \cup V(\ib) \subset V(\ia \cap \ib)$. Now suppose $\pp \supset \ia \cap \ib$. Then by Proposition 1.11, we have $\pp \supset \ia$ or $\pp \supset \ib$. 
\end{enumerate}
\end{sol}

\begin{exc}[Exercise 17]
For each $f \in A$, let $X_f$ denote the complement of $V(f)$ in $X=\Spec A$. The sets $X_f$ are open. Show that they form a basis for the Zariski topology, and that
\begin{enumerate}
\item $X_f \cap X_g = X_{fg}$.
\item $X_f = \emptyset \Leftrightarrow f$ is nilpotent.
\item $X_f = X \Leftrightarrow f$ is a unit.
\item $X_f = X_g \Leftrightarrow r((f)) = r((g))$.
\item $X$ is quasi-compact.
\item More generally, each $X_f$ is quasi-compact.
\item An open subset of $X$ is quasi-compact if and only if it is a finite union of the sets $X_f$.
\end{enumerate}
The sets $X_f$ are called \emph{basic open sets} of $X=\Spec A$.
\end{exc}
\begin{sol}
We need to show that the sets $X_f$ forms a basis for the Zariski topology on $X$. This means that each open in $X$ can be written as a union of the $X_f$. An open in $X$ have the form 
\[
U(\ia) = \{ \pp \in \Spec A \mid \pp \not \supset \ia \}.
\]
The sets $X_f$ have the form
\[
X_f = \{ \pp \in \Spec A \mid f \not \in \pp \}.
\]
Let $\{ f_i \}_{i \in I}$ generate $\ia$. I claim that $\bigcup X_{f_i} = U(\ia)$. Let $\pp$ be an element of the left hand side. This means by definition that $f_i \not \in \pp$ for some $i$. But $f_i$ is an element of $\ia$, so $\ia \not \subset \pp$, hence $\pp \in U(\ia)$. 

Conversely, suppose $\pp \not \supset \ia$. Then some generator $f_i$ of $\ia$ is not contained in $\pp$. Hence $\pp \in X_{f_i}$. 

\begin{enumerate}
\item We have $$X_f \cap X_g = \{ \pp \mid f,g  \not \in \pp \} = \{ \pp \mid fg \not \in \pp \} ,$$
since $\pp$ is a prime ideal: for suppose $f,g \not \in \pp$, then $fg \not \in \pp$ also, because if $fg \in \pp$, primality implies either $f$ or $g in \pp$. Conversely, suppose $fg \not \in \pp$. Then neither $f,g$ can be in $\pp$ by defintion of ideals.
\item Suppose $X_f$ is empty. Then there are no prime ideals with $f \not \in \pp$. But that means that $f$ is contained in every prime ideal, hence $f$ is nilpotent.
\item Suppose $X_f = X$. Then for all prime ideals, $f \not \in \pp$, hence $f$ generates the unit ideal, hence $f$ is a unit. For if $f$ did not generate the unit ideal, $f$ would be contained in some maximal ideal $\mm$, and maximal ideals are prime.
\item Suppose $X_f=X_g$. By definition, this means that for every prime $\pp$ with $f \not \in \pp$, we have $g \not \in \pp$ (and conversely). The contrapositive of this is $g \in \pp \Leftrightarrow f \in \pp$. Hence we have 
$$r((f)) = \bigcap_{\pp \supset (f)} \pp=\bigcap_{\pp \ni f} \pp = \bigcap_{\pp \ni g} \pp = r((g)).$$ 
\item Let $\{X_f\}_{f \in I}$ be a covering of $X$ by basic opens, that is, $X= \bigcup_{f \in I} X_f$. This means that for every $\pp \in X$, there is some $f \in I$ with $f \not \in \pp$. I claim that the $f_i$ generate the unit ideal: for if not, $\langle f_i \rangle$ would be contained in some prime ideal, but by the above, this is not the case. Hence there is an equation of the form $1=\sum g_if_i$ with $g_i \in A$, which is a \emph{finite} sum. Hence these finitely many $f_i$ suffice.
\item ...
\end{enumerate}
\end{sol}




\subsection{Chapter 2 - Modules}

\begin{exc}[Excercise 1]
Show that $\Z/m \otimes_Z \Z/n = 0$ if $m,n$ are coprime.
\end{exc}
\begin{sol}
Write $1=am+bn$. Then 
\begin{align*}
1 \otimes 1 = (am+bn) \otimes 1 &= am \otimes 1 + bn \otimes 1 \\
&=  0 + bn \otimes 1 = 1 \otimes bn = 1 \otimes 0 = 0.
\end{align*}
And we are done.
\end{sol}

\begin{exc}[Exercise 2]
 Let $A$ be a ring, $\ia$ an ideal, and $M$ an $A$-module. Then $(A/\ia) \otimes_A M$ is isomorphic to $M/\ia M$.
\end{exc}
\begin{sol}
Start with
\[
0 \to \ia \to A \to A/ \ia \to 0.
\]

Tensoring with $M$ gives
\[
\ia \otimes M  \to M \to A/\ia \otimes_A M \to 0.
\]
But $\ia \otimes_A M \simeq \ia M$, so that the sequence reads $A/\ia \otimes M \simeq M/\ia M$.
\end{sol}

\begin{exc}[Exercise 3]
 Let $A$ be a local ring, $M,N$ finitely generated $A$-modules. Prove that if $M \otimes N=0$, then $M=0$ or $N = 0$. 
\end{exc}
\begin{sol}
First a counterexample if $A$ is not a local ring. Let $A=k[x]$ and $M=k[x]/(x-1)$ and $N=k[x]/(x)$. We can write $1 = -(x-1) + x$. Then $M \otimes_A N = 0$ by the same method as in Exercise 1 ($1 \otimes 1 = (-x+1 + x) \otimes 1 = x \otimes 1 = 1 \otimes x = 0$). 

Let $M_k := M \otimes k = M/\mm M$. By Nakayama's lemma, $M_k=0 \Rightarrow M=0$.

So suppose $M \otimes_A N=0$. Then $(M \otimes_A N)_k = 0$. But this is isomorphic to $M_k \otimes_A  N_k$ since $k \otimes_A k = k$. But $M_k \otimes_A N_k \simeq M_k \otimes_k N_k$, as $k$-modules, since everything in $\mm$ acts trivially on $M_k$. But these are vector spaces over a field, now we must have $M_k=0$ or $N_k=0$, and by Nakayama we are done.
\end{sol}

\begin{exc}[Exercise 4]

Let $M_i$ ($i \in I$) be any family of $A$-modules, and let $M$ be their direct sum. Then $M$ is flat if and only if each $M_i$ is flat.  
\end{exc}
\begin{sol}
Let
\[
0 \to N' \to N \to N'' \to 0
\]
be any exact sequence. Then tensoring with $M$ gives
\[
0 \to N' \otimes_A M \to N \otimes_A M \to N'' \otimes_A M \to 0.
\]
We only need to check that the left map is injective. But we have $N' \otimes_A M \simeq \bigoplus_i N' \otimes_A M_i$ and $N \otimes_A M \simeq \bigotimes_i N \otimes_A M_i$, and thus the left map is just the direct sum of all the maps 
\[
0 \to N' \otimes_A M_i \to N \otimes_A M,
\]
which is injective if and only if each $M_i$ is flat.
\end{sol}

\begin{exc}[Exercise 5]
Let $A[x]$ be the ring of polynomials in one indeterminate over a ring $A$. Prove that $A[x]$ is flat $A$-algebra.  
\end{exc}
\begin{sol}
We have $A[x] = \bigoplus_{i=0}^\infty x^i A$ as an $A$-module. Now use Exercise 4.
\end{sol}

\begin{exc}[Exercise 24]
If $M$ is an $A$-module, the following are equivalent:
  \begin{enumerate}[i)]
  \item $M$ is flat.
\item $\Tor_n^A(M,N)=0$ for all $n>0$ and $A$-modules $N$.
\item $\Tor_1^A(M,N)=0$ for all $A$-modules $N$.
  \end{enumerate}
  \begin{sol}

To compute $\Tor_A^n(M,N)$, one takes an $A$-resolution of $N$ and tensor it with $M$ and take homology. But $M$ is flat, so the sequence stays exact, so the homology is zero. This shows $i) \Rightarrow ii)$.

The implication $ii) \Rightarrow iii)$ is trivial.

Now let
\[
0 \to N' \to N \to N'' \to 0
\]
be any exact sequence of $A$-modules. Then by properties of the Tor functor, we have an exact sequence
\[
\Tor_1(M,N'') \to N' \otimes M \to N \otimes M \to N'' \otimes M \to 0.
\]
But $\Tor_1(M,N'')=0$, so the sequence is short exact. Hence $M$ is flat.
  \end{sol}

  \begin{exc}[Exercise 25]

Let 
\[
0 \to N' \to N \to N'' \to 0
\]
be an exact sequence with $N''$ flat. Then $N'$ is flat if and only if $N$ is flat.
  \end{exc}
  \begin{sol}
    We have from the Tor exact sequence
\[
0 \to \Tor_1(N',M) \to Tor_1(N,M) \to 0
\]
since $\Tor_2(N'',M)=\Tor_1(N'',M)=0$. The statement follows.
  \end{sol}
  
\end{exc}

\subsection{Chapter III - Rings and modules of fractions}
\begin{exc}[Exercise 1]

Let $S$ be a multiplicatively closed subset of a ring $A$, and let $M$ be a finitely-generated $A$-module. Prove that $S^{-1}M=0$ if and only if there exists $s \in S$ such that $sM=0$.  
\end{exc}

\begin{sol}
 Suppose there exists such $s$. Let $m/s' \in S^{-1}M$. This is zero if and only if there exists $s \in M$ such that $s(s'm)=0$. But $ss'm=s'sm=s'0=0$. So $m=0$ in $S^{-1}M$.  (note that we did not use finite generation)

Now let $m_1,\ldots,m_r$ be a set of generators for $M$ and suppose that $S^{-1}M=0$. Then for each $i$ ($i=1,\ldots,r$), there exists $s_i$ such that $s_im_i=0$. Since every element of $M$ is an $A$-linear combination of the $m_i$, it follows that the product $s_1s_2\cdots s_r$ makes $sM=0$.
\end{sol}

\begin{exc}
A multiplicatively closed subset $S$ of a ring $A$ is said to be \emph{saturated} if
\[
xy \in S \Leftrightarrow x \in S \text{ and } y \in S.
\]
Prove that
\begin{enumerate}[i)]
\item $S$ is saturated $\Leftrightarrow$ $A \bs S$ is a union of prime ideals.
\item If $S$ is any multiplicatively closed subset of $A$, there is a unique smallest saturated multiplicatively closed subset $\overline S$ containing $S$, and $\overline S$ is the complement in $A$ of the union of the prime ideals which do not meet $S$. 
\end{enumerate}
If $S = 1 + \ia$, where $\ia$ is an ideal of $A$, find $\overline S$.
\end{exc}

\begin{sol}
i) Suppose $S$ is saturated. Then let $C$ be the set of all prime ideals not meeting $S$. Then by Proposition 3.11, the prime ideals of $S^{-1}A$ are precisely those in $C$, and they are all extensions of prime ideals of $A$. Thus let $a \in A \bs S$ and consider $i:A \to S^{-1}A$. Let $\overline a$ be the image of $a$ in $S^{-1}A$. Then $\overline a$ is contained in some prime ideal $\pp \subset S^{-1} A$. Let $\pp'$ be the inverse image of $\pp$ under $i$. Then $a \in \pp'$ and $\pp' \cap S = \emptyset$. Hence every $a \in A \bs S$ is contained in some prime ideal, hence $A \bs S$ is a union of prime ideals. (note: we didn't use that $S$ was saturated)

Now assume $A \bs S$ is a union of prime ideals, say $A \bs S = \bigcup_{i \in I} \pp_i$. Then we have the following chain of equivalences:
\begin{align*}
  xy \in S &\Leftrightarrow xy \not \in A \bs S \\
&\Leftrightarrow \exists \text{ no } i \in I \text{ with } xy \in \pp_i \\
&\Leftrightarrow \forall i \in I, xy \not \in \pp_i \\
&\Leftrightarrow \forall i \in I, (x \not \in \pp_i \text{ and } y \not \in \pp_i) \\
&\Leftrightarrow x \in S \text{ and } y \in S.
\end{align*}

ii) Clearly $\overline S$ as defined in the exercise contains $S$, and it is clear from the previous paragraph that it is maximal.

Now let $S = 1 + \ia$. 
\end{sol}

\subsection{Chapter 5 - Integral dependence and valuations}

\begin{exc}[Exercise 1]

Let $f:A \to B$ be an integral morphism of rings. Show that $f^\ast:\Spec B \to \Spec A$ is a closed mapping.  
\end{exc}
\begin{sol}
The map $f^\ast$ is by definition given by $\pp \mapsto f^{-1}(\pp) = \pp \cap A$. A closed subset of $\Spec B$ is by definition 
\[
V(\ia) = \{ \pp \in \Spec B \mid \pp \supset \ia \}
\]
for some ideal $\ia \subset B$.

Then the image of $V(\ia)$ is the set
\begin{align*}
f^\ast(V(\ia)) &= \{ \pp \cap A \mid \pp \in \Spec B, \quad  \pp \supset \ia \} 
\end{align*}
I claim that this is equal to 
\[
V(\ia \cap A) = \{ \qq \in \Spec A \mid \qq \supset \ia \cap A \},
\]
which clearly is a closed subset of $\Spec A$.

One direction is obvious: let $\pp \cap A$ be an element of $f^\ast(V(\ia))$. This is a point of $\Spec A$, and clearly $\pp \cap A \supset \ia \cap A$ since $\pp \supset \ia$.

The other direction needs the going up Theorem 5.10. Suppose $\qq \in V(\ia \cap A)$. Then by Going Up, there exists $\pp \in \Spec B$ with $\pp \cap A = \qq$. But we need to check that $\pp \supset \ia$. That is, we need to prove the assertion that if $\qq = \pp \cap A$ and $\qq \supset \ia \cap A$, then $\pp \supset \ia$. So suppose $a \in \ia \subset B$. Then $a$ satisfies an equation
\[
a^n + b_{n-1}a^{n-1} + \ldots + b_1a+b_0=0
\]
with $b_i \in A$. Since $a \in \ia$, we see that $b_0 \in \qq = \pp \cap A$. Hence
\[
a^n+b_{n-1}a^{n-1}+\ldots+b_1a = a(a^{n-1}+b_{n-1}a^{n-2}+\ldots+b_1) \in \pp
\]
since $\qq \subset \pp$. But $\pp$ is prime so either $a \in \pp$ and we are done, or $a^{n-1}b_{n-1}a^{n-2}+\ldots+b_1 \in \pp$, and we can continue by induction.

Hence we are done.
\end{sol}

\subsection{Chapter 7 - Noetherian rings}

\begin{exc}[Exercise 11]
Let $A$ be a ring such that $A_{\pp}$ is Noetherian for each $\pp \in \Spec A$. Is $A$ necessarily noetherian?
\end{exc}
\begin{sol}
Consider the ring
\[
A= \Z/2 \times \Z/2 \cdots .
\]
It is a countable product of noetherian rings. The primes are just the coordinate axes, and each localization is isomorphic to $\Z/2$. Thus each $A_\pp$ is Noetherian, but $A$ is not.
\end{sol}

\begin{exc}[Exercise 15]
Let $A$ be a Noetherian local ring, $\mm$ its maximal ideal and $k$ its residue field and let $M$ be a finitely generated $A$-module. Then the following are equivalent:
\begin{enumerate}[i)]
\item $M$ is free.
\item $M$ is flat.
\item The mapping $\mm \otimes M \to A \otimes M$ is injeective.
\item $\Tor_1^A(k,M)=0$.
\end{enumerate}
\end{exc}
\begin{sol}
The implication $i) \Rightarrow ii)$ is trivial. One way is to compute $\Tor_1^A(M,N)$ for any $A$-module $N$. But a free resolution of $M$ is just one-term, so $\Tor_1^A(M,N)$ is automatically zero.

The implication $ii \Rightarrow iii)$  follows by tensoring the incusion $\mm \hookrightarrow A$ with $M$. 

The implication $iii) \Rightarrow iv)$ follows from the $\Tor$ exact sequence
\[
\Tor_1^A(A,M) \to \Tor^A_1(k,M) \to \mm \otimes M \to A \otimes M \to k \otimes M \to 0.
\]
The leftmost term is zero since $A$ is a free $A$-module, and by $iii)$ and exactness we must as well have $\Tor_1^a(k,M)$.

Now for $iv \Rightarrow i)$. Choose element $m_i \in M$ ($0 \leq i \leq r$) such that they form a $k$-basis for $M/\mm M$. Choose a surjection $f:A^r \to M$ and let $E=\ker f$ be its kernel. Then we have an exact sequence
\[
0 \to E \to A^r \to M \to 0.
\]
of finitely-generated $A$-modules ($E$ is finitely generated by Proposition 6.2). Tensor the sequence by $k$, and get
\[
\Tor_1^A(k,M) \to E/\mm E \to k^r \to M/\mm M \to 0.
\]
The left-most term is zero by assumption. The last two spaces are $k$-vector spaces of the same dimension, and it follows that $E/\mm E=0$. But then it follows that $E$ is zero by Nakayama's lemma, hence $M$ is free.
\end{sol}

\begin{exc}[Exercise 16]
 Let $A$ be a Noetherian ring, $M$ a finitely-generated $A$-module. Then the following are equivalent:
 \begin{enumerate}[i)]
 \item $M$ is a flat $A$-module.
\item $M_\pp$ is a free $A_\pp$-module for each $\pp \in \Spec A$.
\item $M_\mm$ is a free $A_\mm$-module for each maximal ideal $\mm$.
 \end{enumerate}

So flatness is the same as being locally free.
\end{exc}
\begin{sol}
 The implications $i \Rightarrow ii)$ and $ii) \Rightarrow iii)$ follows trivially from the previous exercise. We prove $iii) \Rightarrow i)$. 

Applying the $\Tor$ functor commutes with localization, hence we have $\Tor_1^A(M,N)_\mm = \Tor_1^{A_\mm}(M_\mm, N_\mm)=0$ for all $\mm$. But being zero is a local property, so it follows that $\Tor_1^A(M,N)=0$ for all $A$-modules $N$. Hence $M$ is flat.
\end{sol}

%%%%%%%%%%%%%%%%%%%%%%%%

\section{Lie groups, Lie algebras and Representations - Hall}

\subsection{Matrix Lie groups}

\begin{exc}
Let $a$ be an irrational number and let $G$ be the following subgroup of $\GL(2; \C)$:
$$
G = 
\left\{
\begin{pmatrix}
e^{it} & 0 \\
0 & e^{ita} 
\end{pmatrix}
\, \mid  \, t \in \R \right\}.
$$
Show that
$$
\overline G = \left\{
\begin{pmatrix}
e^{it} & 0 \\
0 & e^{is} 
\end{pmatrix}
\, \mid  \, t,s  \in \R \right\}.
$$
\end{exc}
\begin{sol}
It suffices to show that every pair $(e^{it},e^{is})$ can be arbitrarily apprixmated by a pair $(e^{it},e^{iat})$. 

Let $t' = 2\pi k + t$. The set 
$$
\{ e^{iat'} \mid k \in \Z \} 
$$
is dense in $S^1$, hence for some $k$ we come very close to the pair $(e^{it},e^{iat})$. Hence the closure is the torus.
\end{sol}



%%%%%%%%%%%%%%%%%%%%%%%%

\section{Linear representations of finite groups - Serre}

\subsection{Chapter 1 - Representations and characters}

[no exercises]

\subsection{Chapter 2 - The character of a representation}

\begin{exc}[Exercise 2.1]
  Let $\chi,\chi'$ be the characters of two representations. Prove the formulas:
\[
(\chi+\chi')_\sigma^2 = \chi_\sigma^2 + \chi_\sigma^{'2}+\chi \chi'
\]
and 
\[
(\chi+\chi')_\alpha^2 = \chi_\alpha^2 + \chi_\alpha^{'2}+\chi \chi'
\]
Here $\chi_\sigma,\chi_\alpha$ are the characters of the symmetric and the alternating representation, respectively.
\end{exc}
\begin{sol}
The left hand side is the character of $\Sym^2(V \oplus W)$, and a calculation shows that this decomposes as $\Sym^2 V \oplus \Sym^2 W \oplus (V \otimes W)$. Hence the result follows by Proposition 2.

For the alternating representation we have a similar decomposition.
\end{sol}

\begin{exc}[Exercise 2.2]
  Let $X$ be a finite set on which $G$ acts and let $\rho$ be the corresponding permutation representation and $\chi_X$ the character of $\rho$. Let $s \in G$. Show that $\chi_X(s)$ is the number of elements of $X$ fixed by $s$.
\end{exc}

\begin{sol}
 We have by definition that $\chi_X(s)$ is the trace of a matrix representing $\rho(s)$, but $\rho(s)$ is a permutation matrix. All basis elements corresponding to elements moved by $s$ will be moved off the diagonal, so the remaning elements, the elements fixed by $s$, are on the diagonal, and are all $1$'s. Done.
\end{sol}

\begin{exc}[Excercise 2.3]
Let $\rho:G \to \GL(V)$ be a linear representation with character $\chi$ and let $V'$ be the dual of $V$. Show that there exists a unique linear representation $\rho':G \to \GL(V')$ such that
$$
\langle \rho_s x, \rho' x' \rangle = \langle x, x' \rangle
$$  
for $s \in G$, $x \in V$, $x' \in V'$. Here $\langle,\rangle$ is the natural pairing between $V$ and $V'$, given by $\langle x,x' \rangle = x'(x)$. 

This is the \textbf{contragradient} or \textbf{dual} representation of $\rho$. Its character is $\overline \chi$.
\end{exc}

\begin{sol}
  We first define the representation $\rho'$, and then show that is unique. So let $\rho'(s)$ be defined by
$$
(\rho'(s) f)(v) = f(g^{-1} v).
$$
Then (we omit the $\rho$ from the notation, it being clear which action is referred to):
$$
\langle g \cdot x, g \cdot f \rangle = (g \cdot f)(g \cdot x) = f(g^{-1} gx ) = f(x) = \langle x, f \rangle.
$$

Now let $\sigma:G \to \GL(V')$ be another representation of $V'$ satisfying this identity, and suppose $\sigma \neq \rho'$. Then there is some $s \in G$ such that $\sigma(s) \neq \rho'(s) \in \GL(V')$. This means there is some $f \in GL(V')$ such that $\sigma(s)(f) \neq \rho'(s)(f) \in V'$. This means that there is some $v \in V$ such that $\sigma(s)(f)(v) \neq \rho'(s)(f)(v) \in \C$. Writing this more compactly, this means
$$
(\sigma_s f)(v) \neq (\rho'_s f)(v).
$$
But then (letting $w = s^{-1} \cdot v$)
\begin{align*}
f(w) =& \langle w,f\rangle = \langle s \cdot w, \sigma_s f \rangle= ( \sigma_s 
f)(v) \neq (\rho_s' f)(v) = \langle v, \rho_s' f \rangle \\
&= \langle s \cdot w, (\rho_s')(f) \rangle = \langle w, f \rangle = f(w)
\end{align*}
which is a contradiction.
\end{sol}

\begin{exc}
  Let $\rho_1:G \to \GL(V_1)$ and $\rho_2:G \to \GL(V_2)$ be two linear representations with characters $\chi_1, \chi_2$. Let $W= \Hom(V_1,V_2)$. 

For $s \in G$ and $f \in W$, let $\rho_s f = \rho_{2,s} \circ f \circ \rho_{1,s}^{-1}$ so $\rho_s f \in W$. Show that this defines a linear representation $\rho:G \to \GL(W)$ and that its character is $\chi_1^\ast \cdot \chi_2$. This representation is isomorphic to $\rho_1' \otimes \rho_2$.
\end{exc}

\begin{sol}
  It is easy but notationally challenging to check that this defines a representation.

To prove the statement about characters, we first show that
$$
\Hom(V_1, V_2) \simeq V_1^\ast \otimes V_2
$$
as representations. Then the statement will follow by properties of characters.

The map is given by (from right to left) by $f \otimes v_2 \mapsto (v_1 \mapsto f(v_1)v_2)$. We check that this map intertwines the action of $G$ on the tensor product with that on the $\Hom$-set, that is calling the isomorphism for $\varphi$, that $g \cdot \varphi(f \otimes v_2) = \varphi ( g \cdot (f \otimes v_2))$. But

$$
g \cdot \varphi( f \otimes v_2) = g \cdot (v_1 \mapsto f(v_1)v_2) = v_1 \mapsto f(g^{-1}v_1) g v_2
$$

Note that the notation is ambigious here. With $gf(g^{-1}v)$, we really means $(\rho_2(g)f)(\rho_1(g)v)$, but who wants to write that much? On the other hand we have
$$
\varphi ( g \cdot (f \otimes v_2)) = \varphi ( gf \otimes gv_2) = \varphi((v_1 \mapsto f(g^{-1}v_1)) \otimes gv_2) = v_1 \mapsto f(g^{-1}v_1)  g v_2.
$$
But these are equal!
\end{sol}

\begin{exc}[Exercise 2.5]
Let $\rho$ be a linear representation with character $\chi$. Show that the number of times that $\rho$ contains the unit representation is equal to $(\chi \mid 1)=\frac 1g \sum_{s \in G} \chi(s)$.  
\end{exc}

\begin{sol}
The character $\chi_\rho$ decomposes as $\sum a_i \chi_{\pi_i}$ where $\pi_i$ are its irreducible components with multiplicities $a_i$. Since the unit representation have character $\chi_\epsilon(g)=1$ for all $g$, the result follows trivially.
\end{sol}


\begin{exc}[Exercise 2.6]
Let $X$ be a finite set on which $G$ acts and let $\rho$ be the corresponding permutation representation and $\chi$ its character.
\begin{enumerate}[a)]
\item The set $Gx$ of images under $G$ of an element $x \in X$ is the \emph{orbit} of $x$. Let $c$ be the number of distinct orbits. Show that $c$ is the number of times that $\rho$ contains the unit representation. Deduce that $c=(\chi \mid 1)$. In particular, if $G$ is transitive, $\rho$ can be decomposed into $1 \oplus \theta$ where $\theta$ does not contain the unit representation. If $\psi$ is the character of $\theta$, we have $\chi=1+\psi$ and $(\psi \mid 1)=0$. 
\item Let $G$ act diagonally on $X \times X$. That is, by $s (x,y)= (sx,sy)$. Show that the character of the corresponding representation is equal to $\chi^2$.
\item Suppose that $G$ acts transitively on $X$ and that $X$ has at least two elements. We say that $G$ is doubly transitive if for all $x,y,x',y' \in X$ with $x \neq y$ and $x' \neq y'$, there exists $s \in G$ with $x'=sx$ and $y'=sy$. Prove the equivalence of the following properties:
  \begin{enumerate}[i)]
  \item $G$ is doubly transitive.
\item The action of $G$ on $X \times X$ have two orbits, the diagonal and the complement.
\item $(\chi^2 \mid 1)=2$.
\item The representation $\theta$ defined in a) is irreducible.
  \end{enumerate}
\end{enumerate}
\end{exc}

\begin{sol}
  \begin{enumerate}[a)]
  \item 
Decompose $X= \cup X_i$ where $X_i$ are the disjoint orbits. Then $\rho$ decomposes as $\rho=\oplus \rho_i$. Thus it suffices to show that if $G$ act transitively on $X$, the corresponding permutation representation contains exactly one copy of the unit representation.

It is clear that it contains one copy, namely the subspace spanned by the element $(1,1,\ldots,1)$.

Now, two representations are isomorphic if and only if their characters are equal. Any representation isomorphic to the unit representation must therefore act as the identity. So let $v \in V_\rho$ be any vector. Then its coordinates are permutes by $G$. If the subspace spanned by $v$ is invariant and if $G$ act as the identity on it and since $G$ acts transitively on the coordinates, all its coordinates must be equal. Thus the unit representation occurs exactly once in $\rho$. 

Thus $c= (\chi \mid 1)$. The rest of the claims follows immediately.
\item Just note that the corresponding permutation representation is just the tensor product $\rho \otimes \rho$. 
\item i and ii are clearly equivalent. The implication ii $\Rightarrow$ iii is the content of a) and b). The implication iii $Rightarrow$ ii is a and b also. 

Now suppose that $\theta$ is irreducible. We will show iii. It is easy to see that $(\chi^2,1)=(\chi, \chi)$. This in turn is equal to $(1+\psi,1+\psi)$ which is equal to $(1,1)+2(1,\psi)+(\psi,\psi)$. The first term is $1$. The second is zero, since $\theta$ does not contain the unit representation. The third term is $1$ by assumption. Hence $(\chi^2,1)=2$. 

Clearly we can go the other way as well.
  \end{enumerate}
\end{sol}

\subsection{Chapter 3}

\begin{exc}[Exercise 3.1]
 Show directly using Schur's lemma, that each irreducible representation of an abelian group, finite or not, has degree $1$.
\end{exc}

\begin{sol}
Let $A$ be an abelian group, and let $V$ be an irreducible representation of $A$. Then each $g \in A$ gives  a nonzero $G$-morphism $V \to V$ by left-multiplication. Here we use that $A$ is abelian.

But by Schur's lemma, every such morphism is given by multiplication by some $\alpha(g) \in \C \bs \{ 0\}$.

Let $v \neq 0 \in V$ and let $W \subset V$ be the subspace spanned by $v$. Then $W$ is $G$-invariant: $g \cdot v = \alpha(g) v \in W$. Hence $V=W$ since $W$ was irreducible.
\end{sol}

\begin{exc}
 Let $\rho$ be an irreducible representation of $G$ of degree $n$ and character $\chi$. Let $Z(G)$ be the center of $G$ and let $c$ be its order.
 \begin{enumerate}[a)]
 \item Show that $\rho_s$ is a homothety for each $s \in Z(G)$. Deduce that $\lvert \chi(s) \rvert = n$ for all $ s \in C$. 
 \end{enumerate}
\end{exc}

\section{The K-book - Charles Weibel}

\subsubsection{Chapter 1.1 - Free modules, $GL_n$ and stably free modules}

\begin{exc}[Semisimple rings]

A nonzero $R$-module $M$ is called \emph{simple} if it has no submodules other than $0$ and $M$, and semisimple if it is a direct sum of simple modules. A ring $R$ is called \emph{semisimple} if it is a semisimple $R$-module. If $R$ is semisimple, show that $R$ is a direct sum of a \emph{finite} (say $n$) number of simple modules.

Then use the Jordan-Hölder theorem to show that every stably free module is free.  
\end{exc}
\begin{sol}
Suppose $R$ is semisimple, that is $R = \oplus M_i$ with a priori infinitely many $M_i$. But write $1 = \sum a_im_i$ with $m_i \in M_i$ and $a_i \in R$. This is a finite sum, and since for any $r \in R$, we have $r = \sum a_irm_i$, only finitely many $M_i$ need occur in the decomposition $R=\oplus M_i$. 

To see that any stably free module is free if $R$ is semisimple, suppose $M \oplus R^n \simeq R^m$. Then we can write $M \oplus M_i^n \simeq \oplus M_j^m$ as above, and note that the image of a simple module must be simple, hence the $M_j$ on the right must be mapped to copies of themselves isomorphically. Hence we can cancel $M_i$-terms on both sides until we arrive at $R^k \simeq M$ for some $k$.
\end{sol}

\begin{exc}
Consider the following conditions on a ring $R$:
\begin{enumerate}[i)]
\item $R$ satisfies the invariant basis property (IBP).
\item For all $m,n$, if $R^m \simeq R^n \oplus P$, then $m \leq n$.
\item For all $n$, if $R^n \simeq R^n \oplus P$, then $P=0$.
\end{enumerate}
Show that iii $\Rightarrow$ ii $\Rightarrow$ i. 
\end{exc}
\begin{sol}
Suppose $R^m \simeq R^n \oplus P$ and suppose $n > m$. Then we can write $R^m \simeq R^m \oplus (R^{n-m} \oplus P)$. Then from $iii$ we must have $R^{n-m} \oplus P = 0$, but this is impossible.

Now suppose $R^n \simeq R^m$. Then for $P=0$, we have $R^m \simeq R^n \oplus P$, hence $m \leq n$. But the opposite argument works as well, hence $m=n$.
\end{sol}

\begin{exc}
 Show that iii) in the previous exercise and the following matrix conditions are equivalent:
 \begin{enumerate}[a)]
 \item For all $n$, every surjection $f:R^n \to R^m$ is an isomorphism. 
\item  For all $n$ and $f,g \in M_n(R)$, if $fg=1_n$, then $gf=1_n$ and $g \in \GL_n(R)$.
 \end{enumerate}
Then show that commutative rings satisfy b), hence iii).
\end{exc}
\begin{sol}
 First we see that $iii  \Rightarrow a)$. Suppose $f:R^n \to R^m$ is a surjection. Then we have an exact sequence
\[
0 \to K \to R^n \xrightarrow{f} R^n \to 0.
\]
Since $R^n$ is free, the sequence splits and we have $R^n \simeq R^n \oplus K$, but then by assumption $K=0$. Hence $f$ is an isomorphism.

Now suppose $a)$, that is,  every surjection is an isomorphism. Next suppose $R^n \simeq R^n \oplus P$. Compose with the surjection $R^n \oplus P \to R^n$ to get a surjective map $R^n \to R^n$. The kernel of this is $P$. But every surjection $R^n\to R^n$ is an isomorphism, hence $P=0$.

Now suppose $iii)$. The condition $fg=1_n$ implies that $g$ is injective and that we have a splitting $R^n \simeq R^n \oplus \coker g$. But then $\coker g=0$ by $iii)$, hence $g$ is an isomorphism. To show that $gf=1_n$, suppose $gf(x)=y$. Applying $f$ to both sides give $f(x)=f(y)$. So we must show that $f$ is injective. So suppose that $f(x)=0$. Since $g$ was surjective, we can write $x=g(y)$ for some $y$. Then $f(g(x))=x=0$. Hence $f$ is injective. So we have proven b). 

Now suppose b). Then $b$ implies $a$, hence iii).
\end{sol}

\subsection{Chapter 1.2 - Projective modules}

\begin{exc}[Radical ideals]
Let $I$ be a radical ideal in $R$. If $P_1,P_2$ are finitely generated projective $R$-modules such that $P_1/IP_1 \simeq P_2/IP_2$, show that $P_1 \simeq P_2$. 
\end{exc}

\begin{sol}
  
\end{sol}


\section{Representation Theory - Fulton, Harris}

\subsection{Representations of Finite Groups}

\begin{exc}[Exercise 1.1]
Verify that the relation 
\[
\langle g\cdot v^\ast , g \cdot v \rangle = \langle \rho^\ast(g)(v^\ast),\rho(g)(v) \rangle = \langle v^\ast, v\rangle 
\]
is satisfied when we define
\[
\rho^\ast(g) = \rho(g^{-1})^t :V^\ast \to V^\ast, 
\]
that is, $(\rho^\ast g)(v^\ast)(w)= \langle (\rho^\ast g)(v^\ast),w\rangle=\langle v^\ast, (\rho g^{-1})(w) \rangle$.
\end{exc}

\begin{sol}
This is a matter of calculation.
\[
\langle g v^\ast, gv \rangle = \langle v^\ast, (\rho g^{-1})(gv) \rangle = \langle v^\ast, v \rangle.
\]
So the definition is ok.
\end{sol}


\begin{exc}[Exercise 1.2]
Verify that in general the vector space of $G$-linear maps between two representations $V$ and $W$ of $G$ is just the subspace $\Hom(V,W)^G$ of elements of $\Hom(V,W)$ fixed under the action of $G$. This subspace is often denoted $\Hom_G(V,W)$.
\end{exc}
\begin{sol}	
A map $\varphi:V \to W$ is $G$-linear when $\varphi(gv)=g \varphi(v)$. The action of $G$ on $\varphi$ is given by $g\varphi(v)=g \varphi(g^{-1}v)$. But by $G$-linearity, this is
$$
\varphi(gv)=g g^{-1} \varphi(gv)=gg^{-1}\varphi(v)=\varphi(v).
$$
Hence a map is $G$-linear if and only if it is fixed by the action of $G$. 
\end{sol}

\begin{exc}[Exercise 1.3]
Let $\rho:G \to \GL(V)$ be any representation of the finite group $G$ on an $n$-dimensional vector space $V$ and suppose that for any $g \in G$, the determinant if $\rho(g)$ is $1$. Show that the spaces $\wedge^k V $ and $\wedge^{n-k} V^\ast$ are isomorphic as representations of $G$.
\end{exc}

\begin{sol}
This is (again) just a matter of writing out the definitions. First we define the isomorphism, and then we check that it is actually an isomorphism of representations.

\begin{align*}
\bigwedge ^k V &\to \bigwedge^{n-k} V^\ast \\
v_1 \wedge \cdots \wedge v_k &\mapsto \left( w_1 \wedge \cdots \wedge w_{n-k} \mapsto v_1 \wedge \cdots \wedge v_k \wedge w_1 \wedge \cdots \wedge w_{n-k} \right)
\end{align*}
Being a map of representations is equivalent to $g^{-1}\varphi(gv)=\varphi(v)$, so we just need to check that all the $g$'s disappear from the left hand side. 
\begin{align*}
g^{-1}\varphi(gv) &= g^{-1}(w_1\cdots w_{n-k} \mapsto gv_1\cdots gv_k w_1 \cdots w_{n-k}) \\
&= (gv_1\cdots gv_k gw_1 \cdots gw_{n-k}) \\
&= \det \rho(g) v_1 \wedge \cdots \wedge w_{n-k}.
\end{align*}
Hence $\varphi$ is a map of representations if and only if $\det \rho(g)=1$ for all $g \in G$. 

(it is an isomorphism because it has zero kernel: because what would the kernel be? Every subspace is the same, and this is a basis free description)
\end{sol}

\begin{exc}[Exercise 1.4]
The permutation representation $R$ of $G$ acting on a finite set $X$ have two descriptions: one is given by letting $V$ be the vector space with basis $\{ e_x \mid x \in X \}$ and letting $g$ act on $V$ by $ge_x = e_{gx}$. 

Alternatively $R$ is the set of functions $f:X \to \C$ with action $(g\alpha)(h)=\alpha(g^{-1}h)$.

\begin{enumerate}[a)]
\item Show that these two decriptions agree by identifying $e_x$ with the characteristic function which takes the value $1$ on $x$ and $0$ elsewhere. 
\item The space of functions on $G$ can also be made into a $G$-module by the rule $(g\alpha)(h)=\alpha(hg)$. Show that this is an isomorphic representation.
\end{enumerate}
\end{exc}
\begin{sol}
a). Clearly the vector space dimensions agree (since the characteristic functions are a basis). So we need to check that this is a map of representations. Denote the characteristic function by $\chi_x$. Then $\varphi(ge_x)(h) = \varphi(e_{gx})(h)=\chi_{gx}(h)$. Similarly $g \varphi(e_x)(h) = g \chi_x(h) = \chi_x(g^{-1}h)$, The first function is $1$ if $gx=h$, and the second function is $1$ if $g^{-1}h=x$, and these are equivalent.

b). Send $\alpha$ to the function $g \mapsto \alpha(g^{-1})$. Call this assignment $\psi$. We need to check that $\psi(g\alpha)=g \psi(\alpha)$. 

First the left hand side. We have: $\psi(g\alpha)(h)=\psi(h \mapsto \alpha(g^{-1}h))(h)=\alpha(g^{-1}h^{-1})$.

And similarly: $g \psi(\alpha)(h)=g (h \mapsto \alpha(h^{-1}))(h) = g \alpha(h^{-1})=\alpha(g^{-1}h^{-1})$. 

And these are equal.
\end{sol}

\begin{exc}[Exercise 1.10]
$G=S_3$. Verify that with $\sigma=(12)$, $\tau=(123)$, the standard representation has a basis $\alpha=(\omega, 1, \omega^2)$, $\beta=(1,\omega,\omega^2)$, with
\[
\tau \alpha = \omega \alpha, \qquad \tau \beta = \omega^2 \beta, \qquad \sigma \alpha = \beta, \qquad \sigma \beta = \alpha.
\]
\end{exc}
\begin{sol}
The standard representation $V$ is the subspace $\{ x_1+x_2+x_3=0 \}$ of $\C^3$. Since $1+\omega+\omega^2=0$, and $\alpha \cdot \beta = 3\omega \neq 0$, these two span $V$.

The identities are easy.
\end{sol}


\begin{exc}[Exercise 1.11]
Use this approach to find the decomposition of the representations $\Sym^2 V$ and $\Sym^3 V$.
\end{exc}
\begin{sol}
The elements $\{ \alpha^2, \alpha \beta, \beta^2 \}$ are a basis of $\Sym^2 V$, and the eigenvalues are $\omega^2, 1$ and $\omega$, respectively. Thus $\langle \alpha \beta \rangle$ span a representation isomorphic to $U$, the trivial representation, and $\langle \alpha^2, \beta^2 \rangle$ span a representation isomorphic to $V$, the standard representation. Hence $\Sym^2 V = U \oplus V$.

The elements $\{ \alpha^3, \alpha^2 \beta, \alpha \beta^2, \beta^3 \}$ are a basis of $\Sym^3 V$. The eigenvalues are $1, \omega, \omega^2$ and $1$, respectively. Looking at the action of $\sigma=(12)$, we see that $U \simeq \langle \alpha^3+\beta^3 \rangle$, and $U' \simeq \langle \alpha^3-\beta^3 \rangle$. The remaining $\langle \alpha^2 \beta, \alpha \beta^2 \rangle$ span a representation isomorphic to $V$. Hence $\Sym^3 V = U \oplus U' \oplus V$.
\end{sol}

\begin{exc}[Exercise 2.2]
For $\Sym^2 V$, verify that
\[
\chi_{\Sym^2 V}(g) = \frac 12 \left[ \chi_V(g)^2 + \chi_V(g^2)\right].
\]
Note that this is compatible with the decomposition $V \otimes V = \Sym^2 V \oplus \wedge^2 V$.
\end{exc}
\begin{sol}

The eigenvalues of $g$ acting on $\Sym^2 V$ are $\{\lambda_i \lambda_j \}$. Hence
\begin{align*}
\chi_{\Sym^2 V}(g) &= \sum_{i \leq j} \lambda_i \lambda_j \\
&= \sum_{i < j} \lambda_i \lambda_j + \sum_i \lambda_i^2 \\
&= \frac 12 \left( \chi_V(g)^2 - \chi_V(g^2) \right) + \chi_V(g^2) \\
&= \frac 12  \left( \chi_V(g)^2 + \chi_V(g^2) \right).
\end{align*}
\end{sol}

\begin{exc}[Exercise 2.5, The original fixed point formula]
If $V$ is a permutation representation associated to the action of a group $G$ on a finite set $X$, show that $\chi_V(g)$ is the number of elements fixed by $g$.
\end{exc}
\begin{sol}
This is easy. The matrix associated to $g$ is a permutation matrix with a $1$ in row $j$ if element number $i$ is sent to $j$. Then number of fixed points is the number of ones on the diagonal, and this is $\chi_V(g)$.
\end{sol}

\begin{exc}[Exercise 2.7]
Consider the standard representation $V$ of $S_3$ and its $n$th tensor power $V^{\otimes n}$. Decompose it using character theory.  
\end{exc}
\begin{sol}
 We know that there are three irreducible representations of $S_3$. Hence $V^{\otimes n} \simeq U^a \oplus {U'}^{b} \oplus V^c$ for some numbers $a,b,c$. Here $U$ is the trivial representation, $U'$ is the alternating representation and $V$ the standard representation.

We also know that the characters are orthogonal, so to find $a$ we have to compute $\langle \chi_U, \chi_{V^{\otimes n}}\rangle $. This we do by using that $\chi_{V^{\otimes n}} = \chi_V^n$. Then we see that $a=\frac 13 (2^{n-1} + (-1)^n)$ since
$$
\langle \chi_U, \chi_{V^{\otimes n}} \rangle = \frac 16 \left( 2^n + 0 + (-1)^n \right).
$$
Similarly for $b,c$.
\end{sol}
 

\begin{exc}[Exercise 2.34]
Let $V,W$ be irreducible representations of $G$ and $L_0:V \to W$ any linear mapping. Define $L:V \to W$ by 
$$
L(v) = \frac{1}{\lvert G \rvert} \sum_g g^{-1} L_0(gv).
$$
Show that $L=0$ if $V$ and $W$ are not isomorphic, and that $L$ is multiplication by $\tr(L_0)/\dim (V)$ if $V=W$.
\end{exc}
\begin{sol}
We want to apply Schur's lemma. We check that $L$ is a $G$-module homomorphism. We have
\begin{align*}
L(hv) &= \frac{1}{\lvert G \rvert} \sum_g g^{-1}L_0(ghv) \\
&= \frac{1}{\lvert G\rvert} \sum_{gh} h {gh}^{-1}L_0(ghv) \\
&= \frac{1}{\lvert G\rvert} \sum_{g'} h {g'}^{-1}L_0(g'v)
\end{align*}
Hence $L$ is a $G$-module homomorphism. Hence by Schur's lemma, $L$ is either the zero map or an isomorphism. In particular, if they are not isomorphic, $L=0$. Now suppose $V=W$. 
\end{sol}

\subsection{Chapter 7 - Lie groups}

\begin{exc}[Exercise 7.11]
  \begin{enumerate}[a)]
  \item Show that any discrete normal subgroup $H$ of a connected Lie group $G$ is in the center $Z(G)$.
\item If $Z(G)$ is discrete, then $G/Z(G)$ have trivial center.
 \end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item We must show that for any $z \in H$ and any $g \in G$, we have $gz = zg \Leftrightarrow z = gzg^{-1}$, that is, that $z$ is fixed by conjugation by  all elements of $g$. Since $H$ is normal, we must have $gzg^{-1}=z'$ for some $z' \in H$. Conjugation is a continous mapping, hence if $g'$ is close to $g$, $g'zg^{'-1}$ is close to $z'$. But by normality this must still be an element of $H$, but $H$ is discrete, for for $g'$ close enough to $g$ the only element of $H$ that can be hit is is $z$. Hence the mapping $z \mapsto gzg^{-1}$ is locally constant. $G$ is connected, so the mapping must be constant, and since $geg^{-1}=e$, the mapping must be the identity mapping, hence $gzg^{-1}=z$ for all $g \in G$ and $z \in H$. 
\item Suppose $a \in Z(G/Z(G))$. Let $\pi:G \to G/Z(G)$ be the quotient map. Let $Z=\pi^{-1}(Z(G/Z(G))$. We want to show that if  $a$ is a representative for $a$, then $a$  lies in $Z(G)$. Lying in $Z(G/Z(G))$ means that $[a,b] \in Z(G)$ for all $a \in Z$ and $b \in G$. But this  implies that the map $[,]:Z \times G \to G$ lands in $Z(G)$, which is discrete, hence the map must be constant, hence by definition, $a$ lies in $Z(G)$.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 7.12]
  If $\varphi:H \to G$ is a covering of connected Lie groups, show that $Z(G)$ is discrete if and only if $Z(H)$ is discrete, and then $H/Z(H)=G/Z(G)$. Therefore, if $Z(G)$ is discrete, the adjoint form of $G$ exists and is $G/Z(G)$.
\end{exc}
\begin{sol}
 Suppose $Z(G)$ is discrete, and let $h \in Z(H)$. Since $\varphi$ is a covering, the image $\varphi(h)$ lies in $Z(G)$. Thus, since $Z(G)$ is discrete, we can find a small neighbourhood around $\varphi(h)$ such that $\varphi(h) \cap Z(G) = \{ \varphi(h) \}$. By shrinking the neighbourhood if necessary, it can be shrunk so that $\varphi$ is a diffeomorphism around $h$, hence $Z(H)$ is discrete as well.

Suppose $Z(H)$ is discrete. Then the image of any $h \in Z(H)$ lies in $Z(G)$ and $\varphi$ is a local diffeomorphism. 

Now for the other part. We note that we have a diagram:
\[
\xymatrix{
1 \ar[r] & \ker \restr{\varphi}{Z(H)} \ar[r] \ar[d] & \ker \varphi \ar[r] \ar[d] & \ker \bar{\varphi} \ar[d] \\ 
1 \ar[r] & Z(H) \ar[r] \ar[d] & H \ar[r] \ar[d]^\varphi & H/Z(H) \ar[d] \ar[r] & 1 \\
1 \ar[r] & Z(G) \ar[d]  \ar[r] & G \ar[r] \ar[d]  & G/Z(G) \ar[d] \ar[r] & 1\\ 
& 1 & 1 & 1 
}
\]
The vertical lower maps are all surjective since $\varphi$ is a covering map and by the proof above. By the previous exercise, we find that $\ker \restr{\varphi}{Z(H)} = \ker \varphi$, hence $H/Z(H) \simeq G/Z(G)$ by the snake lemma (which holds here, see mathoverflow 53124).
\end{sol}

\subsection{Lecture 8 - Lie Algebras and Lie groups}

\begin{exc}[Exercise 8.1]
  Let $G$ be a connected Lie group, and $U \subset G$ any neighbourhood of the identity. Show that $U$ generates $G$.
\end{exc}

\begin{sol}
The subgroup generated by $U$ can be written 
\[
H = \bigcup_{n \in \Z} U^n,
\]
hence $H$ is an open subgroup. But since $G \bs H = \bigcup_{h \not \in H} hH$, we see that any open subgroup is also closed, hence $H$ is both open and closed, hence $H=G$. (this solution was given by Theo Bühler at math.stackexchange).
\end{sol}

\section{Twenty-Four Hours of Local Cohomology}

\subsection{Lecture 1 - Basic notions}

\begin{exc}[Exercise 1.6]
Let $k$ be a finite field.
\begin{enumerate}
\item For every point $p \in k^n$, construct a polynomial $f \in k[x_1,\ldots,x_n]$ such that $f(p)=1$ and $f(q)=0$ for all points $q \in k^n \bs \{ p \}$.
\item Given a function $g:k^n \to k$, show that there is a polynomial $f \in k[x_1,\ldots,x_n]$ with $f(p)=g(p)$ for all $p \in k^n$.
\item Prove that any subset of $k^n$ is the zero set of a single polynomial. 
\end{enumerate}
\end{exc}

\begin{sol}
Suppose that $char(k)=p$.
1. Suppose $p=(p_1,\ldots,p_n)$. If $n=1$, then $p=(p_1)$. Then the polynomial $f(x)=\prod_{q \neq p}(x-q)$ is zero on all of $k$. On the other hand, $f(p)$ is the product of all non-zero elements in $k$. But this must be one, as one sees by grouping inverses together.

This generalizes to $k^n$ by taking products over products. 

2. This follows from the previous exercise. Let $f_p$ be as in 1. Then form the polynomial 
$$
f = \sum_{p \in k^n} g(p) f_p .
$$
Then $f(p)=g(p)$ for all $p$.

3. Let $S$ be any subset. Let $q$ be a function that is $1$ outside $S$ and is $0$ on $S$. Then the result follows from 2.
<<<<<<< HEAD
\end{sol}

\begin{oppg}[Exercise 1.11]
Prove that if $K$ is not algebraically closed, then any algebraic set in $K^n$ is the zero set of a single polynomial.
\end{oppg}
\begin{losn}
Suppose $Z=V(F_1,\ldots,F_r)$ is an algebraic set. We first show that for any $n$, there is a polynomial whose only zero is the origin. 

The case $n=1$ is clear, and the case $n=2$ can be gotten this way: choose an irreducible polynomial $f(x)$ of degree greater than one (here we use that $K$ is not algebraically closed). Then form the homogenization of $f(x)$ with respect to $y$. Call this new polynomial $G(x,y)$. Then $G(x,y)$ have only one zero at the origin. 

Now assume we have such a polynomial $H$ for $n=k-1$. Then form $G(H(x_1,\ldots,x_{n-1}),x_n)$. Done.

Let $n=r$. Let $F(x_1,\ldots,x_n)=H(f_1,\ldots,f_r)$. Done.

(I must admit I cheated on this one. I had to Google the first part)
\end{losn}

\begin{oppg}[Exc 1.14]
If a principal ideal domain is not a field, prove that it has dimension one.
\end{oppg}
\begin{losn}
Suppose we have a minimal strict chain of \emph{three} prime ideals. That is, suppose the dimension of $R$ is two or more. $(0) \subset \pp_1 \subset \pp_2$. But $\pp_1=(a)$ for some $a \in R$ and $\pp_2=(b)$. But since $\pp_1 \subset \pp_2$, we must have $b=ar$ for some $r \in R$. But $\pp_2$ is a prime ideal, hence either $a \in \pp_2$ or $r \in \pp_2$. The latter cannot happen, because in that case, the inclusion would not be minimal. Neither the first, because then we would have $\pp_2 = \pp_1$. 
\end{losn}

\begin{exc}
What is the dimension of $\Z[x]$? 
\end{exc}
\begin{sol}
The answer is 2, because of
$$
(0) \subset (p) \subset (p,x).
$$
=======
>>>>>>> 6c23ee3526a4d2c896cddba577f8a746977c2737
\end{sol}

\begin{oppg}[Exercise 1.11]
Prove that if $K$ is not algebraically closed, then any algebraic set in $K^n$ is the zero set of a single polynomial.
\end{oppg}
\begin{losn}
Suppose $Z=V(F_1,\ldots,F_r)$ is an algebraic set. We first show that for any $n$, there is a polynomial whose only zero is the origin. 

The case $n=1$ is clear, and the case $n=2$ can be gotten this way: choose an irreducible polynomial $f(x)$ of degree greater than one (here we use that $K$ is not algebraically closed). Then form the homogenization of $f(x)$ with respect to $y$. Call this new polynomial $G(x,y)$. Then $G(x,y)$ have only one zero at the origin. 

Now assume we have such a polynomial $H$ for $n=k-1$. Then form $G(H(x_1,\ldots,x_{n-1}),x_n)$. Done.

Let $n=r$. Let $F(x_1,\ldots,x_n)=H(f_1,\ldots,f_r)$. Done.

(I must admit I cheated on this one. I had to Google the first part)
\end{losn}

\begin{oppg}[Exc 1.14]
If a principal ideal domain is not a field, prove that it has dimension one.
\end{oppg}
\begin{losn}
Suppose we have a minimal strict chain of \emph{three} prime ideals. That is, suppose the dimension of $R$ is two or more. $(0) \subset \pp_1 \subset \pp_2$. But $\pp_1=(a)$ for some $a \in R$ and $\pp_2=(b)$. But since $\pp_1 \subset \pp_2$, we must have $b=ar$ for some $r \in R$. But $\pp_2$ is a prime ideal, hence either $a \in \pp_2$ or $r \in \pp_2$. The latter cannot happen, because in that case, the inclusion would not be minimal. Neither the first, because then we would have $\pp_2 = \pp_1$. 
\end{losn}

\begin{exc}
What is the dimension of $\Z[x]$? 
\end{exc}
\begin{sol}
The answer is 2, because of
$$
(0) \subset (p) \subset (p,x).
$$
\end{sol}

\subsection{Lecture 7 - Local cohomology}

\begin{exc}[Exercise 7.2]
Check that the $\ia$-torsion functor is left-exact.
\end{exc}
\begin{sol}
Suppose $\varphi:M \hookrightarrow N$ is an injection of $R$-modules. Then clearly the induced morphism $\Gamma_\ia(M) \to \Gamma_\ia(N)$ is injective as well since $\Gamma_\ia(M)$ (N) is a submodule of $M$ (N). 
\end{sol} 




\section{Riemannian geometry - Do Carmo}

\subsection{Chapter 0 - Differentiable manifolds}

\begin{exc}[Excercise 2]
 Prove that the tangent bundle of a differentiable manifold $M$ is orientable.
\end{exc}
\begin{sol}
Locally the tangent bundle is given by $\R^n \times \R^n$, and if $f:\R^n \to \R^n$ is a transition function between two charts, then the induced transition function on the tangent bundle is given by $f \times df$. Hence the differential of the transition map is given by a block diagonal matrix with $df$ appearing twice. Hence the determinant is $(\det df)^2 > 0$, hence $TM$ is orientable.
\end{sol}

\begin{exc}[Exercise 4]
  Show that the projective plane $\PP^2(\R)$ is non-orientable.
\end{exc}
\begin{sol}
  From the hint, we see that it is enough to find an open subset of $\PP^2(\R)$ that is non-orientable. 
\end{sol}

\begin{exc}[Exercise 5 - Embedding of $P^2(\R)$ in $\R^4$]

Let $F:\R^3 \to \R^4$ be given by
\[
F(x,y,z) = (x^2-y^2, xy,xz,yz).
\]  
Let $S^2 \subset \R^3$ be the unit sphere. Observe that the restriction $\varphi = F\mid S^2$ is such that $\varphi(p) = \varphi(-p)$, and consider the mapping $\tilde \varphi: P^2(\R) \to \R^4$ given by
\[
\tilde \varphi([p]) = \varphi(p).
\]
Prove that a) $\tilde \varphi$ is an immersion and b) that $\tilde \varphi$ is injective. This implies, together with the compactness of $P^2(\R)$ that $\tilde \varphi$ is an embedding.
\end{exc}
\begin{sol}
Since $S^2$ is locally diffeomorphic to $P(\R^2)$, it is enough to check that $\varphi$ is an immersion. We do this on charts. One chart of $S^2$ is given by
\[
(x,y) \mapsto \left( \frac{2x}{x^2+y^2+1}, \frac{2y}{x^2+y^2+1}, \frac{x^2+y^2-1}{x^2+y^2+1} \right).
\]
In this chart (forgetting the scaling, since by the chain rule, that will only contribute by multiplication by a scalar), the Jacobian look like
\[
\begin{pmatrix}
  8x & 4y & 6x+2y^2-2 & 4xy \\
-8y & 4x & 4xy & 2x^2+6y^2-2
\end{pmatrix}.
\]
The first minor (the first two columns) is only zero if $x=y=0$, and in that case, the last minor is non-zero. Hence (at least in this chart), the mapping is an immersion.

For b), note the $xy=ab$ and $xz=bc$ together imply $y/z=b/c$ which implies $yc=bz$, hence $y=bc/z$. Hence $bc^2=bz^2$, hence $c = \pm z$. Inserting this into $xz=ac$ gives $x=\pm a$, and similarly $y=\pm b$, hence $\tilde \varphi$ is injective.
\end{sol}

\subsection{Chapter 2 - Affine and Riemannian connections}

\begin{exc}[Exercise 8]
Consider the upper half plane
\[
\R_+^2 = \{ (x,y) \in \R^2 \mid y > 0 \},
\]  
with the metric given by $g_{11}=g_{22}=\frac 1{y^2}$ and $g_{12}=g_{21}=0$.
\begin{enumerate}[a)]
\item Show that the Christoffel symbols of the Riemannian connection are $\Gamma_{11}^1=\Gamma_{12}^2 = \Gamma_{22}^1 = 0$, $\Gamma_{11}^2 = \frac{1}{y}$, $\Gamma_{12}^1 = \Gamma_{22}^2 = -\frac 1y$.
\item Let $v_0=(0,1)$ be a tangent vector at the point $(0,1)$ of $\R_+^2$. Let $v(t)$ be the parallel transport of $v_0$ along the curve $x=t,y=1$. Show that $v(t)$ makes an angle $t$ with the direction of the $y$-axis, measured in the clockwise sense.
\end{enumerate}
\end{exc}

\begin{sol}
a)

This part is easy but tedious, using the fact that
\[
\Gamma^m_{ij} = \frac 12 \sum_k \left( \dd{}{x_i} g_{jk} +\dd{}{x_j} g_{ki} - \dd{}{x_k} g_{ij} \right) g^{km}
\]
where $(g^{km})$ is the inverse matrix of $(g_{ij})$, it being $$
\begin{pmatrix}
y^2 & 0 \\ 0 & y^2 
\end{pmatrix}.$$

b)

The parallel transport satisfies the equation
\[
0 = \frac{dv^k}{dt} + \sum_{ij} \Gamma_{ij} v^j \frac{dx_i}{dt}
\]
for $k=1,2$, on page 53. In this case, using the values of $\Gamma_{ij}^k$, and the fact that $y=1$ along the curve $v(t)$, these equations simplify to
\[
\begin{cases}
  0 &= \frac{da}{dt} - b(t) \\
0 &= \frac{db}{dt} + a(t).
\end{cases}
\]
Now, since $v_0$ was a unit vector, and paralell transport is an isometry, the image of $v_0$ must lie on the unit circle on each point of the curve. Thus we can write $(a(t),b(t)) = (\sin \theta(t), \cos \theta(t))$ for some function $\theta(t)$. Using the chain rule the equations transform to
\[
\begin{cases}
0 &= -\sin \theta(t) \theta'(t)-\sin \theta(t) = 0\\
0 &= \cos \theta(t) \theta'(t) +\cos \theta(t) = 0.
\end{cases}
\]
This implies that $\theta'(t)=-1$, hence $\theta(t)=\pi/2- t$. 
\end{sol}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
