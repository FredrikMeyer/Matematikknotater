\documentclass[11pt, english]{article}
%\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}   % S P R A A K
% \usepackage{graphicx}    % postscript graphics
\usepackage{amssymb, amsmath, amsthm, amssymb} % symboler, osv
\usepackage{mathrsfs}
\usepackage{url}
\usepackage{thmtools}
\usepackage{enumerate}  % lister $  
\usepackage{float}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{calc}
%\usepackage{tikz-3dplot}
\usepackage{subcaption}
\usepackage[all]{xy}   % for comm.diagram
\usepackage{wrapfig} % for float right
\usepackage{hyperref}
\usepackage{mystyle} % stilfilen      

%\usepackage[a5paper,margin=0.5in]{geometry}


\begin{document}
\title{Exercises}
\author{Fredrik Meyer}
\maketitle 

I solve and type exercises from different places (read \emph{books}). 

\section{Algebraic Geometry - Hartshorne}

\subsection{Chapter I - Varieties}

\begin{exc}[Exercise 1.1]
  \begin{enumerate}[a)]
  \item Let $Y$ be the plane curve $y=x^2$. Show that $A(Y)$ is isomorphic to a polynomial ring in one variable over $k$.
\item Let $Z$ be the plane curve $xy=1$. Show that $A(Z)$ is not isomorphic to a polynomial ring in one variable over $k$.
\item Let $f$ be any irreducible quadratic polynomial in $k[x,y]$, and let $W$ be the conic defined by $f$. Show that $A(W)$ is isomorphic to $A(Y)$ or $A(Z)$. Which one is it when?
  \end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item  We have $A(Y)=k[x,y]/(y-x^2)$. An isomorphism $A(Y) \to k[t]$ is given by $x \mapsto t$ and $y \mapsto t^2$. 
\item We have $A(Z) = k[x,y]/(xy-1) \simeq k[x,\frac 1x]$. So we must show that $k[x,\frac 1x] \not \approx k[x]$. It can be computed that the first one has automorphisms given by $x \mapsto cx^n$ for $c$ nonzero and $n \neq 0$. The second has as automorphisms $ax+b$ ($a \neq 0$). So the first one have an abelian automorphism group, the second has not.
\item What is special about $A(Y)$ and $A(Z)$? Staring at pictures, we see that any line in $\Aa^2$ intersects $Y$ in at least one point, but in the case of $Z$, there exist two lines which do not intersect $Z$. We claim that this is the only two things that can happen.

First we claim that if we are in the second situation, that is, if there exist a pair of lines $\ell,\ell'$ such that $W \cap \ell = W \cap \ell' =\emptyset$, then $W \simeq Z$. 

A general quadric can be written as
\[
ax^2+bxy+cy^2+dx+ey+f=0.
\]
Suppose now $\ell \cap W=\emptyset$. This is equivalent to $I(f,\ell^\vee)=(1)$. Without loss of generality, we can assumme $\ell = \{ x = 0 \}$. Then
\[
I(f,\ell) = (cy^2+ey+f,x).
\]
This generates $k[x,y]$ if and only if $c=e=0$ and $f \neq 0$. Thus $f$ must be of the form
\[
ax^2+bxy+dx+f=0
\]
with $f \neq 0$. But this can be written as
\[
x(ax+by+d)+f = 0.
\]
Put $y' = ax+by+d$. Then $I(W)$ takes the form $(xy'+f=0)$, which is clearly isomorphic to $Z$ after a linear change of coordinates. Note that the other line not meeting $W$ is the line given by $y'=ax+by+d=0$.

Assume now that we are in the other situation, namely that \emph{every} line in $\Aa^2$ meets $W$. Now pick a tangent line $\ell$ of $W$. Without loss of generality, we can assume that $\ell$ is $\{ y=0 \}$. This is a tangent line if and only if it meets $W$ doubly, meaning that $I(W) + (\ell^\vee)$ takes the form $(l^2,y)$ for some linear form $l$. We can also assume that $\ell \cap W = (0,0)$, so that $I(W) + (\ell^\vee) =(x^2,y)$. But this means that
\begin{align*}
  I(W) + I(\ell) &= (ax^2+bxy+cy^2+dx+ey+f,y) \\
&= (ax^2+dx+f,y)
\end{align*}
We want $ax^2+dx+f=x^2$. This can happen only if $d=f=0$ and $a \neq 0$. Thus the quadric takes the form
\[
ax^2+bxy+cy^2+ey=0.
\]
Now we claim that there exist one line at each point of $W$ that intersect $W$ transversally in exactly one point. This is the case for $Y$. Consider the pencil of lines through $(0,0)$ defined by $x=\lambda y$. We want to find $\lambda$ such that the intersection is transversal and only one point. We have
\[
( ax^2+bxy+cy^2+ey, x-\lambda y) = \left( (a\lambda ^2+b\lambda+c)y^2+ey,x-\lambda y \right).
\]
This have exactly one solution if and only if $a\lambda^2+b\lambda+c=0$. This is solvable since $a \neq 0$ and since all lines intersect $W$. Thus choose $\lambda$ as above. We can rotate this line such that it becomes $x=0$. Then the equation takes the form
\[
ax^2+bxy+ey=0.
\]
We have still not arrived at $y=x^2$. Let now $y=\lambda x$ be a general line through the origin. We demand that this intersect $W$ twice for every $\lambda$ such that the line is not tangent. We get that the intersection is given by
\[
ax^2+b\lambda x+ex = x((a+\lambda b)x+e) = 0.
\]
For this to have two solutions for every $\lambda$ we must have $a+\lambda b \neq 0$ for all $\lambda$. But this requires $b =0$.  Thus the equation is
\[
ax^2+ey = 0
\]
which is the conic we were looking for.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 1.2, the twisted cubic curve]

Let $Y \subseteq \Aa^3$ be the set $\{ (t,t^2,t^3) \mid t \in k\}$. Show that $Y$ is an affine variety of dimension $1$. Find generators for the ideal $I(Y)$. Show that $A(Y)$ is isomorphic to a polynomial ring in one variable over $k$. We say that $Y$ is given by the \emph{parametric equation} $x=t,y=t^2,z=t^3$.  
\end{exc}
\begin{sol}
An affine variety is by definition a closed irreducible subset of $\Aa^3$. So we must find an irreducible ideal $I$ such that $Z(I)=Y$ (forgive the abuse of notation).

I claim that $I(Y)=\langle x^2-y,x^3-z \rangle$. Clearly, every $P \in Y$ satisfies these equations. This shows the inclusion $Y \subset Z(I)$. Now suppose $P \in Z(I)$, that is, $f(P)=0$ for all $f \in I$. In particular $(x^2-y)(P)=0$ and $(x^3-z)(P)=0$. Thus $y=x^2$ and $z=x^3$. So if $P=(a,b,c) \in k^3$, then $P=(a,a^2,a^3)$, so $P \in Y$. This shows that $Z(I)=Y$. If we can show that $I$ is prime, then it follows that $I(Y)=I$ and that $Y$ is a variety.

In fact, we claim that $k[x,y,z]/I \simeq k[t]$, implying that $I$ is prime. The map $\varphi$ is given by $x \mapsto t$, $y \mapsto t^2$, $z \mapsto t^3$. Then clearly $I \subseteq \ker \varphi$. We must show equality. So suppose $\varphi(f)=0$. 

First we claim that any $f \in k[x,y,z]$ can be written as $f=R(x)+S(x)y+T(x)z+i(x,y,z)$ where $i$ is a polynomial in $I$. We prove this by induction on $\deg f$. If $\deg f = 1$, this is trivially true.  The rest of the proof proceeds by tedious induction.
\end{sol}

\subsection{Chapter II - Schemes}

\begin{exc}[Exercise 1.16, Flabby/flasque sheaves]
A sheaf $\FF$ on a topological space $X$ is \emph{flasque} (flabby) if for every inclusion $U \subseteq V$, the restriction map $\FF(U) \to \FF(V)$ is surjective.
\begin{enumerate}[a)]
\item Show that a constant sheaf on an irreducible topological space is flasque.
\item If $0 \to \FF' \to \FF \to \FF'' \to 0$ is an exact sequence of sheaves, and if $\FF'$ is flabby, then for any open set $U$, the sequence
$$
0 \to \FF'(U) \to \FF(U) \to \FF''(U) \to 0
$$
is exact.
\item Same as above, but suppose $\FF'$ and $\FF$ are flabby. Show that $\FF''$ is flabby.
\item If $f:X \to Y$ is a continous map, and $\FF$ is a flabby sheaf on $X$, then $f_*\FF$ is flabby on $Y$.
\item Let $\FF$ be any sheaf on $X$. We define a new sheaf $\mathscr G$, called the \emph{sheaf of discontinous sections of $\FF$}, as follows: For each open set $U \subset X$, $\mathscr G(U)$ is the set of maps $s:U \to \cup_{P \in U} \FF_P$, such that for all $P \in U$, $s(P) \in \FF_P$. Show that $\mathscr G$ is a flabby sheaf, and that there is a natural injective morphism from $\FF$ to $\mathscr G$.
\end{enumerate}
\end{exc}

\begin{sol}
\begin{enumerate}[a)]
\item Every open set in $X$ is irreducible and dense, and dense sets are connected. Hence a constant sheaf is actually constant, and all the restriction maps are identities (except if one of them is the empty set).
\item The sheaf axiom for a sheaf $\FF$ is equivalent to the following: for every covering $\{U_i \}$ of $U$, the following sequence is exact:
$$
0 \to \FF(U) \to \prod_i \FF(U_i) \to \prod_{ij} \FF(U_{ij}),
$$
where $U_{ij}= U_i \cap U_j$. The first map sends a section $s$ to the product of all its restrictions, and the second map sends $(s_i) \mapsto (s_i-s_j)_{ij \in I \times I}$.

Since the sequence of sheaves in the exercise is exact, for small enough $U_i$, the sequence $0 \to \FF'(U_i) \to \FF(U_i) \to \FF''(U_i) \to 0$ is exact (for sheaves, exactness is a local property). Hence we can form the following diagram, where the columns are exact by the sheaf property, and the rows are exact by what was just said:
\[
\xymatrix{
 & 0\ar[d] & 0 \ar[d] & 0 \ar[d] \\
 0 \ar[r] & \FF'(U) \ar[r]\ar[d] & \FF(U) \ar[r]\ar[d] & \FF''(U)\ar[d] \\
 0 \ar[r] & \prod_i \FF'(U_i) \ar[r]\ar[d]^f & \prod_i \FF(U_i) \ar[r]\ar[d] & \prod_i\FF''(U_i) \ar[r]\ar[d] & 0  \\
 0 \ar[r] &\prod_{ij} \FF'(U_{ij}) \ar[r]\ar[d] & \prod_{ij} \FF(U_{ij}) \ar[r] & \prod_{ij}\FF''(U_{ij}) \ar[r] & 0 \\
 & \coker f
}
\]
Now, $\coker f=0$ since $\FF'$ is flabby! Hence apply the snake lemma to see that the top right map is surjective as well!
\item Use the same diagram. The middle column is surjective at the bottom, and by commutativity, the right column must be as well.
\item This is obvious, since $f_\ast \FF(V) = \FF(f^{-1}(V))$.
\item It is clear that $\mathscr G$ is a sheaf. If $U \subset V$, let $s \in \mathscr G(U)$ be given. Then define $s' \in G(V)$ as follows: $s'(P)=s(P)$ if $P \in U$ and zero elsewhere. This element will be sent to $s$.

The injective morphism from $\FF$ to $\mathscr G$ is defined as follows: send $s \in \FF(U)$ to the function $s(P)=s_P$ in $\mathscr G(U)$.
\end{enumerate}
\end{sol}



\begin{exc}[Exercise 2.19]
Let $A$ be a ring. The following are equivalent:
\begin{enumerate}
\item $\Spec A$ is disconnected.
\item There exists nonzero elements $e_1,e_2 \in A$ such that $e_1e_2=0$, $e_1^2=e_1$, $e_2^2=e_2$ and $e_1+e_2=1$ (these are called \emph{orthogonal idempotents}).
\item $A$ is isomorphic to a direct product $A_1 \times A_2$ of two nonzero rings.
\end{enumerate}
\end{exc}
\begin{proof}
$1 \Rightarrow 3$: Let $U$ be a nonempty connected compontent of $X=\Spec A$. Let $V = X \bs U$ be its complement, and let $i_1:U \to X$ and $i_2=V \to X$ be the natural inclusions on topological spaces. This can be extended to a map of schemes as well: we need to give a morphism $f^\#:\OO_X \to f_\ast \OO_U$. But $f_\ast \OO_U(W)=\OO_X(W \cap U)$, so $f_\ast \OO_U = \restr{\OO_X}{U}$. Hence we just choose $f^\$:\OO_X \to \OO_U$ to be the natural map provided by the sheaf axioms.

We now have two morphisms $i_1:U \to X$ and $i_2:V \to X$ which are closed immersions, hence the induced ring morphisms $A \to A_1$ and $A \to A_2$ are surjective. Also, the universal property for products hold because the universal property for coproducts hold in the category of affine schemes. Hence $A \simeq A_1 \times A_2$.  (a bit clumsy??)

$2 \Rightarrow 3$: Let $\pi_i: A \to A$ be given by multiplication by $e_i$ and let $A_i$ be its image. Then $\ker \pi_1 = A_2$, because  if $e_1f$ then $f=e_2f$, so $f \in A_2$. The splitting maps are the natural inclusions. 

$3 \Rightarrow 2$: If $A = A_1 \times A_2$, let $e_i=\pi_i(1)$. 

$3 \Rightarrow 1$: Similar to the first argument, just opposite.
\end{proof}



\begin{exc}[Excercise 7.1]
Let $(X,\OO_X)$ be a locally ringed space and let $f:\mathscr L \to \mathscr M$ be a surjective map of invertible sheaves on $X$. Show that $f$ is an isomorphism.  
\end{exc}
\begin{sol}
Since $\mathscr L, \mathscr M$ are invertible, we have isomorphisms $\mathscr L_x \approx \OO_{X,x}$ and $\mathscr M_x \approx \OO_{X,x}$ for each $x \in X$.

But $\Hom_{\OO_{X,x}}(\OO_{X,x},\OO_{X,x})=\OO_{X,x}$, that is, all homomorphisms are given by multiplication by some $h \in \OO_{X,x}$. But since $f$ was surjective, we conclude that $h$ is outside $\mm_x$, the maximal ideal of $\OO_{X,x}$. But then $h$ is a unit, so $f$ is an isomorphism.
\end{sol}

\subsection{Chapter III - Cohomology}

\begin{exc}[Exercise 4.3]
Let $X= \Aa^2_k=\Spec k[x,y]$ and let $U = X \bs \{(0,0)\}$. Use a suitable open cover of $X$ by open affine subsets to show that $H^1(U,\OO_U)$ is isomorphic to the $k$-vector space spanned by $\{ x^i y^j \mid i,j < 0 \}$. In particular, it is infinitedimensional, and so $U$ cannot be affine (not projective either).  
\end{exc}
\begin{sol}
We can cover $U$ by $U_1= \Aa^2 \bs \{ x= 0\}$ and $U_2 = \Aa^2 \bs \{ y = 0\}$. We have $U_1 \cap U_2 = \Aa^2 \bs \{ xy=0\}$. Also, $\OO(U_1)=k[x,y,\frac 1x]$ and $\OO(U_2)=k[x,y,\frac 1y]$ and $\OO(U_1 \cap U_2) = k[x,y,\frac {1}{xy}]$. Then the \v{C}ech complex takes the form
\[
0 \to k[x,y,\frac 1x] \times k[x,y, \frac 1y] \xrightarrow{d} k[x,y,\frac{1}{xy}] \to 0,
\]
the differential being difference. Then $H^1(U,\OO_U)$ can be computed as the homology at the second term. But nothing on the left side can hit anything of the form $x^iy^j$ with $i,j < 0$. Anything else is hit. Thus we have
\[
H^1(U, \OO_U) \simeq \{ x^i y^j \mid i,j < 0 \}
\]
as $k$-vector spaces.
\end{sol}

\begin{exc}[Exercise 4.7]
Let $X$ be the subscheme of $\PP_k^2$ defined by a single homogeneous polynomial $f(x_0,x_1,x_2)=0$ of degree $d$. Assume that $(1,0,0)$ is not on $X$. Then show that $X$ can be covered by the two open affine subsets $U= X \cap \{ x_1 \neq 0\}$ and $V = X \cap \{ x_2 \neq 0\}$. Now calculate the \v Cech complex
\[
\Gamma(U,\OO_X) \oplus \Gamma(V,\OO_X) \to \Gamma(U \cap V, \OO_X)
\]
explicitly, and thus show that
\begin{align*}
  \dim_k H^0(X,\OO_X) &= 1 \\
\dim _k H^1(X,\OO_X) &= \frac 12 (d-1)(d-2).
\end{align*}
\end{exc}

\begin{sol}
  $X$ can be covered by just two open affines since $\PP^2 \bs (U \cup V) = \{(1:0:0)\}$, which was assumed not to lie on the curve.

The open affine subset $\Gamma(U, \OO_X)$ can be identified with the polynomial ring $k[u,v]/\langle f(u,1,v) \rangle$, and $\Gamma(V,\OO_X) = k[x,y]/f(x,y,1)$. The differential is then given by 
\[
\left( g(u,v), h(x,y) \right) \mapsto g(xy^{-1},y^{-1})-h(x,y) \in k[x,y,\frac 1y].
\]

We can assume that $f=x_0^d$, since what really matters is the degree, and we are just doing linear algebra.

We first calculate $H^0(X,\OO_X)$. So suppose $g(xy^{-1}, y^{-1})-h(x,y)=0$ in $k[x,y,y^{-1}]/\langle f(x,y,1) \rangle$. By definition this means that
\[
g(xy^{-1},y^{-1}) - h(x,y) = f(x,y,1) \cdot \tilde f(x,y,\frac 1y)
\]
for some polynomial $\tilde f$. Write $\tilde f$ as $\tilde f_0 + \tilde f_1$, where $\tilde f_0=\sum_{j < 0} a_{ij} x^i y^j$ and $\tilde f_1 \in k[x,y]$. Then we have the equality
\[
g(xy^{-1},y^{-1}) - h(x,y) = \sum_{j < 0} a_{ij}x^{i+d}y^j + \sum_{j \geq 0} x^{i+d} y^j.
\]
First of all, we see that the constant terms of $g$ and $h$ must be equal, because there are no constant terms on the right hand side. Secondly, $g(xy^{-1},y^{-1})$ consists solely of terms with $j < 0$. Thus the non constant terms of  $g(xy^{-1},y^{-1})$ must be equal to the left term of the right hand side above. But both terms of the right hand side are zero modulo $f$, so the constant terms of $g(xy^{-1},y^{-1})$ are also zero mod $f$. The same holds for $h(x,y)$. Thus $H^0(X,\OO_X)= \{ (c,c) \mid c \in k \} \simeq k$.

Now we compute $H^1(X,\OO_X)$. Consider a monomial $x^iy^j$ in the target. If both $i,j \geq 0$, then it is hit by $(0,-x^iy^j)$. Likewise, if $j \geq i$, then $(x^iy^{j-i},0) \mapsto x^i x^{-j}$. Thus all monomials $x^iy^{-j}$ with $j \geq i$ is zero in the cokernel. Further, if $i \geq d$, then $x^i y^j$ is already zero! Thus, we can draw the non-zero monomials in the cokernel as points in the lattice $\Z^2$. This is a triangle of length $d-2$. Thus the dimension of $H^1(X,\OO_X)$ is 
\[
1 + 2 + \ldots+ d-3 + d-2 = \frac 12 (d-2)(d-2+1) = \frac 12 (d-2)(d-1).
\]
\end{sol}

\subsection{Chapter IV - Curves}

\begin{exc}[Exercise 1.1]
Let $X$ be a curve and $P \in X$ a point. Show that there exists a nonconstant rational function $f \in K(X)$ which is regular everywhere except at $P$.
\end{exc}
\begin{sol}
Let $D$ be the divisor $D=nP$. The linear system 
$$
\{ E = D + f \geq 0 \}
$$
consists of all divisors linearly equivalent to $D$. But these are classified by those $f$ with $(f) \geq -nP$, i.e. those $f$ with at most poles of order $n$ at $P$.

By Riemann-Roch we have
$$
l(D)-l(K-D) = \deg D +1 -g = n+1-g.
$$
If $n$ is large enough, $K-D$ will have negative degree, so $l(K-D)=0$. Thus for large $n$, we can get $l(D)$ as big as we want.

\end{sol}

%%%%%%%%%%%%%%%
\section{Commutative Algebra - Eisenbud}

\subsection{Chapter 16 - Modules of Differentials}
\begin{exc}[Exercise 16.1]
Show that if $b \in S$ is an idempotent ($b^2=b$), and $d:S \to M$ is any derivation, then $db=0$.  
\end{exc}
\begin{sol}
This is trivial. $db=d(b^2)=2db$. If $2=0$, then the statement is automatically true. If not, then $db=0$ by subtraction. 
\end{sol}

\section{Deformation Theory - Hartshorne}

\subsection{Chapter I.3 - The $T^i$ functors}

\begin{exc}[Exercise 3.1]
Let $B=k[x,y](xy)$. Show that $T^1(B/k,M)=M \otimes k$ and $T^2(B/k,M)=0$ for any $B$-module $M$.  
\end{exc}
\begin{sol}
Since $B$ is defined by a principal ideal in $P=k[x,y]$, it follows that $L_2=0$ in the cotangent complex. Thus $T^2(B/k,M)$ is automatically zero.

We have that $L_1 = B$ and $L_0 = B dx \oplus B dy$ with $d_1$ being $f \mapsto (fy,fx)$. Applying $\Hom(-,M)$, we get $\Hom(L_0,M)=M \oplus M$ and $\Hom(L_1,M)=M$.

We have $\Hom(B \oplus B,M) \simeq M \oplus M$ by $\phi \mapsto (\phi(1,0),\phi(0,1)$. We have a diagram
\[
\xymatrix{
\Hom(B \oplus B, M) \ar[d]_{\simeq} \ar[r]^{\psi^\ast} & \Hom(B,M) \ar[d]^{\simeq} \\
M \oplus M  \ar[r] & M
}
\]
Under these isomorphisms, it is easy to see that the bottom map is given by
\[
(\phi(1,0),\phi(0,1)) \mapsto y \phi(1,0) + x\phi(0,1).
\]
Thus since $T^1$ is the cokernel of this map, we must have $T^1(B/k,M) = M \otimes k$. 
\end{sol}

\begin{exc}[Exercise 3.3]
Let $B = k[x,y]/(x^2,xy,y^2)$. Show that $T^0(B/k,B) = k^4$, $T^1(B/k,B)=k^4$ and $T^2(B/k,B)=k$.  
\end{exc}

\begin{sol}
Let's compute $L_2$ first. For that we need part of a resolution of $I$. We have in fact
\[
0 \to \im \begin{pmatrix} -y & 0 \\ x & -y \\ 0 & x \end{pmatrix} \to P(-2)^3 \to I \to 0.
\]
The Koszul relations are given by 
\[
\im \begin{pmatrix}
-y^2 & -xy & 0 \\
0 & x^2 & -y^2 \\
x^2 & 0 & xy
\end{pmatrix}.
\]
Let's compute $Q/F_0$ (relations modulo Koszul relations). Since $Q$ is generated in degree $3$, and $F_0$ is of degree $4$, we have $\dim_k (Q/F_0)_3 = 2$. Let's consider degree $4$. As a $k$-vector space $Q_4$ is spanned by the four elements
\[
\begin{pmatrix}
  -y^2 \\ xy \\ 0 
\end{pmatrix},
\begin{pmatrix}
  0 \\ -y^2 \\ xy 
\end{pmatrix},
\begin{pmatrix}
  -yx \\ x^2 \\ 0
\end{pmatrix},
\begin{pmatrix}
  0 \\ -yx \\ x^2
\end{pmatrix}.
\]
The two in the middle are already Koszul relations, so that $(Q/F_0)_4$ have dimension $\leq 2$. But we also have
\[
\begin{pmatrix}
  -y^2 \\ xy \\ 0
\end{pmatrix} = 
\begin{pmatrix}
0 \\ yx \\ -x^2 
\end{pmatrix}
+
\begin{pmatrix}
-y^2 \\ 0 \\ x^2
\end{pmatrix}.
\]
Thus $\dim_k (Q/F_0)_4=1$, since the second term above is a Koszul relation. Similarly we find that $\dim_k (Q/F_0)_5 =0$. Hence, $L_2$ is the $3$-dimensional $k$-vector space spanned by $Q_3$ and one more relation. $L_1$ is $F \otimes B=B^3$, and $L_0$ is $B \oplus B$, spanned by $dx,dy$.

Taking duals, we get that $L_2 = \Hom(Q/F_0,B)$. This set can be identified with
\begin{align*}
\Hom(Q/F_0,B) &= \{ \varphi: Q \to B \mid \restr{\varphi}{F_0} = 0 \} \\
&= \{ \varphi: Q \to P \mid \im \restr{f}{F_0} \subseteq I \}
\end{align*}
Thus, since $I= \mm^2$, we must have that $\varphi$ sends the two generators of $Q$ to something of degree $1$ (degree $0$ is not ok, since then $F_0$ would be sent outside $I$). Thus $\Hom(Q/F_0,B)$ is $2 \times 2=4$-dimensional, spanned by 
\[
\im 
\begin{pmatrix}
  y & x & 0 & 0 \\
0 & 0 & x & y
\end{pmatrix}.
\]
But $d_2$ is the dual of the inclusion $Q \to F$ from the exact sequence above. The dual is given by transposing, and we are left with one column - in conclusion, $T^2(B/k,B)$ is one-dimensional.

The Jacobian of $I$ is given by
\[
\begin{pmatrix}
  2x & y & 0 \\
0 & x & 2y 
\end{pmatrix},
\]
and it is easily seen that the kernel of $\text{Jac} \otimes B$ is given by $\mm \oplus \mm \oplus \mm \subset B^3$. The two relations kill off two dimensions, so $\dim_k T^1(B/k,B) = \dim_k \mm^{\oplus 3} - 2 = 6-2=4$.

Also $T^0(B/k,B)$ is $B^2$ modulo the image of the Jacobian. The constants are left untouched, so $\dim_k T^0(B/k,B) = 2+2+2-3=3$. A basis is given by $(1,0),(0,1)$ and $(x,y)$. (thus Hartshorne is wrong?)
\end{sol}

\section{Introduction to Commutative Algebra - Atiyah-MacDonald}

\subsection{Chapter 1 - Rings and ideals}

\begin{exc}
Let $x$ be a nilpotent element of a ring $A$. Show that $1+x$ is a unit of $A$. Deduce that the sum of a nilpotent element and a unit is a unit.
\end{exc}
\begin{sol}
Suppose $x^{n+1}=0$ and that $x^n \neq 0$. Consider
\[
s = 1-x+x^2-x^3+\ldots+x^n
\]
Then
\[
sx = x-x^2+x^3-x^4+\ldots-x^n
\]
since $x^{n+1}=0$. But then $s+sx=1$, so that $s(1+x)=1$. Hence $1+x$ is a unit. To prove that the sum of any unit and any nilpotent is a unit, note that if $u$ is any unit, then $u^{-1}x$ is still nilpotent. So since $u+x=u(1+u^{-1}x)$ and product of units are units, the claim follows.
\end{sol}

\begin{exc}[Exercise 11]
A ring $A$ is \emph{Boolean} if $x^2=x$ every $x \in A$. In a Boolean ring $A$, show that
\begin{enumerate}[i)]
\item $2x=0$ for all $x \in A$.
\item Every prime ideal $\pp$ is maximal, and $A/\pp$ is a field with two elements.
\item Every finitely generated ideal in $A$ is principal.
\end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[i)]
  \item We have $4x=4x^2=(2x)^2=2x$, hence $2x=0$.
\item Consider $A/\pp$. This is an integral domain in which $x^2=x$ for all $x \in A/\pp$. But then $x^2-x=x(x-1)=0$. Hence either $x=0$ or $x=1$, hence $A/\pp$ can have only two elements. Thus it is isomorphic to $\Z/2\Z$ which is a field, hence $\pp$ is maximal.
\item Let $I=(a_1,\cdots,a_r)$. Every ideal is contained in a maximal ideal $\mm$. Consider the image of $I$ in $A/\mm$. 
\item By induction we can assume that $I$ is generated by two elements, say $I=(a_1,a_2)$. Then I claim that $I=(a_1+a_2)$. Cleary $(a_1+a_2) \subseteq (a_1,a_2)$. The other direction will follow if we can see that $a_1a_2=0$ (or they can be assumed to satisfy this), because $a_1a_2+a_1 \in (a_1+a_2)$.  [[[[[[[[[[[????]]]]]]]]]]]
\end{enumerate}
\end{sol}

\begin{exc}[Exercise 12]
A local ring contains no nontrivial idempotents.  
\end{exc}
\begin{sol}
Suppose $x \neq 0,1$ and that $x^2=x$. Then $x^2-x=x(x-1)=0$. Both $x$ and $x-1$ cannot be contained in $\mm$ since they generate $A$. Hence one of the is unit. Hence either $x=0$ or $x=1$, contradiction. 
\end{sol}

\begin{exc}[Exercise 15, The prime spectrum of a ring]

Let $A$ be a ring and let $X$ be the set of prime ideals of $A$. For each subset $E$ of $A$, let $V(E)$ denote the set of prime ideals of $A$ which contain $E$. Prove that
\begin{enumerate}
\item If $\ia$ is the ideal generated by $E$, then $V(E)=V(\ia)=V(r(\ia))$\footnote{Here $r(\ia)$ denotes the radical of $\ia$}.
\item $V(0)=X$ and $V(1)=\emptyset$.
\item If $(E_i)_{i \in I}$ is a family of subsets of $A$, then
\[
V\left( \bigcup_{i \in I} E_i \right) = \bigcap_{i \in I} V\left(E_i\right).
\]
\item $V(\ia \cap \ib)=V(\ia \ib)=V(\ia) \cup V(\ib)$ for all ideals $\ia,\ib$ of $A$.
\end{enumerate}
These results show that the sets $V(E)$ satisfy the axioms for closed sets in a topological space. The resulting topolgoy is called the \emph{Zariski topology}. The topological space $X$ is called the \emph{prime spectrum of $A$} and denoted $\Spec A$.
\end{exc}

\begin{sol}
We do these one by one.
\begin{enumerate}
\item Clearly $\pp \supset \langle E \rangle \supset E$, where the brackets denote the ideal generated by $E$. Hence $V(\ia) \subset V(E)$. But if $\pp \supset E$, we must have $\pp \supset \ia$ since $\langle \pp \rangle = \pp$. Thus the first equality is established.

Since $r(\ia) \subset \ia$, we have $V(\ia) \subset V(r(\ia))$. Suppose $\pp \supset r(\ia)$ and suppose $a \in \ia$. We want to show $a \in \pp$. We know that $a^n \in r(\ia)$ for some $n$, hence $a^n \in \pp$. But $\pp$ is a prime ideal, so $a \in \pp$ also. Hence equality is established.
\item Every ideal contains the zero ideal and $(1)$ is not a prime ideal.
\item Suppose $\pp \supset \cup E_i$. Then $\pp \supset E_i$ for all $i$, so $\pp \in \cap V(E_i)$. Thus this is just a formal consequence of the contravariant nature of $V(-)$.
\item Since $\ia \ib  \subset \ia \cap \ib$, we automatically have $V(\ia \cap \ib) \subset V(\ia \ib)$. So suppose $\pp \supset \ia \ib$ and let $a \in \ia \cap \ib$. Then $a^2 \in \ia \ib \subset \pp$, but then $a \in \pp$ since $\pp$ is prime.

Now suppose $\pp \supset \ia$ or $\pp \supset \ib$. Then if $a \in \ia \cap \ib$, we have $a \in \pp$, so $V(\ia) \cup V(\ib) \subset V(\ia \cap \ib)$. Now suppose $\pp \supset \ia \cap \ib$. Then by Proposition 1.11, we have $\pp \supset \ia$ or $\pp \supset \ib$. 
\end{enumerate}
\end{sol}

\begin{exc}[Exercise 17]
For each $f \in A$, let $X_f$ denote the complement of $V(f)$ in $X=\Spec A$. The sets $X_f$ are open. Show that they form a basis for the Zariski topology, and that
\begin{enumerate}
\item $X_f \cap X_g = X_{fg}$.
\item $X_f = \emptyset \Leftrightarrow f$ is nilpotent.
\item $X_f = X \Leftrightarrow f$ is a unit.
\item $X_f = X_g \Leftrightarrow r((f)) = r((g))$.
\item $X$ is quasi-compact.
\item More generally, each $X_f$ is quasi-compact.
\item An open subset of $X$ is quasi-compact if and only if it is a finite union of the sets $X_f$.
\end{enumerate}
The sets $X_f$ are called \emph{basic open sets} of $X=\Spec A$.
\end{exc}
\begin{sol}
We need to show that the sets $X_f$ forms a basis for the Zariski topology on $X$. This means that each open in $X$ can be written as a union of the $X_f$. An open in $X$ have the form 
\[
U(\ia) = \{ \pp \in \Spec A \mid \pp \not \supset \ia \}.
\]
The sets $X_f$ have the form
\[
X_f = \{ \pp \in \Spec A \mid f \not \in \pp \}.
\]
Let $\{ f_i \}_{i \in I}$ generate $\ia$. I claim that $\bigcup X_{f_i} = U(\ia)$. Let $\pp$ be an element of the left hand side. This means by definition that $f_i \not \in \pp$ for some $i$. But $f_i$ is an element of $\ia$, so $\ia \not \subset \pp$, hence $\pp \in U(\ia)$. 

Conversely, suppose $\pp \not \supset \ia$. Then some generator $f_i$ of $\ia$ is not contained in $\pp$. Hence $\pp \in X_{f_i}$. 

\begin{enumerate}
\item We have $$X_f \cap X_g = \{ \pp \mid f,g  \not \in \pp \} = \{ \pp \mid fg \not \in \pp \} ,$$
since $\pp$ is a prime ideal: for suppose $f,g \not \in \pp$, then $fg \not \in \pp$ also, because if $fg \in \pp$, primality implies either $f$ or $g in \pp$. Conversely, suppose $fg \not \in \pp$. Then neither $f,g$ can be in $\pp$ by defintion of ideals.
\item Suppose $X_f$ is empty. Then there are no prime ideals with $f \not \in \pp$. But that means that $f$ is contained in every prime ideal, hence $f$ is nilpotent.
\item Suppose $X_f = X$. Then for all prime ideals, $f \not \in \pp$, hence $f$ generates the unit ideal, hence $f$ is a unit. For if $f$ did not generate the unit ideal, $f$ would be contained in some maximal ideal $\mm$, and maximal ideals are prime.
\item Suppose $X_f=X_g$. By definition, this means that for every prime $\pp$ with $f \not \in \pp$, we have $g \not \in \pp$ (and conversely). The contrapositive of this is $g \in \pp \Leftrightarrow f \in \pp$. Hence we have 
$$r((f)) = \bigcap_{\pp \supset (f)} \pp=\bigcap_{\pp \ni f} \pp = \bigcap_{\pp \ni g} \pp = r((g)).$$ 
\item Let $\{X_f\}_{f \in I}$ be a covering of $X$ by basic opens, that is, $X= \bigcup_{f \in I} X_f$. This means that for every $\pp \in X$, there is some $f \in I$ with $f \not \in \pp$. I claim that the $f_i$ generate the unit ideal: for if not, $\langle f_i \rangle$ would be contained in some prime ideal, but by the above, this is not the case. Hence there is an equation of the form $1=\sum g_if_i$ with $g_i \in A$, which is a \emph{finite} sum. Hence these finitely many $f_i$ suffice.
\item ...
\end{enumerate}
\end{sol}




\subsection{Chapter 2 - Modules}

\begin{exc}[Excercise 1]
Show that $\Z/m \otimes_Z \Z/n = 0$ if $m,n$ are coprime.
\end{exc}
\begin{sol}
Write $1=am+bn$. Then 
\begin{align*}
1 \otimes 1 = (am+bn) \otimes 1 &= am \otimes 1 + bn \otimes 1 \\
&=  0 + bn \otimes 1 = 1 \otimes bn = 1 \otimes 0 = 0.
\end{align*}
And we are done.
\end{sol}

\begin{exc}[Exercise 2]
 Let $A$ be a ring, $\ia$ an ideal, and $M$ an $A$-module. Then $(A/\ia) \otimes_A M$ is isomorphic to $M/\ia M$.
\end{exc}
\begin{sol}
Start with
\[
0 \to \ia \to A \to A/ \ia \to 0.
\]

Tensoring with $M$ gives
\[
\ia \otimes M  \to M \to A/\ia \otimes_A M \to 0.
\]
But $\ia \otimes_A M \simeq \ia M$, so that the sequence reads $A/\ia \otimes M \simeq M/\ia M$.
\end{sol}

\begin{exc}[Exercise 3]
 Let $A$ be a local ring, $M,N$ finitely generated $A$-modules. Prove that if $M \otimes N=0$, then $M=0$ or $N = 0$. 
\end{exc}
\begin{sol}
First a counterexample if $A$ is not a local ring. Let $A=k[x]$ and $M=k[x]/(x-1)$ and $N=k[x]/(x)$. We can write $1 = -(x-1) + x$. Then $M \otimes_A N = 0$ by the same method as in Exercise 1 ($1 \otimes 1 = (-x+1 + x) \otimes 1 = x \otimes 1 = 1 \otimes x = 0$). 

Let $M_k := M \otimes k = M/\mm M$. By Nakayama's lemma, $M_k=0 \Rightarrow M=0$.

So suppose $M \otimes_A N=0$. Then $(M \otimes_A N)_k = 0$. But this is isomorphic to $M_k \otimes_A  N_k$ since $k \otimes_A k = k$. But $M_k \otimes_A N_k \simeq M_k \otimes_k N_k$, as $k$-modules, since everything in $\mm$ acts trivially on $M_k$. But these are vector spaces over a field, now we must have $M_k=0$ or $N_k=0$, and by Nakayama we are done.
\end{sol}

\begin{exc}[Exercise 4]

Let $M_i$ ($i \in I$) be any family of $A$-modules, and let $M$ be their direct sum. Then $M$ is flat if and only if each $M_i$ is flat.  
\end{exc}
\begin{sol}
Let
\[
0 \to N' \to N \to N'' \to 0
\]
be any exact sequence. Then tensoring with $M$ gives
\[
0 \to N' \otimes_A M \to N \otimes_A M \to N'' \otimes_A M \to 0.
\]
We only need to check that the left map is injective. But we have $N' \otimes_A M \simeq \bigoplus_i N' \otimes_A M_i$ and $N \otimes_A M \simeq \bigotimes_i N \otimes_A M_i$, and thus the left map is just the direct sum of all the maps 
\[
0 \to N' \otimes_A M_i \to N \otimes_A M,
\]
which is injective if and only if each $M_i$ is flat.
\end{sol}

\begin{exc}[Exercise 5]
Let $A[x]$ be the ring of polynomials in one indeterminate over a ring $A$. Prove that $A[x]$ is flat $A$-algebra.  
\end{exc}
\begin{sol}
We have $A[x] = \bigoplus_{i=0}^\infty x^i A$ as an $A$-module. Now use Exercise 4.
\end{sol}

\begin{exc}[Exercise 24]
If $M$ is an $A$-module, the following are equivalent:
  \begin{enumerate}[i)]
  \item $M$ is flat.
\item $\Tor_n^A(M,N)=0$ for all $n>0$ and $A$-modules $N$.
\item $\Tor_1^A(M,N)=0$ for all $A$-modules $N$.
  \end{enumerate}
  \begin{sol}

To compute $\Tor_A^n(M,N)$, one takes an $A$-resolution of $N$ and tensor it with $M$ and take homology. But $M$ is flat, so the sequence stays exact, so the homology is zero. This shows $i) \Rightarrow ii)$.

The implication $ii) \Rightarrow iii)$ is trivial.

Now let
\[
0 \to N' \to N \to N'' \to 0
\]
be any exact sequence of $A$-modules. Then by properties of the Tor functor, we have an exact sequence
\[
\Tor_1(M,N'') \to N' \otimes M \to N \otimes M \to N'' \otimes M \to 0.
\]
But $\Tor_1(M,N'')=0$, so the sequence is short exact. Hence $M$ is flat.
  \end{sol}

  \begin{exc}[Exercise 25]

Let 
\[
0 \to N' \to N \to N'' \to 0
\]
be an exact sequence with $N''$ flat. Then $N'$ is flat if and only if $N$ is flat.
  \end{exc}
  \begin{sol}
    We have from the Tor exact sequence
\[
0 \to \Tor_1(N',M) \to Tor_1(N,M) \to 0
\]
since $\Tor_2(N'',M)=\Tor_1(N'',M)=0$. The statement follows.
  \end{sol}
  
\end{exc}

\subsection{Chapter III - Rings and modules of fractions}
\begin{exc}[Exercise 1]

Let $S$ be a multiplicatively closed subset of a ring $A$, and let $M$ be a finitely-generated $A$-module. Prove that $S^{-1}M=0$ if and only if there exists $s \in S$ such that $sM=0$.  
\end{exc}

\begin{sol}
 Suppose there exists such $s$. Let $m/s' \in S^{-1}M$. This is zero if and only if there exists $s \in M$ such that $s(s'm)=0$. But $ss'm=s'sm=s'0=0$. So $m=0$ in $S^{-1}M$.  (note that we did not use finite generation)

Now let $m_1,\ldots,m_r$ be a set of generators for $M$ and suppose that $S^{-1}M=0$. Then for each $i$ ($i=1,\ldots,r$), there exists $s_i$ such that $s_im_i=0$. Since every element of $M$ is an $A$-linear combination of the $m_i$, it follows that the product $s_1s_2\cdots s_r$ makes $sM=0$.
\end{sol}

\subsection{Chapter 5 - Integral dependence and valuations}

\begin{exc}[Exercise 1]

Let $f:A \to B$ be an integral morphism of rings. Show that $f^\ast:\Spec B \to \Spec A$ is a closed mapping.  
\end{exc}
\begin{sol}
The map $f^\ast$ is by definition given by $\pp \mapsto f^{-1}(\pp) = \pp \cap A$. A closed subset of $\Spec B$ is by definition 
\[
V(\ia) = \{ \pp \in \Spec B \mid \pp \supset \ia \}
\]
for some ideal $\ia \subset B$.

Then the image of $V(\ia)$ is the set
\begin{align*}
f^\ast(V(\ia)) &= \{ \pp \cap A \mid \pp \in \Spec B, \quad  \pp \supset \ia \} 
\end{align*}
I claim that this is equal to 
\[
V(\ia \cap A) = \{ \qq \in \Spec A \mid \qq \supset \ia \cap A \},
\]
which clearly is a closed subset of $\Spec A$.

One direction is obvious: let $\pp \cap A$ be an element of $f^\ast(V(\ia))$. This is a point of $\Spec A$, and clearly $\pp \cap A \supset \ia \cap A$ since $\pp \supset \ia$.

The other direction needs the going up Theorem 5.10. Suppose $\qq \in V(\ia \cap A)$. Then by Going Up, there exists $\pp \in \Spec B$ with $\pp \cap A = \qq$. But we need to check that $\pp \supset \ia$. That is, we need to prove the assertion that if $\qq = \pp \cap A$ and $\qq \supset \ia \cap A$, then $\pp \supset \ia$. So suppose $a \in \ia \subset B$. Then $a$ satisfies an equation
\[
a^n + b_{n-1}a^{n-1} + \ldots + b_1a+b_0=0
\]
with $b_i \in A$. Since $a \in \ia$, we see that $b_0 \in \qq = \pp \cap A$. Hence
\[
a^n+b_{n-1}a^{n-1}+\ldots+b_1a = a(a^{n-1}+b_{n-1}a^{n-2}+\ldots+b_1) \in \pp
\]
since $\qq \subset \pp$. But $\pp$ is prime so either $a \in \pp$ and we are done, or $a^{n-1}b_{n-1}a^{n-2}+\ldots+b_1 \in \pp$, and we can continue by induction.

Hence we are done.
\end{sol}

\subsection{Chapter 7 - Noetherian rings}

\begin{exc}[Exercise 11]
Let $A$ be a ring such that $A_{\pp}$ is Noetherian for each $\pp \in \Spec A$. Is $A$ necessarily noetherian?
\end{exc}
\begin{sol}
Consider the ring
\[
A= \Z/2 \times \Z/2 \cdots .
\]
It is a countable product of noetherian rings. The primes are just the coordinate axes, and each localization is isomorphic to $\Z/2$. Thus each $A_\pp$ is Noetherian, but $A$ is not.
\end{sol}

\begin{exc}[Exercise 15]
Let $A$ be a Noetherian local ring, $\mm$ its maximal ideal and $k$ its residue field and let $M$ be a finitely generated $A$-module. Then the following are equivalent:
\begin{enumerate}[i)]
\item $M$ is free.
\item $M$ is flat.
\item The mapping $\mm \otimes M \to A \otimes M$ is injeective.
\item $\Tor_1^A(k,M)=0$.
\end{enumerate}
\end{exc}
\begin{sol}
The implication $i) \Rightarrow ii)$ is trivial. One way is to compute $\Tor_1^A(M,N)$ for any $A$-module $N$. But a free resolution of $M$ is just one-term, so $\Tor_1^A(M,N)$ is automatically zero.

The implication $ii \Rightarrow iii)$  follows by tensoring the incusion $\mm \hookrightarrow A$ with $M$. 

The implication $iii) \Rightarrow iv)$ follows from the $\Tor$ exact sequence
\[
\Tor_1^A(A,M) \to \Tor^A_1(k,M) \to \mm \otimes M \to A \otimes M \to k \otimes M \to 0.
\]
The leftmost term is zero since $A$ is a free $A$-module, and by $iii)$ and exactness we must as well have $\Tor_1^a(k,M)$.

Now for $iv \Rightarrow i)$. Choose element $m_i \in M$ ($0 \leq i \leq r$) such that they form a $k$-basis for $M/\mm M$. Choose a surjection $f:A^r \to M$ and let $E=\ker f$ be its kernel. Then we have an exact sequence
\[
0 \to E \to A^r \to M \to 0.
\]
of finitely-generated $A$-modules ($E$ is finitely generated by Proposition 6.2). Tensor the sequence by $k$, and get
\[
\Tor_1^A(k,M) \to E/\mm E \to k^r \to M/\mm M \to 0.
\]
The left-most term is zero by assumption. The last two spaces are $k$-vector spaces of the same dimension, and it follows that $E/\mm E=0$. But then it follows that $E$ is zero by Nakayama's lemma, hence $M$ is free.
\end{sol}

\begin{exc}[Exercise 16]
 Let $A$ be a Noetherian ring, $M$ a finitely-generated $A$-module. Then the following are equivalent:
 \begin{enumerate}[i)]
 \item $M$ is a flat $A$-module.
\item $M_\pp$ is a free $A_\pp$-module for each $\pp \in \Spec A$.
\item $M_\mm$ is a free $A_\mm$-module for each maximal ideal $\mm$.
 \end{enumerate}

So flatness is the same as being locally free.
\end{exc}
\begin{sol}
 The implications $i \Rightarrow ii)$ and $ii) \Rightarrow iii)$ follows trivially from the previous exercise. We prove $iii) \Rightarrow i)$. 

Applying the $\Tor$ functor commutes with localization, hence we have $\Tor_1^A(M,N)_\mm = \Tor_1^{A_\mm}(M_\mm, N_\mm)=0$ for all $\mm$. But being zero is a local property, so it follows that $\Tor_1^A(M,N)=0$ for all $A$-modules $N$. Hence $M$ is flat.
\end{sol}


\section{Representation Theory - Fulton, Harris}

\subsection{Representations of Finite Groups}

\begin{exc}[Exercise 1.1]
Verify that the relation 
\[
\langle g\cdot v^\ast , g \cdot v \rangle = \langle \rho^\ast(g)(v^\ast),\rho(g)(v) \rangle = \langle v^\ast, v\rangle 
\]
is satisfied when we define
\[
\rho^\ast(g) = \rho(g^{-1})^t :V^\ast \to V^\ast, 
\]
that is, $(\rho^\ast g)(v^\ast)(w)= \langle (\rho^\ast g)(v^\ast),w\rangle=\langle v^\ast, (\rho g^{-1})(w) \rangle$.
\end{exc}

\begin{sol}
This is a matter of calculation.
\[
\langle g v^\ast, gv \rangle = \langle v^\ast, (\rho g^{-1})(gv) \rangle = \langle v^\ast, v \rangle.
\]
So the definition is ok.
\end{sol}


\begin{exc}[Exercise 1.2]
Verify that in general the vector space of $G$-linear maps between two representations $V$ and $W$ of $G$ is just the subspace $\Hom(V,W)^G$ of elements of $\Hom(V,W)$ fixed under the action of $G$. This subspace is often denoted $\Hom_G(V,W)$.
\end{exc}
\begin{sol}	
A map $\varphi:V \to W$ is $G$-linear when $\varphi(gv)=g \varphi(v)$. The action of $G$ on $\varphi$ is given by $g\varphi(v)=g \varphi(g^{-1}v)$. But by $G$-linearity, this is
$$
\varphi(gv)=g g^{-1} \varphi(gv)=gg^{-1}\varphi(v)=\varphi(v).
$$
Hence a map is $G$-linear if and only if it is fixed by the action of $G$. 
\end{sol}

\begin{exc}[Exercise 1.3]
Let $\rho:G \to \GL(V)$ be any representation of the finite group $G$ on an $n$-dimensional vector space $V$ and suppose that for any $g \in G$, the determinant if $\rho(g)$ is $1$. Show that the spaces $\wedge^k V $ and $\wedge^{n-k} V^\ast$ are isomorphic as representations of $G$.
\end{exc}

\begin{sol}
This is (again) just a matter of writing out the definitions. First we define the isomorphism, and then we check that it is actually an isomorphism of representations.

\begin{align*}
\bigwedge ^k V &\to \bigwedge^{n-k} V^\ast \\
v_1 \wedge \cdots \wedge v_k &\mapsto \left( w_1 \wedge \cdots \wedge w_{n-k} \mapsto v_1 \wedge \cdots \wedge v_k \wedge w_1 \wedge \cdots \wedge w_{n-k} \right)
\end{align*}
Being a map of representations is equivalent to $g^{-1}\varphi(gv)=\varphi(v)$, so we just need to check that all the $g$'s disappear from the left hand side. 
\begin{align*}
g^{-1}\varphi(gv) &= g^{-1}(w_1\cdots w_{n-k} \mapsto gv_1\cdots gv_k w_1 \cdots w_{n-k}) \\
&= (gv_1\cdots gv_k gw_1 \cdots gw_{n-k}) \\
&= \det \rho(g) v_1 \wedge \cdots \wedge w_{n-k}.
\end{align*}
Hence $\varphi$ is a map of representations if and only if $\det \rho(g)=1$ for all $g \in G$. 

(it is an isomorphism because it has zero kernel: because what would the kernel be? Every subspace is the same, and this is a basis free description)
\end{sol}

\begin{exc}[Exercise 1.4]
The permutation representation $R$ of $G$ acting on a finite set $X$ have two descriptions: one is given by letting $V$ be the vector space with basis $\{ e_x \mid x \in X \}$ and letting $g$ act on $V$ by $ge_x = e_{gx}$. 

Alternatively $R$ is the set of functions $f:X \to \C$ with action $(g\alpha)(h)=\alpha(g^{-1}h)$.

\begin{enumerate}[a)]
\item Show that these two decriptions agree by identifying $e_x$ with the characteristic function which takes the value $1$ on $x$ and $0$ elsewhere. 
\item The space of functions on $G$ can also be made into a $G$-module by the rule $(g\alpha)(h)=\alpha(hg)$. Show that this is an isomorphic representation.
\end{enumerate}
\end{exc}
\begin{sol}
a). Clearly the vector space dimensions agree (since the characteristic functions are a basis). So we need to check that this is a map of representations. Denote the characteristic function by $\chi_x$. Then $\varphi(ge_x)(h) = \varphi(e_{gx})(h)=\chi_{gx}(h)$. Similarly $g \varphi(e_x)(h) = g \chi_x(h) = \chi_x(g^{-1}h)$, The first function is $1$ if $gx=h$, and the second function is $1$ if $g^{-1}h=x$, and these are equivalent.

b). Send $\alpha$ to the function $g \mapsto \alpha(g^{-1})$. Call this assignment $\psi$. We need to check that $\psi(g\alpha)=g \psi(\alpha)$. 

First the left hand side. We have: $\psi(g\alpha)(h)=\psi(h \mapsto \alpha(g^{-1}h))(h)=\alpha(g^{-1}h^{-1})$.

And similarly: $g \psi(\alpha)(h)=g (h \mapsto \alpha(h^{-1}))(h) = g \alpha(h^{-1})=\alpha(g^{-1}h^{-1})$. 

And these are equal.
\end{sol}

\begin{exc}[Exercise 1.10]
$G=S_3$. Verify that with $\sigma=(12)$, $\tau=(123)$, the standard representation has a basis $\alpha=(\omega, 1, \omega^2)$, $\beta=(1,\omega,\omega^2)$, with
\[
\tau \alpha = \omega \alpha, \qquad \tau \beta = \omega^2 \beta, \qquad \sigma \alpha = \beta, \qquad \sigma \beta = \alpha.
\]
\end{exc}
\begin{sol}
The standard representation $V$ is the subspace $\{ x_1+x_2+x_3=0 \}$ of $\C^3$. Since $1+\omega+\omega^2=0$, and $\alpha \cdot \beta = 3\omega \neq 0$, these two span $V$.

The identities are easy.
\end{sol}


\begin{exc}[Exercise 1.11]
Use this approach to find the decomposition of the representations $\Sym^2 V$ and $\Sym^3 V$.
\end{exc}
\begin{sol}
The elements $\{ \alpha^2, \alpha \beta, \beta^2 \}$ are a basis of $\Sym^2 V$, and the eigenvalues are $\omega^2, 1$ and $\omega$, respectively. Thus $\langle \alpha \beta \rangle$ span a representation isomorphic to $U$, the trivial representation, and $\langle \alpha^2, \beta^2 \rangle$ span a representation isomorphic to $V$, the standard representation. Hence $\Sym^2 V = U \oplus V$.

The elements $\{ \alpha^3, \alpha^2 \beta, \alpha \beta^2, \beta^3 \}$ are a basis of $\Sym^3 V$. The eigenvalues are $1, \omega, \omega^2$ and $1$, respectively. Looking at the action of $\sigma=(12)$, we see that $U \simeq \langle \alpha^3+\beta^3 \rangle$, and $U' \simeq \langle \alpha^3-\beta^3 \rangle$. The remaining $\langle \alpha^2 \beta, \alpha \beta^2 \rangle$ span a representation isomorphic to $V$. Hence $\Sym^3 V = U \oplus U' \oplus V$.
\end{sol}

\begin{exc}[Exercise 2.2]
For $\Sym^2 V$, verify that
\[
\chi_{\Sym^2 V}(g) = \frac 12 \left[ \chi_V(g)^2 + \chi_V(g^2)\right].
\]
Note that this is compatible with the decomposition $V \otimes V = \Sym^2 V \oplus \wedge^2 V$.
\end{exc}
\begin{proof}
The eigenvalues of $g$ acting on $\Sym^2 V$ are $\{\lambda_i \lambda_j \}$. Hence
\begin{align*}
\chi_{\Sym^2 V}(g) &= \sum_{i \leq j} \lambda_i \lambda_j \\
&= \sum_{i < j} \lambda_i \lambda_j + \sum_i \lambda_i^2 \\
&= \frac 12 \left( \chi_V(g)^2 - \chi_V(g^2) \right) + \chi_V(g^2) \\
&= \frac 12  \left( \chi_V(g)^2 + \chi_V(g^2) \right).
\end{align*}
\end{proof}

\begin{exc}[Exercise 2.5, The original fixed point formula]
If $V$ is a permutation representation associated to the action of a group $G$ on a finite set $X$, show that $\chi_V(g)$ is the number of elements fixed by $g$.
\end{exc}
\begin{sol}
This is easy. The matrix associated to $g$ is a permutation matrix with a $1$ in row $j$ if element number $i$ is sent to $j$. Then number of fixed points is the number of ones on the diagonal, and this is $\chi_V(g)$.
\end{sol}


\begin{exc}[Exercise 2.34]
Let $V,W$ be irreducible representations of $G$ and $L_0:V \to W$ any linear mapping. Define $L:V \to W$ by 
$$
L(v) = \frac{1}{\lvert G \rvert} \sum_g g^{-1} L_0(gv).
$$
Show that $L=0$ if $V$ and $W$ are not isomorphic, and that $L$ is multiplication by $\tr(L_0)/\dim (V)$ if $V=W$.
\end{exc}
\begin{sol}
We want to apply Schur's lemma. We check that $L$ is a $G$-module homomorphism. We have
\begin{align*}
L(hv) &= \frac{1}{\lvert G \rvert} \sum_g g^{-1}L_0(ghv) \\
&= \frac{1}{\lvert G\rvert} \sum_{gh} h {gh}^{-1}L_0(ghv) \\
&= \frac{1}{\lvert G\rvert} \sum_{g'} h {g'}^{-1}L_0(g'v)
\end{align*}
Hence $L$ is a $G$-module homomorphism. Hence by Schur's lemma, $L$ is either the zero map or an isomorphism. In particular, if they are not isomorphic, $L=0$. Now suppose $V=W$. 
\end{sol}





\end{document}
