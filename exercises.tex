\documentclass[11pt, english]{article}
%\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}   % S P R A A K
% \usepackage{graphicx}    % postscript graphics
\usepackage{amssymb, amsmath, amsthm, amssymb} % symboler, osv
\usepackage{mathrsfs}
\usepackage{url}
\usepackage{thmtools}
\usepackage{enumerate}  % lister $  
\usepackage{float}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{calc}
%\usepackage{tikz-3dplot}
\usepackage{subcaption}
\usepackage[all]{xy}   % for comm.diagram
\usepackage{wrapfig} % for float right
\usepackage{hyperref}
\usepackage{mystyle} % stilfilen      

%\usepackage[a5paper,margin=0.5in]{geometry}


\begin{document}
\title{Exercises}
\author{Fredrik Meyer}
\maketitle 

I solve and type exercises from different places (read \emph{books}). 

\section{Algebraic Geometry - Hartshorne}

\subsection{Chapter I - Varieties}

\begin{exc}[Exercise 1.1]
  \begin{enumerate}[a)]
  \item Let $Y$ be the plane curve $y=x^2$. Show that $A(Y)$ is isomorphic to a polynomial ring in one variable over $k$.
\item Let $Z$ be the plane curve $xy=1$. Show that $A(Z)$ is not isomorphic to a polynomial ring in one variable over $k$.
\item Let $f$ be any irreducible quadratic polynomial in $k[x,y]$, and let $W$ be the conic defined by $f$. Show that $A(W)$ is isomorphic to $A(Y)$ or $A(Z)$. Which one is it when?
  \end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item  We have $A(Y)=k[x,y]/(y-x^2)$. An isomorphism $A(Y) \to k[t]$ is given by $x \mapsto t$ and $y \mapsto t^2$. 
\item We have $A(Z) = k[x,y]/(xy-1) \simeq k[x,\frac 1x]$. So we must show that $k[x,\frac 1x] \not \approx k[x]$. It can be computed that the first one has automorphisms given by $x \mapsto cx^n$ for $c$ nonzero and $n \neq 0$. The second has as automorphisms $ax+b$ ($a \neq 0$). So the first one have an abelian automorphism group, the second has not.
\item What is special about $A(Y)$ and $A(Z)$? Staring at pictures, we see that any line in $\Aa^2$ intersects $Y$ in at least one point, but in the case of $Z$, there exist two lines which do not intersect $Z$. We claim that this is the only two things that can happen.

First we claim that if we are in the second situation, that is, if there exist a pair of lines $\ell,\ell'$ such that $W \cap \ell = W \cap \ell' =\emptyset$, then $W \simeq Z$. 

A general quadric can be written as
\[
ax^2+bxy+cy^2+dx+ey+f=0.
\]
Suppose now $\ell \cap W=\emptyset$. This is equivalent to $I(f,\ell^\vee)=(1)$. Without loss of generality, we can assumme $\ell = \{ x = 0 \}$. Then
\[
I(f,\ell) = (cy^2+ey+f,x).
\]
This generates $k[x,y]$ if and only if $c=e=0$ and $f \neq 0$. Thus $f$ must be of the form
\[
ax^2+bxy+dx+f=0
\]
with $f \neq 0$. But this can be written as
\[
x(ax+by+d)+f = 0.
\]
Put $y' = ax+by+d$. Then $I(W)$ takes the form $(xy'+f=0)$, which is clearly isomorphic to $Z$ after a linear change of coordinates. Note that the other line not meeting $W$ is the line given by $y'=ax+by+d=0$.

Assume now that we are in the other situation, namely that \emph{every} line in $\Aa^2$ meets $W$. Now pick a tangent line $\ell$ of $W$. Without loss of generality, we can assume that $\ell$ is $\{ y=0 \}$. This is a tangent line if and only if it meets $W$ doubly, meaning that $I(W) + (\ell^\vee)$ takes the form $(l^2,y)$ for some linear form $l$. We can also assume that $\ell \cap W = (0,0)$, so that $I(W) + (\ell^\vee) =(x^2,y)$. But this means that
\begin{align*}
  I(W) + I(\ell) &= (ax^2+bxy+cy^2+dx+ey+f,y) \\
&= (ax^2+dx+f,y)
\end{align*}
We want $ax^2+dx+f=x^2$. This can happen only if $d=f=0$ and $a \neq 0$. Thus the quadric takes the form
\[
ax^2+bxy+cy^2+ey=0.
\]
Now we claim that there exist one line at each point of $W$ that intersect $W$ transversally in exactly one point. This is the case for $Y$. Consider the pencil of lines through $(0,0)$ defined by $x=\lambda y$. We want to find $\lambda$ such that the intersection is transversal and only one point. We have
\[
( ax^2+bxy+cy^2+ey, x-\lambda y) = \left( (a\lambda ^2+b\lambda+c)y^2+ey,x-\lambda y \right).
\]
This have exactly one solution if and only if $a\lambda^2+b\lambda+c=0$. This is solvable since $a \neq 0$ and since all lines intersect $W$. Thus choose $\lambda$ as above. We can rotate this line such that it becomes $x=0$. Then the equation takes the form
\[
ax^2+bxy+ey=0.
\]
We have still not arrived at $y=x^2$. Let now $y=\lambda x$ be a general line through the origin. We demand that this intersect $W$ twice for every $\lambda$ such that the line is not tangent. We get that the intersection is given by
\[
ax^2+b\lambda x+ex = x((a+\lambda b)x+e) = 0.
\]
For this to have two solutions for every $\lambda$ we must have $a+\lambda b \neq 0$ for all $\lambda$. But this requires $b =0$.  Thus the equation is
\[
ax^2+ey = 0
\]
which is the conic we were looking for.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 1.2, the twisted cubic curve]

Let $Y \subseteq \Aa^3$ be the set $\{ (t,t^2,t^3) \mid t \in k\}$. Show that $Y$ is an affine variety of dimension $1$. Find generators for the ideal $I(Y)$. Show that $A(Y)$ is isomorphic to a polynomial ring in one variable over $k$. We say that $Y$ is given by the \emph{parametric equation} $x=t,y=t^2,z=t^3$.  
\end{exc}
\begin{sol}
An affine variety is by definition a closed irreducible subset of $\Aa^3$. So we must find an irreducible ideal $I$ such that $Z(I)=Y$ (forgive the abuse of notation).

I claim that $I(Y)=\langle x^2-y,x^3-z \rangle$. Clearly, every $P \in Y$ satisfies these equations. This shows the inclusion $Y \subset Z(I)$. Now suppose $P \in Z(I)$, that is, $f(P)=0$ for all $f \in I$. In particular $(x^2-y)(P)=0$ and $(x^3-z)(P)=0$. Thus $y=x^2$ and $z=x^3$. So if $P=(a,b,c) \in k^3$, then $P=(a,a^2,a^3)$, so $P \in Y$. This shows that $Z(I)=Y$. If we can show that $I$ is prime, then it follows that $I(Y)=I$ and that $Y$ is a variety.

In fact, we claim that $k[x,y,z]/I \simeq k[t]$, implying that $I$ is prime. The map $\varphi$ is given by $x \mapsto t$, $y \mapsto t^2$, $z \mapsto t^3$. Then clearly $I \subseteq \ker \varphi$. We must show equality. So suppose $\varphi(f)=0$. 

First we claim that any $f \in k[x,y,z]$ can be written as $f=R(x)+S(x)y+T(x)z+i(x,y,z)$ where $i$ is a polynomial in $I$. We prove this by induction on $\deg f$. If $\deg f = 1$, this is trivially true.  The rest of the proof proceeds by tedious induction.
\end{sol}

\subsection{Chapter II - Schemes}

\begin{exc}[Exercise 1.2]
  \begin{enumerate}[a)]
  \item For any morphism of sheaves $\varphi:\FF \to \mathscr G$, show that for each point $P$, $(\ker \varphi)_P = \ker (\varphi_P)$ and $(\im \varphi)_P =  \im(\varphi_P)$. 
\item Show that $\varphi$ is injective (resp. surjective) if and only if the induced map on the stalks $\varphi_P$ is injective (resp. surjective) for all $P$.
\item Show that a sequence $\ldots \FF^{i-1} \xrightarrow{\varphi^{i-1}} \FF^i \xrightarrow{\varphi^{i}}  \FF^{i+1} \to \ldots$ of sheaves and morphisms is exact if and only if for each $P \in X$, the corresponding sequence of stalks is exact as a sequence of abelian groups.
\end{enumerate}
\end{exc}

  \begin{sol}
    \begin{enumerate}[a)]
    \item An element of $(\ker \varphi)_P$ is represented by a pair $(U,f)$ with $f \in \mathscr F(U)$ satisfying $\varphi(U)(f)=0$. We have $(U,f) \simeq (V,g)$ if there is a neighbourhood $W$ of $p$ contained in $U \cap V$ such that $\restr{f}{W}=\restr{g}{W}$ (then automatically $\varphi(W)(f)=0$, since $\varphi(W)=\restr{\varphi(U)}{W}$).

On the other hand, an element of $\ker \varphi_P$ is represented by a pair $(U,f)$ satisfying the same conditions.

A similar argument works for $\im \varphi$. Alternatively, one can show that finite limits commute with direct limits. 
\item Suppose $\varphi:\FF \to \mathscr G$ is injective. Then by definition all $\varphi(U):\FF(U) \to \mathscr G(U)$ are injective, hence $(\ker \varphi)_P=\ker \varphi_P=0$, hence $\varphi_P$ is injective. Suppose $\varphi:\FF \to \mathscr G$ is surjective. By definition, this means that $\im \varphi=\mathscr G$, hence $\mathscr G_P = (\im \varphi)_P = \im \varphi_P$, so the stalks are surjective. 
\item Exactness means that $\ker \varphi^i = \im \varphi^{i-1}$. Taking stalks, gives one implication. Assume that the stalks are exact. Then the same argument works.
    \end{enumerate}
  \end{sol}

  \begin{exc}
    \begin{enumerate}[a)]
    \item Let $\varphi:\FF \to \mathscr G$ be a morphism of presheaves such that $\varphi(U):\FF(U) \to \mathscr G(U)$ is injective for each $U$. Show that the induced map $\varphi^+:\FF^+ \to \mathscr G^+$ of associated sheaves is injective.
\item Use part a) to show that if $\varphi:\FF \to \mathscr G$ is a morphism of sheaves, then $\im \varphi$ can be naturally identified with a subsheaf of $\mathscr G$, as mentioned in the text.
    \end{enumerate}
  \end{exc}

  \begin{sol}
    \begin{enumerate}[a)]
    \item From the universal property of the sheafification functor, we have a commutative square:
\[
\xymatrix{
\FF \ar[r]^\varphi \ar[d]_\theta & \mathscr G \ar[d]^\theta \\
\FF^+ \ar[r]^{\exists !} & \mathscr G^+
}
\]
The lower arrow follows from the universal property of sheafification applied to $\theta \circ \varphi$. Taking stalks induced the identity map on the vertical arrows, and since a map is injective if it is injective on stalks, the statement follows.
\item $\im \varphi$ is the sheafification of $(\im \varphi)_{pre}(U)=\{U \mapsto \varphi(U)\} $.  We have $\im \varphi(U) \subset \mathscr G(U)$ for all $U$, hence $\im \varphi_P \subset \mathscr G_P$ for all $P$, hence $\im \varphi \to \mathscr G$ is injective.
    \end{enumerate}
  \end{sol}

\begin{exc}[Exercise 1.14, Support]
Let $\FF$ be a sheaf on $X$, and let $s \in \FF(U)$ be a section over an open set $U$. The \emph{support of $s$} denoted $\Supp (s)$, is defined to be the set $\{ P \in U \mid s_P \neq 0\}$ where $s_P$ denotes the germ of $s$ in the stalk $s_P$. Show that $\Supp (s)$ is a closed subset of $U$. We define the \emph{support} of $\FF$ by $\Supp \FF$ to be $\{P \in X \mid \FF_P \neq 0 \}$. It need not be a closed subset.
\end{exc}

\begin{sol}
Showing that $\Supp(s)$ is closed is equivalent to showing that the complement is open. So let $P \in X \bs \Supp(s)$. Then $s_P=0$. But every germ is represented by a pair $(s,U)$ (with $(s',U') \simeq (s,U)$ if $\restr{s}{W}=\restr{s'}{W}$ for some open $W \subset U \cap U'$). But since $s_P=0$, there must be some neighbourhood $U$ such that $s_P$ is represented by $s=0$, hence $X \bs \Supp(s)$ can be covered by those open $U$'s.

To see that $\Supp \FF$ need not be closed, let $X=\Aa_k^1$ with $k$ an infinite field. Let $\Z$ be the constant sheaf and let $\mathscr L$ be the direct sum of infinitely many skyscraper sheaves, but not everyone. Let $\FF/\mathscr L$ be the quotient. This has support on the infinitely many points chosen, which is not closed.
\end{sol}

\begin{exc}[Exercise 1.16, Flabby/flasque sheaves]
A sheaf $\FF$ on a topological space $X$ is \emph{flasque} (flabby) if for every inclusion $U \subseteq V$, the restriction map $\FF(U) \to \FF(V)$ is surjective.
\begin{enumerate}[a)]
\item Show that a constant sheaf on an irreducible topological space is flasque.
\item If $0 \to \FF' \to \FF \to \FF'' \to 0$ is an exact sequence of sheaves, and if $\FF'$ is flabby, then for any open set $U$, the sequence
$$
0 \to \FF'(U) \to \FF(U) \to \FF''(U) \to 0
$$
is exact.
\item Same as above, but suppose $\FF'$ and $\FF$ are flabby. Show that $\FF''$ is flabby.
\item If $f:X \to Y$ is a continous map, and $\FF$ is a flabby sheaf on $X$, then $f_*\FF$ is flabby on $Y$.
\item Let $\FF$ be any sheaf on $X$. We define a new sheaf $\mathscr G$, called the \emph{sheaf of discontinous sections of $\FF$}, as follows: For each open set $U \subset X$, $\mathscr G(U)$ is the set of maps $s:U \to \cup_{P \in U} \FF_P$, such that for all $P \in U$, $s(P) \in \FF_P$. Show that $\mathscr G$ is a flabby sheaf, and that there is a natural injective morphism from $\FF$ to $\mathscr G$.
\end{enumerate}
\end{exc}

\begin{sol}
\begin{enumerate}[a)]
\item Every open set in $X$ is irreducible and dense, and dense sets are connected. Hence a constant sheaf is actually constant, and all the restriction maps are identities (except if one of them is the empty set).
\item The sheaf axiom for a sheaf $\FF$ is equivalent to the following: for every covering $\{U_i \}$ of $U$, the following sequence is exact:
$$
0 \to \FF(U) \to \prod_i \FF(U_i) \to \prod_{ij} \FF(U_{ij}),
$$
where $U_{ij}= U_i \cap U_j$. The first map sends a section $s$ to the product of all its restrictions, and the second map sends $(s_i) \mapsto (s_i-s_j)_{ij \in I \times I}$.

Since the sequence of sheaves in the exercise is exact, for small enough $U_i$, the sequence $0 \to \FF'(U_i) \to \FF(U_i) \to \FF''(U_i) \to 0$ is exact (for sheaves, exactness is a local property). Hence we can form the following diagram: 
\[
\xymatrix{
 & 0\ar[d] & 0 \ar[d] & 0 \ar[d] \\
 0 \ar[r] & \FF'(U) \ar[r]\ar[d] & \FF(U) \ar[r]\ar[d] & \FF''(U)\ar[d] \\
 0 \ar[r] & \prod_i \FF'(U_i) \ar[r]\ar[d]^f & \prod_i \FF(U_i) \ar[r]\ar[d] & \prod_i\FF''(U_i) \ar[r]\ar[d] & 0  \\
 0 \ar[r] &\prod_{ij} \FF'(U_{ij}) \ar[r]\ar[d] & \prod_{ij} \FF(U_{ij}) \ar[r] & \prod_{ij}\FF''(U_{ij}) \ar[r] & 0 \\
 & \coker f
}
\]
Hm! If $f$ was surjective, we could apply the snake lemma!! But $f$ is not surjective. (...) All proofs I've found use Zorns lemma...
\item Use the same diagram. The middle column is surjective at the bottom, and by commutativity, the right column must be as well.
\item This is obvious, since $f_\ast \FF(V) = \FF(f^{-1}(V))$.
\item It is clear that $\mathscr G$ is a sheaf. If $U \subset V$, let $s \in \mathscr G(U)$ be given. Then define $s' \in G(V)$ as follows: $s'(P)=s(P)$ if $P \in U$ and zero elsewhere. This element will be sent to $s$.

The injective morphism from $\FF$ to $\mathscr G$ is defined as follows: send $s \in \FF(U)$ to the function $s(P)=s_P$ in $\mathscr G(U)$.
\end{enumerate}
\end{sol}



\begin{exc}[Exercise 2.19]
Let $A$ be a ring. The following are equivalent:
\begin{enumerate}
\item $\Spec A$ is disconnected.
\item There exists nonzero elements $e_1,e_2 \in A$ such that $e_1e_2=0$, $e_1^2=e_1$, $e_2^2=e_2$ and $e_1+e_2=1$ (these are called \emph{orthogonal idempotents}).
\item $A$ is isomorphic to a direct product $A_1 \times A_2$ of two nonzero rings.
\end{enumerate}
\end{exc}
\begin{sol}
$1 \Rightarrow 3$: Let $U$ be a nonempty connected compontent of $X=\Spec A$. Let $V = X \bs U$ be its complement, and let $i_1:U \to X$ and $i_2=V \to X$ be the natural inclusions on topological spaces. This can be extended to a map of schemes as well: we need to give a morphism $f^\#:\OO_X \to f_\ast \OO_U$. But $f_\ast \OO_U(W)=\OO_X(W \cap U)$, so $f_\ast \OO_U = \restr{\OO_X}{U}$. Hence we just choose $f^\$:\OO_X \to \OO_U$ to be the natural map provided by the sheaf axioms.

We now have two morphisms $i_1:U \to X$ and $i_2:V \to X$ which are closed immersions, hence the induced ring morphisms $A \to A_1$ and $A \to A_2$ are surjective. Also, the universal property for products hold because the universal property for coproducts hold in the category of affine schemes. Hence $A \simeq A_1 \times A_2$.  (a bit clumsy??)

$2 \Rightarrow 3$: Let $\pi_i: A \to A$ be given by multiplication by $e_i$ and let $A_i$ be its image. Then $\ker \pi_1 = A_2$, because  if $e_1f$ then $f=e_2f$, so $f \in A_2$. The splitting maps are the natural inclusions. 

$3 \Rightarrow 2$: If $A = A_1 \times A_2$, let $e_i=\pi_i(1)$. 

$3 \Rightarrow 1$: Similar to the first argument, just opposite.
  
\end{sol}

\begin{exc}[Excercise 7.1]
Let $(X,\OO_X)$ be a locally ringed space and let $f:\mathscr L \to \mathscr M$ be a surjective map of invertible sheaves on $X$. Show that $f$ is an isomorphism.  
\end{exc}
\begin{sol}
Since $\mathscr L, \mathscr M$ are invertible, we have isomorphisms $\mathscr L_x \approx \OO_{X,x}$ and $\mathscr M_x \approx \OO_{X,x}$ for each $x \in X$.

But $\Hom_{\OO_{X,x}}(\OO_{X,x},\OO_{X,x})=\OO_{X,x}$, that is, all homomorphisms are given by multiplication by some $h \in \OO_{X,x}$. But since $f$ was surjective, we conclude that $h$ is outside $\mm_x$, the maximal ideal of $\OO_{X,x}$. But then $h$ is a unit, so $f$ is an isomorphism.
\end{sol}

\subsection{Chapter III - Cohomology}

\begin{exc}[Exercise 2.1]
  \begin{enumerate}[a)]
  \item Let $X=\Aa_k^1$ be the affine line over an infinite field $k$. Let $P,Q$ be distinct closed points on $X$ and let $U=X - \{ P,Q\}$. Show that $H^1(X,\Z_U)\neq 0$.
  \end{enumerate}
\end{exc}

\begin{sol}
  \begin{enumerate}[a)]
  \item We have an exact sequence
\[
0 \to \Z_U \to \Z \to i_\ast(\restr{\Z}{Z}) \to 0,
\]
where $Z=P \cup Q$. The last sheaf is equal to the skyscraper sheaf $\Z_P \oplus \Z_Q$. Since $\Z$ is flabby, we have $H^1(X,\Z)=0$. Hence the long exact sequence reads 
\[
0 \to \Z \to \Z \to \Z \oplus \Z \to H^1(\Z_U) \to 0.
\]
It follows that $H^1(\Z_U)=\Z^2$. In fact, this should please us, because if $k=\C$, we have that $U$ is the complex plane minus two points, which is homotopic to the figure eight, which indeed have $H_{sing}^1(U,\C)=\C^2$.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 4.3]
Let $X= \Aa^2_k=\Spec k[x,y]$ and let $U = X \bs \{(0,0)\}$. Use a suitable open cover of $X$ by open affine subsets to show that $H^1(U,\OO_U)$ is isomorphic to the $k$-vector space spanned by $\{ x^i y^j \mid i,j < 0 \}$. In particular, it is infinitedimensional, and so $U$ cannot be affine (not projective either).  
\end{exc}
\begin{sol}
We can cover $U$ by $U_1= \Aa^2 \bs \{ x= 0\}$ and $U_2 = \Aa^2 \bs \{ y = 0\}$. We have $U_1 \cap U_2 = \Aa^2 \bs \{ xy=0\}$. Also, $\OO(U_1)=k[x,y,\frac 1x]$ and $\OO(U_2)=k[x,y,\frac 1y]$ and $\OO(U_1 \cap U_2) = k[x,y,\frac {1}{xy}]$. Then the \v{C}ech complex takes the form
\[
0 \to k[x,y,\frac 1x] \times k[x,y, \frac 1y] \xrightarrow{d} k[x,y,\frac{1}{xy}] \to 0,
\]
the differential being difference. Then $H^1(U,\OO_U)$ can be computed as the homology at the second term. But nothing on the left side can hit anything of the form $x^iy^j$ with $i,j < 0$. Anything else is hit. Thus we have
\[
H^1(U, \OO_U) \simeq \{ x^i y^j \mid i,j < 0 \}
\]
as $k$-vector spaces.
\end{sol}

\begin{exc}[Exercise 4.7]
Let $X$ be the subscheme of $\PP_k^2$ defined by a single homogeneous polynomial $f(x_0,x_1,x_2)=0$ of degree $d$. Assume that $(1,0,0)$ is not on $X$. Then show that $X$ can be covered by the two open affine subsets $U= X \cap \{ x_1 \neq 0\}$ and $V = X \cap \{ x_2 \neq 0\}$. Now calculate the \v Cech complex
\[
\Gamma(U,\OO_X) \oplus \Gamma(V,\OO_X) \to \Gamma(U \cap V, \OO_X)
\]
explicitly, and thus show that
\begin{align*}
  \dim_k H^0(X,\OO_X) &= 1 \\
\dim _k H^1(X,\OO_X) &= \frac 12 (d-1)(d-2).
\end{align*}
\end{exc}

\begin{sol}
  $X$ can be covered by just two open affines since $\PP^2 \bs (U \cup V) = \{(1:0:0)\}$, which was assumed not to lie on the curve.

The open affine subset $\Gamma(U, \OO_X)$ can be identified with the polynomial ring $k[u,v]/\langle f(u,1,v) \rangle$, and $\Gamma(V,\OO_X) = k[x,y]/f(x,y,1)$. The differential is then given by 
\[
\left( g(u,v), h(x,y) \right) \mapsto g(xy^{-1},y^{-1})-h(x,y) \in k[x,y,\frac 1y].
\]

We can assume that $f=x_0^d$, since what really matters is the degree, and we are just doing linear algebra.

We first calculate $H^0(X,\OO_X)$. So suppose $g(xy^{-1}, y^{-1})-h(x,y)=0$ in $k[x,y,y^{-1}]/\langle f(x,y,1) \rangle$. By definition this means that
\[
g(xy^{-1},y^{-1}) - h(x,y) = f(x,y,1) \cdot \tilde f(x,y,\frac 1y)
\]
for some polynomial $\tilde f$. Write $\tilde f$ as $\tilde f_0 + \tilde f_1$, where $\tilde f_0=\sum_{j < 0} a_{ij} x^i y^j$ and $\tilde f_1 \in k[x,y]$. Then we have the equality
\[
g(xy^{-1},y^{-1}) - h(x,y) = \sum_{j < 0} a_{ij}x^{i+d}y^j + \sum_{j \geq 0} x^{i+d} y^j.
\]
First of all, we see that the constant terms of $g$ and $h$ must be equal, because there are no constant terms on the right hand side. Secondly, $g(xy^{-1},y^{-1})$ consists solely of terms with $j < 0$. Thus the non constant terms of  $g(xy^{-1},y^{-1})$ must be equal to the left term of the right hand side above. But both terms of the right hand side are zero modulo $f$, so the constant terms of $g(xy^{-1},y^{-1})$ are also zero mod $f$. The same holds for $h(x,y)$. Thus $H^0(X,\OO_X)= \{ (c,c) \mid c \in k \} \simeq k$.

Now we compute $H^1(X,\OO_X)$. Consider a monomial $x^iy^j$ in the target. If both $i,j \geq 0$, then it is hit by $(0,-x^iy^j)$. Likewise, if $j \geq i$, then $(x^iy^{j-i},0) \mapsto x^i x^{-j}$. Thus all monomials $x^iy^{-j}$ with $j \geq i$ is zero in the cokernel. Further, if $i \geq d$, then $x^i y^j$ is already zero! Thus, we can draw the non-zero monomials in the cokernel as points in the lattice $\Z^2$. This is a triangle of length $d-2$. Thus the dimension of $H^1(X,\OO_X)$ is 
\[
1 + 2 + \ldots+ d-3 + d-2 = \frac 12 (d-2)(d-2+1) = \frac 12 (d-2)(d-1).
\]
\end{sol}

\subsection{Chapter IV - Curves}

\begin{exc}[Exercise 1.1]
Let $X$ be a curve and $P \in X$ a point. Show that there exists a nonconstant rational function $f \in K(X)$ which is regular everywhere except at $P$.
\end{exc}
\begin{sol}
Let $D$ be the divisor $D=nP$. The linear system 
$$
\{ E = D + f \geq 0 \}
$$
consists of all divisors linearly equivalent to $D$. But these are classified by those $f$ with $(f) \geq -nP$, i.e. those $f$ with at most poles of order $n$ at $P$.

By Riemann-Roch we have
$$
l(D)-l(K-D) = \deg D +1 -g = n+1-g.
$$
If $n$ is large enough, $K-D$ will have negative degree, so $l(K-D)=0$. Thus for large $n$, we can get $l(D)$ as big as we want.

\end{sol}

%%%%%%%%%%%%%%%%%%%%
\section{Calculus on Manifolds - Spivak}

\subsection{Functions on Euclidean Space}

\begin{exc}[Exercise 1.1]
Prove that $\lvert x \rvert \leq \sum_{i=1}^n \lvert x^i  \rvert$.  
\end{exc}
\begin{sol}
 By induction, one can prove that $\sqrt{\sum_i a_i} \leq \sum_i \sqrt{a_i}$. The claim then follows trivially.
\end{sol}

\begin{exc}[Exercise 1.7]
A linear transformation $T:\R^n \to \R^n$ is \emph{norm preserving} if $\lvert T(x)\rvert = \lvert x \rvert$ for all $x \in \R^n$. It is inner product preserving if $\langle Tx,Ty \rangle = \langle x,y \rangle y$. 
\begin{enumerate}[a)]
\item Prove that $T$ is norm preserving if and only if it is inner product preserving.
\item Prove that such a linear transformation is $1-1$ and $T^{-1}$ is of the same sort.
\end{enumerate}
\end{exc}
\begin{sol}
a). The direction $\Leftarrow$ is trivial. For the other direction, choose a basis $\{x_1,\ldots,x_n\}$ of $\R^n$ such that $x=x_1$ and $y=\sum a_ix_i$. 
Then $\langle Tx ,a_ix_i \rangle = a_i \langle T x, x_i \rangle = 0$ if $i \neq 1$ and $a_1$ else. Then since $T(0)=0$ it follows that 
\[
\langle Tx, Ty \rangle = \langle Tx,T(a_1x_1) \rangle = a_1 \langle Tx_1,Tx_1 \rangle = a_1 \lvert Tx_1\rvert ^2 = a_1 \lvert x_1 \rvert ^2 = a_1\langle x_1,x_1 \rangle.
\]

b). Suppose $T(x)=0$. Then $0=\langle Tx,Tx \rangle = \langle x,x \rangle$, but this happens if and only if $x=0$. Also $\langle T^{-1} y,T^{-1}y \rangle = \langle T^{-1}T(x),T^{-1}T(x) \rangle = \langle TT^{-1}(x),TT^{-1}(x) \rangle = \langle T^{-1}x,T^{-1}x \rangle = \langle y,y \rangle$. 
\end{sol}

%%%%%%%%%%%%%%%
\section{Commutative Algebra - Eisenbud}

\subsection{Chapter 16 - Modules of Differentials}
\begin{exc}[Exercise 16.1]
Show that if $b \in S$ is an idempotent ($b^2=b$), and $d:S \to M$ is any derivation, then $db=0$.  
\end{exc}
\begin{sol}
This is trivial. $db=d(b^2)=2db$. If $2=0$, then the statement is automatically true. If not, then $db=0$ by subtraction. 
\end{sol}

\section{Deformation Theory - Hartshorne}

\subsection{Chapter I.3 - The $T^i$ functors}

\begin{exc}[Exercise 3.1]
Let $B=k[x,y](xy)$. Show that $T^1(B/k,M)=M \otimes k$ and $T^2(B/k,M)=0$ for any $B$-module $M$.  
\end{exc}
\begin{sol}
Since $B$ is defined by a principal ideal in $P=k[x,y]$, it follows that $L_2=0$ in the cotangent complex. Thus $T^2(B/k,M)$ is automatically zero.

We have that $L_1 = B$ and $L_0 = B dx \oplus B dy$ with $d_1$ being $f \mapsto (fy,fx)$. Applying $\Hom(-,M)$, we get $\Hom(L_0,M)=M \oplus M$ and $\Hom(L_1,M)=M$.

We have $\Hom(B \oplus B,M) \simeq M \oplus M$ by $\phi \mapsto (\phi(1,0),\phi(0,1)$. We have a diagram
\[
\xymatrix{
\Hom(B \oplus B, M) \ar[d]_{\simeq} \ar[r]^{\psi^\ast} & \Hom(B,M) \ar[d]^{\simeq} \\
M \oplus M  \ar[r] & M
}
\]
Under these isomorphisms, it is easy to see that the bottom map is given by
\[
(\phi(1,0),\phi(0,1)) \mapsto y \phi(1,0) + x\phi(0,1).
\]
Thus since $T^1$ is the cokernel of this map, we must have $T^1(B/k,M) = M \otimes k$. 
\end{sol}

\begin{exc}[Exercise 3.3]
Let $B = k[x,y]/(x^2,xy,y^2)$. Show that $T^0(B/k,B) = k^4$, $T^1(B/k,B)=k^4$ and $T^2(B/k,B)=k$.  
\end{exc}

\begin{sol}
Let's compute $L_2$ first. For that we need part of a resolution of $I$. We have in fact
\[
0 \to \im \begin{pmatrix} -y & 0 \\ x & -y \\ 0 & x \end{pmatrix} \to P(-2)^3 \to I \to 0.
\]
The Koszul relations are given by 
\[
\im \begin{pmatrix}
-y^2 & -xy & 0 \\
0 & x^2 & -y^2 \\
x^2 & 0 & xy
\end{pmatrix}.
\]
Let's compute $Q/F_0$ (relations modulo Koszul relations). Since $Q$ is generated in degree $3$, and $F_0$ is of degree $4$, we have $\dim_k (Q/F_0)_3 = 2$. Let's consider degree $4$. As a $k$-vector space $Q_4$ is spanned by the four elements
\[
\begin{pmatrix}
  -y^2 \\ xy \\ 0 
\end{pmatrix},
\begin{pmatrix}
  0 \\ -y^2 \\ xy 
\end{pmatrix},
\begin{pmatrix}
  -yx \\ x^2 \\ 0
\end{pmatrix},
\begin{pmatrix}
  0 \\ -yx \\ x^2
\end{pmatrix}.
\]
The two in the middle are already Koszul relations, so that $(Q/F_0)_4$ have dimension $\leq 2$. But we also have
\[
\begin{pmatrix}
  -y^2 \\ xy \\ 0
\end{pmatrix} = 
\begin{pmatrix}
0 \\ yx \\ -x^2 
\end{pmatrix}
+
\begin{pmatrix}
-y^2 \\ 0 \\ x^2
\end{pmatrix}.
\]
Thus $\dim_k (Q/F_0)_4=1$, since the second term above is a Koszul relation. Similarly we find that $\dim_k (Q/F_0)_5 =0$. Hence, $L_2$ is the $3$-dimensional $k$-vector space spanned by $Q_3$ and one more relation. $L_1$ is $F \otimes B=B^3$, and $L_0$ is $B \oplus B$, spanned by $dx,dy$.

Taking duals, we get that $L_2 = \Hom(Q/F_0,B)$. This set can be identified with
\begin{align*}
\Hom(Q/F_0,B) &= \{ \varphi: Q \to B \mid \restr{\varphi}{F_0} = 0 \} \\
&= \{ \varphi: Q \to P \mid \im \restr{f}{F_0} \subseteq I \}
\end{align*}
Thus, since $I= \mm^2$, we must have that $\varphi$ sends the two generators of $Q$ to something of degree $1$ (degree $0$ is not ok, since then $F_0$ would be sent outside $I$). Thus $\Hom(Q/F_0,B)$ is $2 \times 2=4$-dimensional, spanned by 
\[
\im 
\begin{pmatrix}
  y & x & 0 & 0 \\
0 & 0 & x & y
\end{pmatrix}.
\]
But $d_2$ is the dual of the inclusion $Q \to F$ from the exact sequence above. The dual is given by transposing, and we are left with one column - in conclusion, $T^2(B/k,B)$ is one-dimensional.

The Jacobian of $I$ is given by
\[
\begin{pmatrix}
  2x & y & 0 \\
0 & x & 2y 
\end{pmatrix},
\]
and it is easily seen that the kernel of $\text{Jac} \otimes B$ is given by $\mm \oplus \mm \oplus \mm \subset B^3$. The two relations kill off two dimensions, so $\dim_k T^1(B/k,B) = \dim_k \mm^{\oplus 3} - 2 = 6-2=4$.

Also $T^0(B/k,B)$ is $B^2$ modulo the image of the Jacobian. The constants are left untouched, so $\dim_k T^0(B/k,B) = 2+2+2-3=3$. A basis is given by $(1,0),(0,1)$ and $(x,y)$. (thus Hartshorne is wrong?)
\end{sol}

\section{Introduction to Differential Geometry - Spivak}

\subsection{Chapter 1 - Manifolds}

\begin{exc}[Exercise 3]
  \begin{enumerate}[a)]
  \item Every manifold is locally compact.
\item Every manifold is locally pathwise connected, and a connected manifold is pathwise connected.
\item A connected manifold is arcwise connected. (\emph{Arcwise connected} means that any two points can be connected by a $1-1$ path.)
  \end{enumerate}
\end{exc}

\begin{sol}
  \begin{enumerate}[a)]
  \item Indeed, let $x:\R^n \to U \subset M$ be a homeomorphism of an open subset of $M$ with $\R^n$. Then the image of $[0,1]^n$ is compact in $M$. 
\item The first part follows in the same way, since $M$ is locally homeomorphic to $\R^n$. Now assume that $M$ is connected. Fix $q \in M$. Let $V$ be the set of all points in $M$ such that there is a path from $q$ to $p$. Clearly $V$ is non-empty, by the first part of the exercise.

$V$ is also open: For let $p \in V$. Choose a neighbourhood $U$ around $p$ homeomorphic to $\R^n$. By composing paths, any point in $U$ can be reached as well. Hence $V$ is open.

We show that $V$ is closed: let $\{p_i \}$ be a convergent sequence of points $p_i \in M$ with all $p_i \in V$. We want to show that the limit point is contained in $V$. Choose a compact neighbourhood around $\lim p_i = p$, which we can assume to be $\approx [0,1]^n$. Then $p \in [0,1]^n$, and this is path connected. Hence $V$ is closed.
\item For $n > 2$, one can always homotope away from the points of non-injectivity. For $n=2$, one can do ``Reidemeister'' moves.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 4]
A space $X$ is called locally connected if for each $x \in X$, it is the case that every neoughbourhood of $x$ contains a connected neighbourhood. 
\begin{enumerate}[a)]
\item Connectedness does not imply local connectedness.
\item An open subset of a locally connected space is locally connected.
\item $X$ is locally connected if and only if components of open sets are open, so every neigbourhood of a point in a locally connected space contains an \emph{open} connected neighbourhood.
\item A locally connected space is homeomorphic to the disjoint union of its components.
\item Every manifold is locally connected, and consequently homeomorphic to the disjoint union of its components, which are open submanifolds.
\end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item Consider the topologist's since curve. Every neighbourhood of $0$ is diconnected.
\item This is ``trivial''. Let $U$ be the said open subset. The open subsets of $U$ are intersections $U \cap V$ where $V$ is open in $X$. Hence local connectedness is trivially inherited.
\item Suppose $X$ is locally connected. Let $U \subset X$ be an open set, and let $U= \cup_i U_i$ be its decomposition into its components. We want to show that each $U_i$ is open. So let $x \in U_i$. Then $U_i$ contains a connected neighbourhood containing $x$, by definition, hence $U_i$ is open.

Conversely, assume components of open sets are open. Let $x \in X$, and let $U$ be an open neighbourhood of $x$. Then $U_i$ as above is connected and can be chosen to contain $x$, hence $x$ is locally connected.

\item This is trivial, since the components are open.

\item Pathwise local connectedness implies local connectedness.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 15]
  \begin{enumerate}[a)]
  \item   Show that $\PP^1$ is homeomorphic to $S^1$. (in fact, diffeomorphic)
\item Show that $\PP^n \bs \PP^{n-1}$ is homeomorphic to the interior $D^n=\{ x \in \R^n \mid d(x,0) < 1 \}$.
  \end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item Both $\PP^1$ and $S^1$ can be covered by two open subsets homeomorphic to $\R$, and it can be checked that in both cases, the transition mapping is given by $x \mapsto \frac 1x$, hence they are glued in the same way, hence they must be diffeomorphic.S
\item By using homoegeneous coordinates, we see that $\PP^n \bs \PP^{n-1}$ is homeomorphic to $\R^n$ which is again homeomorphic to the interior of a disc.
  \end{enumerate}
\end{sol}

\section{Introduction to Commutative Algebra - Atiyah-MacDonald}

\subsection{Chapter 1 - Rings and ideals}

\begin{exc}
Let $x$ be a nilpotent element of a ring $A$. Show that $1+x$ is a unit of $A$. Deduce that the sum of a nilpotent element and a unit is a unit.
\end{exc}
\begin{sol}
Suppose $x^{n+1}=0$ and that $x^n \neq 0$. Consider
\[
s = 1-x+x^2-x^3+\ldots+x^n
\]
Then
\[
sx = x-x^2+x^3-x^4+\ldots-x^n
\]
since $x^{n+1}=0$. But then $s+sx=1$, so that $s(1+x)=1$. Hence $1+x$ is a unit. To prove that the sum of any unit and any nilpotent is a unit, note that if $u$ is any unit, then $u^{-1}x$ is still nilpotent. So since $u+x=u(1+u^{-1}x)$ and product of units are units, the claim follows.
\end{sol}

\begin{exc}[Exercise 11]
A ring $A$ is \emph{Boolean} if $x^2=x$ every $x \in A$. In a Boolean ring $A$, show that
\begin{enumerate}[i)]
\item $2x=0$ for all $x \in A$.
\item Every prime ideal $\pp$ is maximal, and $A/\pp$ is a field with two elements.
\item Every finitely generated ideal in $A$ is principal.
\end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[i)]
  \item We have $4x=4x^2=(2x)^2=2x$, hence $2x=0$.
\item Consider $A/\pp$. This is an integral domain in which $x^2=x$ for all $x \in A/\pp$. But then $x^2-x=x(x-1)=0$. Hence either $x=0$ or $x=1$, hence $A/\pp$ can have only two elements. Thus it is isomorphic to $\Z/2\Z$ which is a field, hence $\pp$ is maximal.
\item Let $I=(a_1,\cdots,a_r)$. Every ideal is contained in a maximal ideal $\mm$. Consider the image of $I$ in $A/\mm$. 
\item By induction we can assume that $I$ is generated by two elements, say $I=(a_1,a_2)$. Then I claim that $I=(a_1+a_2)$. Cleary $(a_1+a_2) \subseteq (a_1,a_2)$. The other direction will follow if we can see that $a_1a_2=0$ (or they can be assumed to satisfy this), because $a_1a_2+a_1 \in (a_1+a_2)$.  [[[[[[[[[[[????]]]]]]]]]]]
\end{enumerate}
\end{sol}

\begin{exc}[Exercise 12]
A local ring contains no nontrivial idempotents.  
\end{exc}
\begin{sol}
Suppose $x \neq 0,1$ and that $x^2=x$. Then $x^2-x=x(x-1)=0$. Both $x$ and $x-1$ cannot be contained in $\mm$ since they generate $A$. Hence one of the is unit. Hence either $x=0$ or $x=1$, contradiction. 
\end{sol}

\begin{exc}[Exercise 15, The prime spectrum of a ring]

Let $A$ be a ring and let $X$ be the set of prime ideals of $A$. For each subset $E$ of $A$, let $V(E)$ denote the set of prime ideals of $A$ which contain $E$. Prove that
\begin{enumerate}
\item If $\ia$ is the ideal generated by $E$, then $V(E)=V(\ia)=V(r(\ia))$\footnote{Here $r(\ia)$ denotes the radical of $\ia$}.
\item $V(0)=X$ and $V(1)=\emptyset$.
\item If $(E_i)_{i \in I}$ is a family of subsets of $A$, then
\[
V\left( \bigcup_{i \in I} E_i \right) = \bigcap_{i \in I} V\left(E_i\right).
\]
\item $V(\ia \cap \ib)=V(\ia \ib)=V(\ia) \cup V(\ib)$ for all ideals $\ia,\ib$ of $A$.
\end{enumerate}
These results show that the sets $V(E)$ satisfy the axioms for closed sets in a topological space. The resulting topolgoy is called the \emph{Zariski topology}. The topological space $X$ is called the \emph{prime spectrum of $A$} and denoted $\Spec A$.
\end{exc}

\begin{sol}
We do these one by one.
\begin{enumerate}
\item Clearly $\pp \supset \langle E \rangle \supset E$, where the brackets denote the ideal generated by $E$. Hence $V(\ia) \subset V(E)$. But if $\pp \supset E$, we must have $\pp \supset \ia$ since $\langle \pp \rangle = \pp$. Thus the first equality is established.

Since $r(\ia) \subset \ia$, we have $V(\ia) \subset V(r(\ia))$. Suppose $\pp \supset r(\ia)$ and suppose $a \in \ia$. We want to show $a \in \pp$. We know that $a^n \in r(\ia)$ for some $n$, hence $a^n \in \pp$. But $\pp$ is a prime ideal, so $a \in \pp$ also. Hence equality is established.
\item Every ideal contains the zero ideal and $(1)$ is not a prime ideal.
\item Suppose $\pp \supset \cup E_i$. Then $\pp \supset E_i$ for all $i$, so $\pp \in \cap V(E_i)$. Thus this is just a formal consequence of the contravariant nature of $V(-)$.
\item Since $\ia \ib  \subset \ia \cap \ib$, we automatically have $V(\ia \cap \ib) \subset V(\ia \ib)$. So suppose $\pp \supset \ia \ib$ and let $a \in \ia \cap \ib$. Then $a^2 \in \ia \ib \subset \pp$, but then $a \in \pp$ since $\pp$ is prime.

Now suppose $\pp \supset \ia$ or $\pp \supset \ib$. Then if $a \in \ia \cap \ib$, we have $a \in \pp$, so $V(\ia) \cup V(\ib) \subset V(\ia \cap \ib)$. Now suppose $\pp \supset \ia \cap \ib$. Then by Proposition 1.11, we have $\pp \supset \ia$ or $\pp \supset \ib$. 
\end{enumerate}
\end{sol}

\begin{exc}[Exercise 17]
For each $f \in A$, let $X_f$ denote the complement of $V(f)$ in $X=\Spec A$. The sets $X_f$ are open. Show that they form a basis for the Zariski topology, and that
\begin{enumerate}
\item $X_f \cap X_g = X_{fg}$.
\item $X_f = \emptyset \Leftrightarrow f$ is nilpotent.
\item $X_f = X \Leftrightarrow f$ is a unit.
\item $X_f = X_g \Leftrightarrow r((f)) = r((g))$.
\item $X$ is quasi-compact.
\item More generally, each $X_f$ is quasi-compact.
\item An open subset of $X$ is quasi-compact if and only if it is a finite union of the sets $X_f$.
\end{enumerate}
The sets $X_f$ are called \emph{basic open sets} of $X=\Spec A$.
\end{exc}
\begin{sol}
We need to show that the sets $X_f$ forms a basis for the Zariski topology on $X$. This means that each open in $X$ can be written as a union of the $X_f$. An open in $X$ have the form 
\[
U(\ia) = \{ \pp \in \Spec A \mid \pp \not \supset \ia \}.
\]
The sets $X_f$ have the form
\[
X_f = \{ \pp \in \Spec A \mid f \not \in \pp \}.
\]
Let $\{ f_i \}_{i \in I}$ generate $\ia$. I claim that $\bigcup X_{f_i} = U(\ia)$. Let $\pp$ be an element of the left hand side. This means by definition that $f_i \not \in \pp$ for some $i$. But $f_i$ is an element of $\ia$, so $\ia \not \subset \pp$, hence $\pp \in U(\ia)$. 

Conversely, suppose $\pp \not \supset \ia$. Then some generator $f_i$ of $\ia$ is not contained in $\pp$. Hence $\pp \in X_{f_i}$. 

\begin{enumerate}
\item We have $$X_f \cap X_g = \{ \pp \mid f,g  \not \in \pp \} = \{ \pp \mid fg \not \in \pp \} ,$$
since $\pp$ is a prime ideal: for suppose $f,g \not \in \pp$, then $fg \not \in \pp$ also, because if $fg \in \pp$, primality implies either $f$ or $g in \pp$. Conversely, suppose $fg \not \in \pp$. Then neither $f,g$ can be in $\pp$ by defintion of ideals.
\item Suppose $X_f$ is empty. Then there are no prime ideals with $f \not \in \pp$. But that means that $f$ is contained in every prime ideal, hence $f$ is nilpotent.
\item Suppose $X_f = X$. Then for all prime ideals, $f \not \in \pp$, hence $f$ generates the unit ideal, hence $f$ is a unit. For if $f$ did not generate the unit ideal, $f$ would be contained in some maximal ideal $\mm$, and maximal ideals are prime.
\item Suppose $X_f=X_g$. By definition, this means that for every prime $\pp$ with $f \not \in \pp$, we have $g \not \in \pp$ (and conversely). The contrapositive of this is $g \in \pp \Leftrightarrow f \in \pp$. Hence we have 
$$r((f)) = \bigcap_{\pp \supset (f)} \pp=\bigcap_{\pp \ni f} \pp = \bigcap_{\pp \ni g} \pp = r((g)).$$ 
\item Let $\{X_f\}_{f \in I}$ be a covering of $X$ by basic opens, that is, $X= \bigcup_{f \in I} X_f$. This means that for every $\pp \in X$, there is some $f \in I$ with $f \not \in \pp$. I claim that the $f_i$ generate the unit ideal: for if not, $\langle f_i \rangle$ would be contained in some prime ideal, but by the above, this is not the case. Hence there is an equation of the form $1=\sum g_if_i$ with $g_i \in A$, which is a \emph{finite} sum. Hence these finitely many $f_i$ suffice.
\item ...
\end{enumerate}
\end{sol}




\subsection{Chapter 2 - Modules}

\begin{exc}[Excercise 1]
Show that $\Z/m \otimes_Z \Z/n = 0$ if $m,n$ are coprime.
\end{exc}
\begin{sol}
Write $1=am+bn$. Then 
\begin{align*}
1 \otimes 1 = (am+bn) \otimes 1 &= am \otimes 1 + bn \otimes 1 \\
&=  0 + bn \otimes 1 = 1 \otimes bn = 1 \otimes 0 = 0.
\end{align*}
And we are done.
\end{sol}

\begin{exc}[Exercise 2]
 Let $A$ be a ring, $\ia$ an ideal, and $M$ an $A$-module. Then $(A/\ia) \otimes_A M$ is isomorphic to $M/\ia M$.
\end{exc}
\begin{sol}
Start with
\[
0 \to \ia \to A \to A/ \ia \to 0.
\]

Tensoring with $M$ gives
\[
\ia \otimes M  \to M \to A/\ia \otimes_A M \to 0.
\]
But $\ia \otimes_A M \simeq \ia M$, so that the sequence reads $A/\ia \otimes M \simeq M/\ia M$.
\end{sol}

\begin{exc}[Exercise 3]
 Let $A$ be a local ring, $M,N$ finitely generated $A$-modules. Prove that if $M \otimes N=0$, then $M=0$ or $N = 0$. 
\end{exc}
\begin{sol}
First a counterexample if $A$ is not a local ring. Let $A=k[x]$ and $M=k[x]/(x-1)$ and $N=k[x]/(x)$. We can write $1 = -(x-1) + x$. Then $M \otimes_A N = 0$ by the same method as in Exercise 1 ($1 \otimes 1 = (-x+1 + x) \otimes 1 = x \otimes 1 = 1 \otimes x = 0$). 

Let $M_k := M \otimes k = M/\mm M$. By Nakayama's lemma, $M_k=0 \Rightarrow M=0$.

So suppose $M \otimes_A N=0$. Then $(M \otimes_A N)_k = 0$. But this is isomorphic to $M_k \otimes_A  N_k$ since $k \otimes_A k = k$. But $M_k \otimes_A N_k \simeq M_k \otimes_k N_k$, as $k$-modules, since everything in $\mm$ acts trivially on $M_k$. But these are vector spaces over a field, now we must have $M_k=0$ or $N_k=0$, and by Nakayama we are done.
\end{sol}

\begin{exc}[Exercise 4]

Let $M_i$ ($i \in I$) be any family of $A$-modules, and let $M$ be their direct sum. Then $M$ is flat if and only if each $M_i$ is flat.  
\end{exc}
\begin{sol}
Let
\[
0 \to N' \to N \to N'' \to 0
\]
be any exact sequence. Then tensoring with $M$ gives
\[
0 \to N' \otimes_A M \to N \otimes_A M \to N'' \otimes_A M \to 0.
\]
We only need to check that the left map is injective. But we have $N' \otimes_A M \simeq \bigoplus_i N' \otimes_A M_i$ and $N \otimes_A M \simeq \bigotimes_i N \otimes_A M_i$, and thus the left map is just the direct sum of all the maps 
\[
0 \to N' \otimes_A M_i \to N \otimes_A M,
\]
which is injective if and only if each $M_i$ is flat.
\end{sol}

\begin{exc}[Exercise 5]
Let $A[x]$ be the ring of polynomials in one indeterminate over a ring $A$. Prove that $A[x]$ is flat $A$-algebra.  
\end{exc}
\begin{sol}
We have $A[x] = \bigoplus_{i=0}^\infty x^i A$ as an $A$-module. Now use Exercise 4.
\end{sol}

\begin{exc}[Exercise 24]
If $M$ is an $A$-module, the following are equivalent:
  \begin{enumerate}[i)]
  \item $M$ is flat.
\item $\Tor_n^A(M,N)=0$ for all $n>0$ and $A$-modules $N$.
\item $\Tor_1^A(M,N)=0$ for all $A$-modules $N$.
  \end{enumerate}
  \begin{sol}

To compute $\Tor_A^n(M,N)$, one takes an $A$-resolution of $N$ and tensor it with $M$ and take homology. But $M$ is flat, so the sequence stays exact, so the homology is zero. This shows $i) \Rightarrow ii)$.

The implication $ii) \Rightarrow iii)$ is trivial.

Now let
\[
0 \to N' \to N \to N'' \to 0
\]
be any exact sequence of $A$-modules. Then by properties of the Tor functor, we have an exact sequence
\[
\Tor_1(M,N'') \to N' \otimes M \to N \otimes M \to N'' \otimes M \to 0.
\]
But $\Tor_1(M,N'')=0$, so the sequence is short exact. Hence $M$ is flat.
  \end{sol}

  \begin{exc}[Exercise 25]

Let 
\[
0 \to N' \to N \to N'' \to 0
\]
be an exact sequence with $N''$ flat. Then $N'$ is flat if and only if $N$ is flat.
  \end{exc}
  \begin{sol}
    We have from the Tor exact sequence
\[
0 \to \Tor_1(N',M) \to Tor_1(N,M) \to 0
\]
since $\Tor_2(N'',M)=\Tor_1(N'',M)=0$. The statement follows.
  \end{sol}
  
\end{exc}

\subsection{Chapter III - Rings and modules of fractions}
\begin{exc}[Exercise 1]

Let $S$ be a multiplicatively closed subset of a ring $A$, and let $M$ be a finitely-generated $A$-module. Prove that $S^{-1}M=0$ if and only if there exists $s \in S$ such that $sM=0$.  
\end{exc}

\begin{sol}
 Suppose there exists such $s$. Let $m/s' \in S^{-1}M$. This is zero if and only if there exists $s \in M$ such that $s(s'm)=0$. But $ss'm=s'sm=s'0=0$. So $m=0$ in $S^{-1}M$.  (note that we did not use finite generation)

Now let $m_1,\ldots,m_r$ be a set of generators for $M$ and suppose that $S^{-1}M=0$. Then for each $i$ ($i=1,\ldots,r$), there exists $s_i$ such that $s_im_i=0$. Since every element of $M$ is an $A$-linear combination of the $m_i$, it follows that the product $s_1s_2\cdots s_r$ makes $sM=0$.
\end{sol}

\subsection{Chapter 5 - Integral dependence and valuations}

\begin{exc}[Exercise 1]

Let $f:A \to B$ be an integral morphism of rings. Show that $f^\ast:\Spec B \to \Spec A$ is a closed mapping.  
\end{exc}
\begin{sol}
The map $f^\ast$ is by definition given by $\pp \mapsto f^{-1}(\pp) = \pp \cap A$. A closed subset of $\Spec B$ is by definition 
\[
V(\ia) = \{ \pp \in \Spec B \mid \pp \supset \ia \}
\]
for some ideal $\ia \subset B$.

Then the image of $V(\ia)$ is the set
\begin{align*}
f^\ast(V(\ia)) &= \{ \pp \cap A \mid \pp \in \Spec B, \quad  \pp \supset \ia \} 
\end{align*}
I claim that this is equal to 
\[
V(\ia \cap A) = \{ \qq \in \Spec A \mid \qq \supset \ia \cap A \},
\]
which clearly is a closed subset of $\Spec A$.

One direction is obvious: let $\pp \cap A$ be an element of $f^\ast(V(\ia))$. This is a point of $\Spec A$, and clearly $\pp \cap A \supset \ia \cap A$ since $\pp \supset \ia$.

The other direction needs the going up Theorem 5.10. Suppose $\qq \in V(\ia \cap A)$. Then by Going Up, there exists $\pp \in \Spec B$ with $\pp \cap A = \qq$. But we need to check that $\pp \supset \ia$. That is, we need to prove the assertion that if $\qq = \pp \cap A$ and $\qq \supset \ia \cap A$, then $\pp \supset \ia$. So suppose $a \in \ia \subset B$. Then $a$ satisfies an equation
\[
a^n + b_{n-1}a^{n-1} + \ldots + b_1a+b_0=0
\]
with $b_i \in A$. Since $a \in \ia$, we see that $b_0 \in \qq = \pp \cap A$. Hence
\[
a^n+b_{n-1}a^{n-1}+\ldots+b_1a = a(a^{n-1}+b_{n-1}a^{n-2}+\ldots+b_1) \in \pp
\]
since $\qq \subset \pp$. But $\pp$ is prime so either $a \in \pp$ and we are done, or $a^{n-1}b_{n-1}a^{n-2}+\ldots+b_1 \in \pp$, and we can continue by induction.

Hence we are done.
\end{sol}

\subsection{Chapter 7 - Noetherian rings}

\begin{exc}[Exercise 11]
Let $A$ be a ring such that $A_{\pp}$ is Noetherian for each $\pp \in \Spec A$. Is $A$ necessarily noetherian?
\end{exc}
\begin{sol}
Consider the ring
\[
A= \Z/2 \times \Z/2 \cdots .
\]
It is a countable product of noetherian rings. The primes are just the coordinate axes, and each localization is isomorphic to $\Z/2$. Thus each $A_\pp$ is Noetherian, but $A$ is not.
\end{sol}

\begin{exc}[Exercise 15]
Let $A$ be a Noetherian local ring, $\mm$ its maximal ideal and $k$ its residue field and let $M$ be a finitely generated $A$-module. Then the following are equivalent:
\begin{enumerate}[i)]
\item $M$ is free.
\item $M$ is flat.
\item The mapping $\mm \otimes M \to A \otimes M$ is injeective.
\item $\Tor_1^A(k,M)=0$.
\end{enumerate}
\end{exc}
\begin{sol}
The implication $i) \Rightarrow ii)$ is trivial. One way is to compute $\Tor_1^A(M,N)$ for any $A$-module $N$. But a free resolution of $M$ is just one-term, so $\Tor_1^A(M,N)$ is automatically zero.

The implication $ii \Rightarrow iii)$  follows by tensoring the incusion $\mm \hookrightarrow A$ with $M$. 

The implication $iii) \Rightarrow iv)$ follows from the $\Tor$ exact sequence
\[
\Tor_1^A(A,M) \to \Tor^A_1(k,M) \to \mm \otimes M \to A \otimes M \to k \otimes M \to 0.
\]
The leftmost term is zero since $A$ is a free $A$-module, and by $iii)$ and exactness we must as well have $\Tor_1^a(k,M)$.

Now for $iv \Rightarrow i)$. Choose element $m_i \in M$ ($0 \leq i \leq r$) such that they form a $k$-basis for $M/\mm M$. Choose a surjection $f:A^r \to M$ and let $E=\ker f$ be its kernel. Then we have an exact sequence
\[
0 \to E \to A^r \to M \to 0.
\]
of finitely-generated $A$-modules ($E$ is finitely generated by Proposition 6.2). Tensor the sequence by $k$, and get
\[
\Tor_1^A(k,M) \to E/\mm E \to k^r \to M/\mm M \to 0.
\]
The left-most term is zero by assumption. The last two spaces are $k$-vector spaces of the same dimension, and it follows that $E/\mm E=0$. But then it follows that $E$ is zero by Nakayama's lemma, hence $M$ is free.
\end{sol}

\begin{exc}[Exercise 16]
 Let $A$ be a Noetherian ring, $M$ a finitely-generated $A$-module. Then the following are equivalent:
 \begin{enumerate}[i)]
 \item $M$ is a flat $A$-module.
\item $M_\pp$ is a free $A_\pp$-module for each $\pp \in \Spec A$.
\item $M_\mm$ is a free $A_\mm$-module for each maximal ideal $\mm$.
 \end{enumerate}

So flatness is the same as being locally free.
\end{exc}
\begin{sol}
 The implications $i \Rightarrow ii)$ and $ii) \Rightarrow iii)$ follows trivially from the previous exercise. We prove $iii) \Rightarrow i)$. 

Applying the $\Tor$ functor commutes with localization, hence we have $\Tor_1^A(M,N)_\mm = \Tor_1^{A_\mm}(M_\mm, N_\mm)=0$ for all $\mm$. But being zero is a local property, so it follows that $\Tor_1^A(M,N)=0$ for all $A$-modules $N$. Hence $M$ is flat.
\end{sol}


\section{Representation Theory - Fulton, Harris}

\subsection{Representations of Finite Groups}

\begin{exc}[Exercise 1.1]
Verify that the relation 
\[
\langle g\cdot v^\ast , g \cdot v \rangle = \langle \rho^\ast(g)(v^\ast),\rho(g)(v) \rangle = \langle v^\ast, v\rangle 
\]
is satisfied when we define
\[
\rho^\ast(g) = \rho(g^{-1})^t :V^\ast \to V^\ast, 
\]
that is, $(\rho^\ast g)(v^\ast)(w)= \langle (\rho^\ast g)(v^\ast),w\rangle=\langle v^\ast, (\rho g^{-1})(w) \rangle$.
\end{exc}

\begin{sol}
This is a matter of calculation.
\[
\langle g v^\ast, gv \rangle = \langle v^\ast, (\rho g^{-1})(gv) \rangle = \langle v^\ast, v \rangle.
\]
So the definition is ok.
\end{sol}


\begin{exc}[Exercise 1.2]
Verify that in general the vector space of $G$-linear maps between two representations $V$ and $W$ of $G$ is just the subspace $\Hom(V,W)^G$ of elements of $\Hom(V,W)$ fixed under the action of $G$. This subspace is often denoted $\Hom_G(V,W)$.
\end{exc}
\begin{sol}	
A map $\varphi:V \to W$ is $G$-linear when $\varphi(gv)=g \varphi(v)$. The action of $G$ on $\varphi$ is given by $g\varphi(v)=g \varphi(g^{-1}v)$. But by $G$-linearity, this is
$$
\varphi(gv)=g g^{-1} \varphi(gv)=gg^{-1}\varphi(v)=\varphi(v).
$$
Hence a map is $G$-linear if and only if it is fixed by the action of $G$. 
\end{sol}

\begin{exc}[Exercise 1.3]
Let $\rho:G \to \GL(V)$ be any representation of the finite group $G$ on an $n$-dimensional vector space $V$ and suppose that for any $g \in G$, the determinant if $\rho(g)$ is $1$. Show that the spaces $\wedge^k V $ and $\wedge^{n-k} V^\ast$ are isomorphic as representations of $G$.
\end{exc}

\begin{sol}
This is (again) just a matter of writing out the definitions. First we define the isomorphism, and then we check that it is actually an isomorphism of representations.

\begin{align*}
\bigwedge ^k V &\to \bigwedge^{n-k} V^\ast \\
v_1 \wedge \cdots \wedge v_k &\mapsto \left( w_1 \wedge \cdots \wedge w_{n-k} \mapsto v_1 \wedge \cdots \wedge v_k \wedge w_1 \wedge \cdots \wedge w_{n-k} \right)
\end{align*}
Being a map of representations is equivalent to $g^{-1}\varphi(gv)=\varphi(v)$, so we just need to check that all the $g$'s disappear from the left hand side. 
\begin{align*}
g^{-1}\varphi(gv) &= g^{-1}(w_1\cdots w_{n-k} \mapsto gv_1\cdots gv_k w_1 \cdots w_{n-k}) \\
&= (gv_1\cdots gv_k gw_1 \cdots gw_{n-k}) \\
&= \det \rho(g) v_1 \wedge \cdots \wedge w_{n-k}.
\end{align*}
Hence $\varphi$ is a map of representations if and only if $\det \rho(g)=1$ for all $g \in G$. 

(it is an isomorphism because it has zero kernel: because what would the kernel be? Every subspace is the same, and this is a basis free description)
\end{sol}

\begin{exc}[Exercise 1.4]
The permutation representation $R$ of $G$ acting on a finite set $X$ have two descriptions: one is given by letting $V$ be the vector space with basis $\{ e_x \mid x \in X \}$ and letting $g$ act on $V$ by $ge_x = e_{gx}$. 

Alternatively $R$ is the set of functions $f:X \to \C$ with action $(g\alpha)(h)=\alpha(g^{-1}h)$.

\begin{enumerate}[a)]
\item Show that these two decriptions agree by identifying $e_x$ with the characteristic function which takes the value $1$ on $x$ and $0$ elsewhere. 
\item The space of functions on $G$ can also be made into a $G$-module by the rule $(g\alpha)(h)=\alpha(hg)$. Show that this is an isomorphic representation.
\end{enumerate}
\end{exc}
\begin{sol}
a). Clearly the vector space dimensions agree (since the characteristic functions are a basis). So we need to check that this is a map of representations. Denote the characteristic function by $\chi_x$. Then $\varphi(ge_x)(h) = \varphi(e_{gx})(h)=\chi_{gx}(h)$. Similarly $g \varphi(e_x)(h) = g \chi_x(h) = \chi_x(g^{-1}h)$, The first function is $1$ if $gx=h$, and the second function is $1$ if $g^{-1}h=x$, and these are equivalent.

b). Send $\alpha$ to the function $g \mapsto \alpha(g^{-1})$. Call this assignment $\psi$. We need to check that $\psi(g\alpha)=g \psi(\alpha)$. 

First the left hand side. We have: $\psi(g\alpha)(h)=\psi(h \mapsto \alpha(g^{-1}h))(h)=\alpha(g^{-1}h^{-1})$.

And similarly: $g \psi(\alpha)(h)=g (h \mapsto \alpha(h^{-1}))(h) = g \alpha(h^{-1})=\alpha(g^{-1}h^{-1})$. 

And these are equal.
\end{sol}

\begin{exc}[Exercise 1.10]
$G=S_3$. Verify that with $\sigma=(12)$, $\tau=(123)$, the standard representation has a basis $\alpha=(\omega, 1, \omega^2)$, $\beta=(1,\omega,\omega^2)$, with
\[
\tau \alpha = \omega \alpha, \qquad \tau \beta = \omega^2 \beta, \qquad \sigma \alpha = \beta, \qquad \sigma \beta = \alpha.
\]
\end{exc}
\begin{sol}
The standard representation $V$ is the subspace $\{ x_1+x_2+x_3=0 \}$ of $\C^3$. Since $1+\omega+\omega^2=0$, and $\alpha \cdot \beta = 3\omega \neq 0$, these two span $V$.

The identities are easy.
\end{sol}


\begin{exc}[Exercise 1.11]
Use this approach to find the decomposition of the representations $\Sym^2 V$ and $\Sym^3 V$.
\end{exc}
\begin{sol}
The elements $\{ \alpha^2, \alpha \beta, \beta^2 \}$ are a basis of $\Sym^2 V$, and the eigenvalues are $\omega^2, 1$ and $\omega$, respectively. Thus $\langle \alpha \beta \rangle$ span a representation isomorphic to $U$, the trivial representation, and $\langle \alpha^2, \beta^2 \rangle$ span a representation isomorphic to $V$, the standard representation. Hence $\Sym^2 V = U \oplus V$.

The elements $\{ \alpha^3, \alpha^2 \beta, \alpha \beta^2, \beta^3 \}$ are a basis of $\Sym^3 V$. The eigenvalues are $1, \omega, \omega^2$ and $1$, respectively. Looking at the action of $\sigma=(12)$, we see that $U \simeq \langle \alpha^3+\beta^3 \rangle$, and $U' \simeq \langle \alpha^3-\beta^3 \rangle$. The remaining $\langle \alpha^2 \beta, \alpha \beta^2 \rangle$ span a representation isomorphic to $V$. Hence $\Sym^3 V = U \oplus U' \oplus V$.
\end{sol}

\begin{exc}[Exercise 2.2]
For $\Sym^2 V$, verify that
\[
\chi_{\Sym^2 V}(g) = \frac 12 \left[ \chi_V(g)^2 + \chi_V(g^2)\right].
\]
Note that this is compatible with the decomposition $V \otimes V = \Sym^2 V \oplus \wedge^2 V$.
\end{exc}
\begin{sol}

The eigenvalues of $g$ acting on $\Sym^2 V$ are $\{\lambda_i \lambda_j \}$. Hence
\begin{align*}
\chi_{\Sym^2 V}(g) &= \sum_{i \leq j} \lambda_i \lambda_j \\
&= \sum_{i < j} \lambda_i \lambda_j + \sum_i \lambda_i^2 \\
&= \frac 12 \left( \chi_V(g)^2 - \chi_V(g^2) \right) + \chi_V(g^2) \\
&= \frac 12  \left( \chi_V(g)^2 + \chi_V(g^2) \right).
\end{align*}
\end{sol}

\begin{exc}[Exercise 2.5, The original fixed point formula]
If $V$ is a permutation representation associated to the action of a group $G$ on a finite set $X$, show that $\chi_V(g)$ is the number of elements fixed by $g$.
\end{exc}
\begin{sol}
This is easy. The matrix associated to $g$ is a permutation matrix with a $1$ in row $j$ if element number $i$ is sent to $j$. Then number of fixed points is the number of ones on the diagonal, and this is $\chi_V(g)$.
\end{sol}


\begin{exc}[Exercise 2.34]
Let $V,W$ be irreducible representations of $G$ and $L_0:V \to W$ any linear mapping. Define $L:V \to W$ by 
$$
L(v) = \frac{1}{\lvert G \rvert} \sum_g g^{-1} L_0(gv).
$$
Show that $L=0$ if $V$ and $W$ are not isomorphic, and that $L$ is multiplication by $\tr(L_0)/\dim (V)$ if $V=W$.
\end{exc}
\begin{sol}
We want to apply Schur's lemma. We check that $L$ is a $G$-module homomorphism. We have
\begin{align*}
L(hv) &= \frac{1}{\lvert G \rvert} \sum_g g^{-1}L_0(ghv) \\
&= \frac{1}{\lvert G\rvert} \sum_{gh} h {gh}^{-1}L_0(ghv) \\
&= \frac{1}{\lvert G\rvert} \sum_{g'} h {g'}^{-1}L_0(g'v)
\end{align*}
Hence $L$ is a $G$-module homomorphism. Hence by Schur's lemma, $L$ is either the zero map or an isomorphism. In particular, if they are not isomorphic, $L=0$. Now suppose $V=W$. 
\end{sol}

\subsection{Chapter 7 - Lie groups}

\begin{exc}[Exercise 7.11]
  \begin{enumerate}[a)]
  \item Show that any discrete normal subgroup $H$ of a connected Lie group $G$ is in the center $Z(G)$.
\item If $Z(G)$ is discrete, then $G/Z(G)$ have trivial center.
 \end{enumerate}
\end{exc}
\begin{sol}
  \begin{enumerate}[a)]
  \item We must show that for any $z \in H$ and any $g \in G$, we have $gz = zg \Leftrightarrow z = gzg^{-1}$, that is, that $z$ is fixed by conjugation by  all elements of $g$. Since $H$ is normal, we must have $gzg^{-1}=z'$ for some $z' \in H$. Conjugation is a continous mapping, hence if $g'$ is close to $g$, $g'zg^{'-1}$ is close to $z'$. But by normality this must still be an element of $H$, but $H$ is discrete, for for $g'$ close enough to $g$ the only element of $H$ that can be hit is is $z$. Hence the mapping $z \mapsto gzg^{-1}$ is locally constant. $G$ is connected, so the mapping must be constant, and since $geg^{-1}=e$, the mapping must be the identity mapping, hence $gzg^{-1}=z$ for all $g \in G$ and $z \in H$. 
\item Suppose $a \in Z(G/Z(G))$. Let $\pi:G \to G/Z(G)$ be the quotient map. Let $Z=\pi^{-1}(Z(G/Z(G))$. We want to show that if  $a$ is a representative for $a$, then $a$  lies in $Z(G)$. Lying in $Z(G/Z(G))$ means that $[a,b] \in Z(G)$ for all $a \in Z$ and $b \in G$. But this  implies that the map $[,]:Z \times G \to G$ lands in $Z(G)$, which is discrete, hence the map must be constant, hence by definition, $a$ lies in $Z(G)$.
  \end{enumerate}
\end{sol}

\begin{exc}[Exercise 7.12]
  If $\varphi:H \to G$ is a covering of connected Lie groups, show that $Z(G)$ is discrete if and only if $Z(H)$ is discrete, and then $H/Z(H)=G/Z(G)$. Therefore, if $Z(G)$ is discrete, the adjoint form of $G$ exists and is $G/Z(G)$.
\end{exc}
\begin{sol}
 Suppose $Z(G)$ is discrete, and let $h \in Z(H)$. Since $\varphi$ is a covering, the image $\varphi(h)$ lies in $Z(G)$. Thus, since $Z(G)$ is discrete, we can find a small neighbourhood around $\varphi(h)$ such that $\varphi(h) \cap Z(G) = \{ \varphi(h) \}$. By shrinking the neighbourhood if necessary, it can be shrunk so that $\varphi$ is a diffeomorphism around $h$, hence $Z(H)$ is discrete as well.

Suppose $Z(H)$ is discrete. Then the image of any $h \in Z(H)$ lies in $Z(G)$ and $\varphi$ is a local diffeomorphism. 

Now for the other part. We note that we have a diagram:
\[
\xymatrix{
1 \ar[r] & \ker \restr{\varphi}{Z(H)} \ar[r] \ar[d] & \ker \varphi \ar[r] \ar[d] & \ker \bar{\varphi} \ar[d] \\ 
1 \ar[r] & Z(H) \ar[r] \ar[d] & H \ar[r] \ar[d]^\varphi & H/Z(H) \ar[d] \ar[r] & 1 \\
1 \ar[r] & Z(G) \ar[d]  \ar[r] & G \ar[r] \ar[d]  & G/Z(G) \ar[d] \ar[r] & 1\\ 
& 1 & 1 & 1 
}
\]
The vertical lower maps are all surjective since $\varphi$ is a covering map and by the proof above. By the previous exercise, we find that $\ker \restr{\varphi}{Z(H)} = \ker \varphi$, hence $H/Z(H) \simeq G/Z(G)$ by the snake lemma (which holds here, see mathoverflow 53124).
\end{sol}

\subsection{Lecture 8 - Lie Algebras and Lie groups}

\begin{exc}[Exercise 8.1]
  Let $G$ be a connected Lie group, and $U \subset G$ any neighbourhood of the identity. Show that $U$ generates $G$.
\end{exc}

\begin{sol}
The subgroup generated by $U$ can be written 
\[
H = \bigcup_{n \in \Z} U^n,
\]
hence $H$ is an open subgroup. But since $G \bs H = \bigcup_{h \not \in H} hH$, we see that any open subgroup is also closed, hence $H$ is both open and closed, hence $H=G$. (this solution was given by Theo Bhler at math.stackexchange).
\end{sol}

\section{Riemannian geometry - Do Carmo}

\subsection{Chapter 0 - Differentiable manifolds}

\begin{exc}[Excercise 2]
 Prove that the tangent bundle of a differentiable manifold $M$ is orientable.
\end{exc}
\begin{sol}
Locally the tangent bundle is given by $\R^n \times \R^n$, and if $f:\R^n \to \R^n$ is a transition function between two charts, then the induced transition function on the tangent bundle is given by $f \times df$. Hence the differential of the transition map is given by a block diagonal matrix with $df$ appearing twice. Hence the determinant is $(\det df)^2 > 0$, hence $TM$ is orientable.
\end{sol}

\begin{exc}[Exercise 4]
  Show that the projective plane $\PP^2(\R)$ is non-orientable.
\end{exc}
\begin{sol}
  From the hint, we see that it is enough to find an open subset of $\PP^2(\R)$ that is non-orientable. 
\end{sol}

\begin{exc}[Exercise 5 - Embedding of $P^2(\R)$ in $\R^4$]

Let $F:\R^3 \to \R^4$ be given by
\[
F(x,y,z) = (x^2-y^2, xy,xz,yz).
\]  
Let $S^2 \subset \R^3$ be the unit sphere. Observe that the restriction $\varphi = F\mid S^2$ is such that $\varphi(p) = \varphi(-p)$, and consider the mapping $\tilde \varphi: P^2(\R) \to \R^4$ given by
\[
\tilde \varphi([p]) = \varphi(p).
\]
Prove that a) $\tilde \varphi$ is an immersion and b) that $\tilde \varphi$ is injective. This implies, together with the compactness of $P^2(\R)$ that $\tilde \varphi$ is an embedding.
\end{exc}
\begin{sol}
Since $S^2$ is locally diffeomorphic to $P(\R^2)$, it is enough to check that $\varphi$ is an immersion. We do this on charts. One chart of $S^2$ is given by
\[
(x,y) \mapsto \left( \frac{2x}{x^2+y^2+1}, \frac{2y}{x^2+y^2+1}, \frac{x^2+y^2-1}{x^2+y^2+1} \right).
\]
In this chart (forgetting the scaling, since by the chain rule, that will only contribute by multiplication by a scalar), the Jacobian look like
\[
\begin{pmatrix}
  8x & 4y & 6x+2y^2-2 & 4xy \\
-8y & 4x & 4xy & 2x^2+6y^2-2
\end{pmatrix}.
\]
The first minor (the first two columns) is only zero if $x=y=0$, and in that case, the last minor is non-zero. Hence (at least in this chart), the mapping is an immersion.

For b), note the $xy=ab$ and $xz=bc$ together imply $y/z=b/c$ which implies $yc=bz$, hence $y=bc/z$. Hence $bc^2=bz^2$, hence $c = \pm z$. Inserting this into $xz=ac$ gives $x=\pm a$, and similarly $y=\pm b$, hence $\tilde \varphi$ is injective.
\end{sol}
\end{document}
